{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "HW04_0407_conformer.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zC5KwRyl6Flp"
      },
      "source": [
        "# Task description\n",
        "- Classify the speakers of given features.\n",
        "- Main goal: Learn how to use transformer.\n",
        "- Baselines:\n",
        "  - Easy: Run sample code and know how to use transformer.\n",
        "  - Medium: Know how to adjust parameters of transformer.\n",
        "  - Hard: Construct [conformer](https://arxiv.org/abs/2005.08100) which is a variety of transformer. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TzP2SBWNkbdf"
      },
      "source": [
        "%reset -f"
      ],
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TPDoreyypeJE"
      },
      "source": [
        "# Download dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QvpaILXnJIcw",
        "outputId": "ba9bce2f-61fa-43b5-f966-b63ec18f163c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "!unzip ./gdrive/MyDrive/Colab\\ Notebooks/HW4/Dataset.zip"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "77ItGu-vwCbd"
      },
      "source": [
        "# CONFIG"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GSgS2NH1wCCQ"
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "CONFIG = {\n",
        "    \"MODEL_PATH\": \"gdrive/MyDrive/Colab Notebooks/HW4/models/model_conformer\",\n",
        "    \"BEST_VAL_PATH\": \"gdrive/MyDrive/Colab Notebooks/HW4/models/best_val_conformer\",  \n",
        "    'SEGMENT_LEN': 128,\n",
        "}\n",
        "\n",
        "# set random seed for reproducibility\n",
        "SEED = 12345\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(SEED)\n",
        "    torch.cuda.manual_seed_all(SEED)"
      ],
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v1gYr_aoNDue"
      },
      "source": [
        "# Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mz_NpuAipk3h"
      },
      "source": [
        "## Dataset\n",
        "- Original dataset is [Voxceleb1](https://www.robots.ox.ac.uk/~vgg/data/voxceleb/).\n",
        "- The [license](https://creativecommons.org/licenses/by/4.0/) and [complete version](https://www.robots.ox.ac.uk/~vgg/data/voxceleb/files/license.txt) of Voxceleb1.\n",
        "- We randomly select 600 speakers from Voxceleb1.\n",
        "- Then preprocess the raw waveforms into mel-spectrograms.\n",
        "\n",
        "- Args:\n",
        "  - data_dir: The path to the data directory.\n",
        "  - metadata_path: The path to the metadata.\n",
        "  - segment_len: The length of audio segment for training. \n",
        "- The architecture of data directory \\\\\n",
        "  - data directory \\\\\n",
        "  |---- metadata.json \\\\\n",
        "  |---- testdata.json \\\\\n",
        "  |---- mapping.json \\\\\n",
        "  |---- uttr-{random string}.pt \\\\\n",
        "\n",
        "- The information in metadata\n",
        "  - \"n_mels\": The dimention of mel-spectrogram.\n",
        "  - \"speakers\": A dictionary. \n",
        "    - Key: speaker ids.\n",
        "    - value: \"feature_path\" and \"mel_len\"\n",
        "\n",
        "\n",
        "For efficiency, we segment the mel-spectrograms into segments in the traing step."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cd7hoGhYtbXQ"
      },
      "source": [
        "import os\n",
        "import json\n",
        "import torch\n",
        "import random\n",
        "from pathlib import Path\n",
        "from torch.utils.data import Dataset\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        " \n",
        "class myDataset(Dataset):\n",
        "  def __init__(self, data_dir, segment_len=CONFIG['SEGMENT_LEN']):\n",
        "    self.data_dir = data_dir\n",
        "    self.segment_len = segment_len\n",
        " \n",
        "    # Load the mapping from speaker neme to their corresponding id. \n",
        "    mapping_path = Path(data_dir) / \"mapping.json\"\n",
        "    mapping = json.load(mapping_path.open())\n",
        "    self.speaker2id = mapping[\"speaker2id\"]\n",
        " \n",
        "    # Load metadata of training data.\n",
        "    metadata_path = Path(data_dir) / \"metadata.json\"\n",
        "    metadata = json.load(open(metadata_path))[\"speakers\"]\n",
        " \n",
        "    # Get the total number of speaker.\n",
        "    self.speaker_num = len(metadata.keys())\n",
        "    self.data = []\n",
        "    for speaker in metadata.keys():\n",
        "      for utterances in metadata[speaker]:\n",
        "        self.data.append([utterances[\"feature_path\"], self.speaker2id[speaker]])\n",
        " \n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        " \n",
        "  def __getitem__(self, index):\n",
        "    feat_path, speaker = self.data[index]\n",
        "    # Load preprocessed mel-spectrogram.\n",
        "    mel = torch.load(os.path.join(self.data_dir, feat_path))\n",
        " \n",
        "    # Segmemt mel-spectrogram into \"segment_len\" frames.\n",
        "    if len(mel) > self.segment_len:\n",
        "      # Randomly get the starting point of the segment.\n",
        "      start = random.randint(0, len(mel) - self.segment_len)\n",
        "      # Get a segment with \"segment_len\" frames.\n",
        "      mel = torch.FloatTensor(mel[start:start+self.segment_len])\n",
        "    else:\n",
        "      mel = torch.FloatTensor(mel)\n",
        "          \n",
        "    # Turn the speaker id into long for computing loss later.\n",
        "    speaker = torch.FloatTensor([speaker]).long()\n",
        "    return mel, speaker\n",
        " \n",
        "  def get_speaker_number(self):\n",
        "    return self.speaker_num"
      ],
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mqJxjoi_NGnB"
      },
      "source": [
        "## Dataloader\n",
        "- Split dataset into training dataset(90%) and validation dataset(10%).\n",
        "- Create dataloader to iterate the data.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zuT1AuFENI8t"
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "\n",
        "def collate_batch(batch):\n",
        "  # Process features within a batch.\n",
        "  \"\"\"Collate a batch of data.\"\"\"\n",
        "  mel, speaker = zip(*batch)\n",
        "  # Because we train the model batch by batch, we need to pad the features in the same batch to make their lengths the same.\n",
        "  mel = pad_sequence(mel, batch_first=True)\n",
        "  # mel: (batch size, length, 40)\n",
        "  return mel, torch.FloatTensor(speaker).long()\n",
        "\n",
        "\n",
        "def get_dataloader(data_dir, batch_size, n_workers):\n",
        "  \"\"\"Generate dataloader\"\"\"\n",
        "  dataset = myDataset(data_dir)\n",
        "  speaker_num = dataset.get_speaker_number()\n",
        "  # Split dataset into training dataset and validation dataset\n",
        "  trainlen = int(0.9 * len(dataset))\n",
        "  lengths = [trainlen, len(dataset) - trainlen]\n",
        "  trainset, validset = random_split(dataset, lengths)\n",
        "\n",
        "  train_loader = DataLoader(\n",
        "    trainset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    drop_last=True,\n",
        "    num_workers=n_workers,\n",
        "    pin_memory=True,\n",
        "    collate_fn=collate_batch,\n",
        "  )\n",
        "  valid_loader = DataLoader(\n",
        "    validset,\n",
        "    batch_size=batch_size,\n",
        "    num_workers=n_workers,\n",
        "    drop_last=True,\n",
        "    pin_memory=True,\n",
        "    collate_fn=collate_batch,\n",
        "  )\n",
        "\n",
        "  return train_loader, valid_loader, speaker_num\n"
      ],
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X0x6eXiHpr4R"
      },
      "source": [
        "# Model\n",
        "- TransformerEncoderLayer:\n",
        "  - Base transformer encoder layer in [Attention Is All You Need](https://arxiv.org/abs/1706.03762)\n",
        "  - Parameters:\n",
        "    - d_model: the number of expected features of the input (required).\n",
        "\n",
        "    - nhead: the number of heads of the multiheadattention models (required).\n",
        "\n",
        "    - dim_feedforward: the dimension of the feedforward network model (default=2048).\n",
        "\n",
        "    - dropout: the dropout value (default=0.1).\n",
        "\n",
        "    - activation: the activation function of intermediate layer, relu or gelu (default=relu).\n",
        "\n",
        "- TransformerEncoder:\n",
        "  - TransformerEncoder is a stack of N transformer encoder layers\n",
        "  - Parameters:\n",
        "    - encoder_layer: an instance of the TransformerEncoderLayer() class (required).\n",
        "\n",
        "    - num_layers: the number of sub-encoder-layers in the encoder (required).\n",
        "\n",
        "    - norm: the layer normalization component (optional)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PIAcmvI2u8-s",
        "outputId": "ad0da35a-42ab-4253-d858-556c662632a7"
      },
      "source": [
        "# reference: https://github.com/sooftware/conformer\n",
        "import sys\n",
        "sys.path.append('gdrive/MyDrive/Colab Notebooks/HW4/conformer')\n",
        "from conformer.encoder import ConformerEncoder"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: einops in /usr/local/lib/python3.7/dist-packages (0.3.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHX4eVj4tjtd"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class Classifier(nn.Module):\n",
        "  def __init__(self, d_model=256, n_spks=600, dropout=0.1):\n",
        "    super().__init__()\n",
        "    segment_len = CONFIG['SEGMENT_LEN']\n",
        "    input_dim = 40\n",
        "\n",
        "    # Normalization\n",
        "    self.bn0 = nn.BatchNorm1d(input_dim, momentum=0.1)\n",
        "\n",
        "    self.encoder = ConformerEncoder(input_dim=input_dim, encoder_dim=d_model, conv_kernel_size=31, num_layers=1)\n",
        "\n",
        "    self.linear1 = nn.Linear(d_model, 1024)\n",
        "    self.bn1 = nn.BatchNorm1d(1024, momentum=0.1)\n",
        "\n",
        "    self.out = nn.Linear(1024, n_spks)\n",
        "\n",
        "    # activation function and dropout\n",
        "    self.act_fn = nn.ReLU(inplace=True)\n",
        "    self.dropout = nn.Dropout(p=0.5)\n",
        "\n",
        "  def forward(self, inputs):\n",
        "    \"\"\"\n",
        "    B: batch_size, S: segment_length, F: feature_num\n",
        "    I: input_dim(40), O: output_dim(n_spks)\n",
        "\n",
        "    bn: expect shape of (B, F, S)\n",
        "    linear: expect shape of (B, *, F)\n",
        "    encoder: expect shape of (B, S, F)\n",
        "    conv: expect shape of (B, F, S)\n",
        "\n",
        "    args:\n",
        "      inputs: (B, S, F/I)\n",
        "    return:\n",
        "      outs: (B, F/O)\n",
        "    \"\"\"\n",
        "    # normalize input\n",
        "    inputs = inputs.transpose(1, 2) # (B, F, S)\n",
        "    inputs = self.bn0(inputs) # (B, F, S)\n",
        "    inputs = inputs.transpose(1, 2) # (B, S, F)\n",
        "\n",
        "    # transformer\n",
        "    inputs, _ = self.encoder(inputs, torch.LongTensor(inputs.shape[0])) # (B, S, F)\n",
        "\n",
        "    # get mean of feature\n",
        "    inputs = inputs.mean(dim=1) # (B, F)\n",
        "\n",
        "    # ff_layer\n",
        "    inputs = self.linear1(inputs) # (B, F)\n",
        "    inputs = self.bn1(inputs) # (B, F)\n",
        "    inputs = self.act_fn(inputs)\n",
        "    inputs = self.dropout(inputs)\n",
        "\n",
        "    # output\n",
        "    outputs = self.out(inputs) # (B, F)\n",
        "\n",
        "    return outputs\n"
      ],
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-__DolPGpvDZ"
      },
      "source": [
        "# Learning rate schedule\n",
        "- For transformer architecture, the design of learning rate schedule is different from that of CNN.\n",
        "- Previous works show that the warmup of learning rate is useful for training models with transformer architectures.\n",
        "- The warmup schedule\n",
        "  - Set learning rate to 0 in the beginning.\n",
        "  - The learning rate increases linearly from 0 to initial learning rate during warmup period."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-0816BntqT9"
      },
      "source": [
        "import math\n",
        "\n",
        "import torch\n",
        "from torch.optim import Optimizer\n",
        "from torch.optim.lr_scheduler import LambdaLR\n",
        "\n",
        "def get_cosine_schedule_with_warmup(\n",
        "  optimizer: Optimizer,\n",
        "  num_warmup_steps: int,\n",
        "  num_training_steps: int,\n",
        "  num_cycles: float = 0.5,\n",
        "  last_epoch: int = -1,\n",
        "):\n",
        "  \"\"\"\n",
        "  Create a schedule with a learning rate that decreases following the values of the cosine function between the\n",
        "  initial lr set in the optimizer to 0, after a warmup period during which it increases linearly between 0 and the\n",
        "  initial lr set in the optimizer.\n",
        "\n",
        "  Args:\n",
        "    optimizer (:class:`~torch.optim.Optimizer`):\n",
        "      The optimizer for which to schedule the learning rate.\n",
        "    num_warmup_steps (:obj:`int`):\n",
        "      The number of steps for the warmup phase.\n",
        "    num_training_steps (:obj:`int`):\n",
        "      The total number of training steps.\n",
        "    num_cycles (:obj:`float`, `optional`, defaults to 0.5):\n",
        "      The number of waves in the cosine schedule (the defaults is to just decrease from the max value to 0\n",
        "      following a half-cosine).\n",
        "    last_epoch (:obj:`int`, `optional`, defaults to -1):\n",
        "      The index of the last epoch when resuming training.\n",
        "\n",
        "  Return:\n",
        "    :obj:`torch.optim.lr_scheduler.LambdaLR` with the appropriate schedule.\n",
        "  \"\"\"\n",
        "\n",
        "  def lr_lambda(current_step):\n",
        "    # Warmup\n",
        "    if current_step < num_warmup_steps:\n",
        "      return float(current_step) / float(max(1, num_warmup_steps))\n",
        "    # decadence\n",
        "    progress = float(current_step - num_warmup_steps) / float(\n",
        "      max(1, num_training_steps - num_warmup_steps)\n",
        "    )\n",
        "    return max(\n",
        "      0.0, 0.5 * (1.0 + math.cos(math.pi * float(num_cycles) * 2.0 * progress))\n",
        "    )\n",
        "\n",
        "  return LambdaLR(optimizer, lr_lambda, last_epoch)\n"
      ],
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IP03FFo9K8DS"
      },
      "source": [
        "# Model Function\n",
        "- Model forward function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fohaLEFJK9-t"
      },
      "source": [
        "import torch\n",
        "\n",
        "\n",
        "def model_fn(batch, model, criterion, device):\n",
        "  \"\"\"Forward a batch through the model.\"\"\"\n",
        "\n",
        "  mels, labels = batch\n",
        "  mels = mels.to(device)\n",
        "  labels = labels.to(device)\n",
        "\n",
        "  outs = model(mels)\n",
        "\n",
        "  loss = criterion(outs, labels)\n",
        "\n",
        "  # Get the speaker id with highest probability.\n",
        "  preds = outs.argmax(1)\n",
        "  # Compute accuracy.\n",
        "  accuracy = torch.mean((preds == labels).float())\n",
        "\n",
        "  return loss, accuracy\n"
      ],
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F7cg-YrzLQcf"
      },
      "source": [
        "# Validate\n",
        "- Calculate accuracy of the validation set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mD-_p6nWLO2L"
      },
      "source": [
        "from tqdm import tqdm\n",
        "import torch\n",
        "\n",
        "def valid(dataloader, model, criterion, device): \n",
        "  \"\"\"Validate on validation set.\"\"\"\n",
        "\n",
        "  model.eval()\n",
        "  running_loss = 0.0\n",
        "  running_accuracy = 0.0\n",
        "  pbar = tqdm(total=len(dataloader.dataset), ncols=0, desc=\"Valid\", unit=\" uttr\", position=0, leave=True)\n",
        "\n",
        "  for i, batch in enumerate(dataloader):\n",
        "    with torch.no_grad():\n",
        "      loss, accuracy = model_fn(batch, model, criterion, device)\n",
        "      running_loss += loss.item()\n",
        "      running_accuracy += accuracy.item()\n",
        "\n",
        "    pbar.update(dataloader.batch_size)\n",
        "    pbar.set_postfix(\n",
        "      loss=f\"{running_loss / (i+1):.5f}\",\n",
        "      accuracy=f\"{running_accuracy / (i+1):.5f}\",\n",
        "    )\n",
        "\n",
        "  pbar.close()\n",
        "  model.train()\n",
        "\n",
        "  return running_accuracy / len(dataloader)\n"
      ],
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "noHXyal5p1W5"
      },
      "source": [
        "# Main function (Training)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "chRQE7oYtw62",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93b936f0-b59a-465a-bd54-298c794cd068"
      },
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.optim import AdamW\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from tqdm import tqdm\n",
        "\n",
        "def parse_args():\n",
        "  \"\"\"arguments\"\"\"\n",
        "  config = {\n",
        "    \"data_dir\": \"./Dataset\",\n",
        "      \"model_path\": CONFIG['MODEL_PATH'],\n",
        "    \"best_val_path\": CONFIG['BEST_VAL_PATH'],\n",
        "    \"batch_size\": 32,\n",
        "    \"n_workers\": 8,\n",
        "    \"valid_steps\": 2000,\n",
        "    \"warmup_steps\": 0,\n",
        "    \"save_steps\": 2000,\n",
        "    \"total_steps\": 200000,\n",
        "  }\n",
        "\n",
        "  return config\n",
        "\n",
        "\n",
        "def main(\n",
        "  data_dir,\n",
        "  model_path,\n",
        "  best_val_path,\n",
        "  batch_size,\n",
        "  n_workers,\n",
        "  valid_steps,\n",
        "  warmup_steps,\n",
        "  total_steps,\n",
        "  save_steps,\n",
        "):\n",
        "  \"\"\"Main function.\"\"\"\n",
        "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "  print(f\"[Info]: Use {device} now!\")\n",
        "\n",
        "  train_loader, valid_loader, speaker_num = get_dataloader(data_dir, batch_size, n_workers)\n",
        "  train_iterator = iter(train_loader)\n",
        "  print(f\"[Info]: Finish loading data!\",flush = True)\n",
        "\n",
        "  model = Classifier(n_spks=speaker_num).to(device)\n",
        "  if os.path.isfile(model_path):\n",
        "    print('loading previous model parameters...')\n",
        "    ckpt = torch.load(model_path, map_location='cpu')  # Load your best model\n",
        "    model.load_state_dict(ckpt)\n",
        "\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  optimizer = AdamW(model.parameters())\n",
        "  # scheduler = get_cosine_schedule_with_warmup(optimizer, warmup_steps, total_steps)\n",
        "  print(f\"[Info]: Finish creating model!\",flush = True)\n",
        "\n",
        "  best_accuracy = -1.0\n",
        "  best_state_dict = None\n",
        "  if os.path.isfile(best_val_path):\n",
        "    with open(best_val_path, 'r') as f:\n",
        "      best_accuracy = float(f.read())\n",
        "      print(f'best_accuracy: {best_accuracy}')\n",
        "\n",
        "  pbar = tqdm(total=valid_steps, ncols=0, desc=\"Train\", unit=\" step\", position=0, leave=True)\n",
        "\n",
        "  tot_batch_loss = 0\n",
        "  tot_batch_accuracy = 0\n",
        "  tot_step = 0\n",
        "  for step in range(total_steps):\n",
        "    # Get data\n",
        "    try:\n",
        "      batch = next(train_iterator)\n",
        "    except StopIteration:\n",
        "      train_iterator = iter(train_loader)\n",
        "      batch = next(train_iterator)\n",
        "\n",
        "    loss, accuracy = model_fn(batch, model, criterion, device)\n",
        "    batch_loss = loss.item()\n",
        "    batch_accuracy = accuracy.item()\n",
        "    tot_batch_loss += batch_loss\n",
        "    tot_batch_accuracy += batch_accuracy\n",
        "\n",
        "    # Updata model\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    # scheduler.step()\n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    # Log\n",
        "    tot_step += 1\n",
        "    pbar.update()\n",
        "    pbar.set_postfix(\n",
        "      loss=f\"{tot_batch_loss/tot_step:.5f}\",\n",
        "      accuracy=f\"{tot_batch_accuracy/tot_step:.5f}\",\n",
        "      step=step + 1,\n",
        "    )\n",
        "\n",
        "    # Do validation\n",
        "    if (step + 1) % valid_steps == 0:\n",
        "      tot_step = 0\n",
        "      tot_batch_loss = 0\n",
        "      tot_batch_accuracy = 0\n",
        "      pbar.close()\n",
        "\n",
        "      valid_accuracy = valid(valid_loader, model, criterion, device)\n",
        "\n",
        "      # keep the best model\n",
        "      if valid_accuracy > best_accuracy:\n",
        "        best_accuracy = valid_accuracy\n",
        "        best_state_dict = model.state_dict()\n",
        "\n",
        "      pbar = tqdm(total=valid_steps, ncols=0, desc=\"Train\", unit=\" step\", position=0, leave=True)\n",
        "\n",
        "    # Save the best model so far.\n",
        "    if (step + 1) % save_steps == 0 and best_state_dict is not None:\n",
        "      torch.save(best_state_dict, model_path)\n",
        "      with open(best_val_path, 'w') as f:\n",
        "        f.write(str(best_accuracy))\n",
        "\n",
        "      pbar.write(f\"Step {step + 1}, best model saved. (accuracy={best_accuracy:.4f})\")\n",
        "\n",
        "  pbar.close()\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  main(**parse_args())\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Info]: Use cuda now!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[Info]: Finish loading data!\n",
            "[Info]: Finish creating model!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [03:16<00:00, 10.20 step/s, accuracy=0.20425, loss=4.16756, step=2000]\n",
            "Valid: 100% 6944/6944 [00:27<00:00, 250.42 uttr/s, accuracy=0.38465, loss=2.80796]\n",
            "Train:   0% 4/2000 [00:00<12:35,  2.64 step/s, accuracy=0.31250, loss=3.06093, step=2004]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 2000, best model saved. (accuracy=0.3846)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [03:53<00:00,  8.58 step/s, accuracy=0.38453, loss=2.80420, step=4000]\n",
            "Valid: 100% 6944/6944 [00:27<00:00, 255.09 uttr/s, accuracy=0.52059, loss=2.10977]\n",
            "Train:   0% 4/2000 [00:00<05:16,  6.31 step/s, accuracy=0.42969, loss=2.50333, step=4004]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 4000, best model saved. (accuracy=0.5206)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [03:52<00:00,  8.60 step/s, accuracy=0.47725, loss=2.28857, step=6000]\n",
            "Valid: 100% 6944/6944 [00:26<00:00, 260.56 uttr/s, accuracy=0.58698, loss=1.77102]\n",
            "Train:   0% 4/2000 [00:00<04:56,  6.73 step/s, accuracy=0.50000, loss=1.95734, step=6004]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 6000, best model saved. (accuracy=0.5870)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [03:52<00:00,  8.60 step/s, accuracy=0.54444, loss=1.93624, step=8000]\n",
            "Valid: 100% 6944/6944 [00:27<00:00, 254.17 uttr/s, accuracy=0.64127, loss=1.51869]\n",
            "Train:   0% 4/2000 [00:00<05:05,  6.54 step/s, accuracy=0.57031, loss=1.80592, step=8004]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 8000, best model saved. (accuracy=0.6413)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [03:51<00:00,  8.66 step/s, accuracy=0.59391, loss=1.70232, step=1e+4]\n",
            "Valid: 100% 6944/6944 [00:27<00:00, 255.22 uttr/s, accuracy=0.68275, loss=1.30293]\n",
            "Train:   0% 4/2000 [00:00<05:12,  6.39 step/s, accuracy=0.65625, loss=1.55690, step=1e+4]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 10000, best model saved. (accuracy=0.6827)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [03:49<00:00,  8.72 step/s, accuracy=0.62917, loss=1.53534, step=12000]\n",
            "Valid: 100% 6944/6944 [00:27<00:00, 253.80 uttr/s, accuracy=0.71904, loss=1.17548]\n",
            "Train:   0% 4/2000 [00:00<05:46,  5.76 step/s, accuracy=0.67969, loss=1.20467, step=12004]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 12000, best model saved. (accuracy=0.7190)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [03:48<00:00,  8.74 step/s, accuracy=0.65750, loss=1.37767, step=14000]\n",
            "Valid: 100% 6944/6944 [00:27<00:00, 251.66 uttr/s, accuracy=0.73056, loss=1.10427]\n",
            "Train:   0% 4/2000 [00:00<04:59,  6.67 step/s, accuracy=0.66406, loss=1.40523, step=14004]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 14000, best model saved. (accuracy=0.7306)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [03:48<00:00,  8.75 step/s, accuracy=0.68237, loss=1.27835, step=16000]\n",
            "Valid: 100% 6944/6944 [00:27<00:00, 252.82 uttr/s, accuracy=0.75562, loss=1.02885]\n",
            "Train:   0% 4/2000 [00:00<04:59,  6.66 step/s, accuracy=0.77344, loss=1.02192, step=16004]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 16000, best model saved. (accuracy=0.7556)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [03:48<00:00,  8.77 step/s, accuracy=0.70220, loss=1.18921, step=18000]\n",
            "Valid: 100% 6944/6944 [00:28<00:00, 247.16 uttr/s, accuracy=0.77347, loss=0.93357]\n",
            "Train:   0% 4/2000 [00:00<04:55,  6.76 step/s, accuracy=0.77344, loss=0.82014, step=18004]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 18000, best model saved. (accuracy=0.7735)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [03:47<00:00,  8.78 step/s, accuracy=0.71931, loss=1.11660, step=2e+4]\n",
            "Valid: 100% 6944/6944 [00:27<00:00, 252.77 uttr/s, accuracy=0.79003, loss=0.86372]\n",
            "Train:   0% 4/2000 [00:00<05:12,  6.38 step/s, accuracy=0.77344, loss=0.85589, step=2e+4]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 20000, best model saved. (accuracy=0.7900)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [03:47<00:00,  8.78 step/s, accuracy=0.73459, loss=1.04107, step=22000]\n",
            "Valid: 100% 6944/6944 [00:28<00:00, 246.27 uttr/s, accuracy=0.79623, loss=0.83395]\n",
            "Train:   0% 4/2000 [00:00<04:53,  6.80 step/s, accuracy=0.67188, loss=1.44915, step=22004]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 22000, best model saved. (accuracy=0.7962)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [03:47<00:00,  8.81 step/s, accuracy=0.74509, loss=0.99208, step=24000]\n",
            "Valid: 100% 6944/6944 [00:27<00:00, 252.05 uttr/s, accuracy=0.79493, loss=0.82355]\n",
            "Train:   0% 5/2000 [00:00<04:55,  6.76 step/s, accuracy=0.75625, loss=1.03382, step=24005]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 24000, best model saved. (accuracy=0.7962)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [03:46<00:00,  8.84 step/s, accuracy=0.75820, loss=0.93970, step=26000]\n",
            "Valid: 100% 6944/6944 [00:28<00:00, 242.14 uttr/s, accuracy=0.81639, loss=0.73942]\n",
            "Train:   0% 5/2000 [00:00<05:18,  6.26 step/s, accuracy=0.78750, loss=0.75185, step=26005]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 26000, best model saved. (accuracy=0.8164)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [03:46<00:00,  8.83 step/s, accuracy=0.76552, loss=0.90075, step=28000]\n",
            "Valid: 100% 6944/6944 [00:28<00:00, 244.56 uttr/s, accuracy=0.82560, loss=0.72453]\n",
            "Train:   0% 4/2000 [00:00<05:21,  6.21 step/s, accuracy=0.71875, loss=1.03268, step=28004]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 28000, best model saved. (accuracy=0.8256)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [03:46<00:00,  8.81 step/s, accuracy=0.77722, loss=0.86479, step=3e+4]\n",
            "Valid: 100% 6944/6944 [00:27<00:00, 249.06 uttr/s, accuracy=0.82560, loss=0.71800]\n",
            "Train:   0% 5/2000 [00:00<05:42,  5.82 step/s, accuracy=0.76250, loss=0.77052, step=3e+4]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 30000, best model saved. (accuracy=0.8256)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [03:42<00:00,  8.99 step/s, accuracy=0.78464, loss=0.82605, step=32000]\n",
            "Valid: 100% 6944/6944 [00:28<00:00, 241.81 uttr/s, accuracy=0.83007, loss=0.69448]\n",
            "Train:   0% 4/2000 [00:00<05:00,  6.64 step/s, accuracy=0.75000, loss=0.72662, step=32004]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 32000, best model saved. (accuracy=0.8301)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [03:43<00:00,  8.94 step/s, accuracy=0.79539, loss=0.77862, step=34000]\n",
            "Valid: 100% 6944/6944 [00:29<00:00, 237.18 uttr/s, accuracy=0.83396, loss=0.68939]\n",
            "Train:   0% 4/2000 [00:00<05:02,  6.59 step/s, accuracy=0.78125, loss=0.87091, step=34004]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 34000, best model saved. (accuracy=0.8340)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [03:42<00:00,  8.99 step/s, accuracy=0.79622, loss=0.77661, step=36000]\n",
            "Valid: 100% 6944/6944 [00:29<00:00, 237.36 uttr/s, accuracy=0.84317, loss=0.65618]\n",
            "Train:   0% 5/2000 [00:00<05:01,  6.62 step/s, accuracy=0.83750, loss=0.57472, step=36005]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 36000, best model saved. (accuracy=0.8432)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [03:40<00:00,  9.07 step/s, accuracy=0.80444, loss=0.73833, step=38000]\n",
            "Valid: 100% 6944/6944 [00:29<00:00, 238.24 uttr/s, accuracy=0.84159, loss=0.64788]\n",
            "Train:   0% 5/2000 [00:00<05:12,  6.39 step/s, accuracy=0.82500, loss=0.68187, step=38005]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 38000, best model saved. (accuracy=0.8432)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [03:39<00:00,  9.10 step/s, accuracy=0.80894, loss=0.72144, step=4e+4]\n",
            "Valid: 100% 6944/6944 [00:29<00:00, 237.32 uttr/s, accuracy=0.85325, loss=0.62376]\n",
            "Train:   0% 4/2000 [00:00<05:27,  6.09 step/s, accuracy=0.78125, loss=0.64880, step=4e+4]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 40000, best model saved. (accuracy=0.8533)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [03:39<00:00,  9.10 step/s, accuracy=0.81183, loss=0.70415, step=42000]\n",
            "Valid: 100% 6944/6944 [00:28<00:00, 241.51 uttr/s, accuracy=0.85757, loss=0.59540]\n",
            "Train:   0% 4/2000 [00:00<05:47,  5.75 step/s, accuracy=0.78906, loss=0.85606, step=42004]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 42000, best model saved. (accuracy=0.8576)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [03:38<00:00,  9.17 step/s, accuracy=0.81969, loss=0.67809, step=44000]\n",
            "Valid: 100% 6944/6944 [00:28<00:00, 241.58 uttr/s, accuracy=0.86247, loss=0.58195]\n",
            "Train:   0% 4/2000 [00:00<05:26,  6.12 step/s, accuracy=0.82812, loss=0.68309, step=44004]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 44000, best model saved. (accuracy=0.8625)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [03:38<00:00,  9.14 step/s, accuracy=0.82325, loss=0.65546, step=46000]\n",
            "Valid: 100% 6944/6944 [00:30<00:00, 228.59 uttr/s, accuracy=0.85426, loss=0.59459]\n",
            "Train:   0% 4/2000 [00:00<07:23,  4.50 step/s, accuracy=0.84375, loss=0.70388, step=46004]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 46000, best model saved. (accuracy=0.8625)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [03:36<00:00,  9.22 step/s, accuracy=0.82684, loss=0.64435, step=48000]\n",
            "Valid: 100% 6944/6944 [00:30<00:00, 227.85 uttr/s, accuracy=0.86550, loss=0.56383]\n",
            "Train:   0% 4/2000 [00:00<06:37,  5.02 step/s, accuracy=0.85156, loss=0.56842, step=48004]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 48000, best model saved. (accuracy=0.8655)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [03:37<00:00,  9.21 step/s, accuracy=0.83123, loss=0.62806, step=5e+4]\n",
            "Valid: 100% 6944/6944 [00:30<00:00, 227.39 uttr/s, accuracy=0.86161, loss=0.57031]\n",
            "Train:   0% 4/2000 [00:00<07:34,  4.39 step/s, accuracy=0.84375, loss=0.59801, step=5e+4]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 50000, best model saved. (accuracy=0.8655)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [03:39<00:00,  9.12 step/s, accuracy=0.83466, loss=0.61030, step=52000]\n",
            "Valid: 100% 6944/6944 [00:29<00:00, 232.30 uttr/s, accuracy=0.87010, loss=0.55063]\n",
            "Train:   0% 4/2000 [00:00<07:44,  4.30 step/s, accuracy=0.83594, loss=0.59813, step=52004]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 52000, best model saved. (accuracy=0.8701)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [03:42<00:00,  8.99 step/s, accuracy=0.84186, loss=0.58991, step=54000]\n",
            "Valid: 100% 6944/6944 [00:30<00:00, 228.74 uttr/s, accuracy=0.87442, loss=0.51337]\n",
            "Train:   0% 4/2000 [00:00<07:02,  4.73 step/s, accuracy=0.81250, loss=0.61904, step=54004]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 54000, best model saved. (accuracy=0.8744)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [03:43<00:00,  8.95 step/s, accuracy=0.83916, loss=0.59852, step=56000]\n",
            "Valid: 100% 6944/6944 [00:30<00:00, 228.46 uttr/s, accuracy=0.86722, loss=0.55675]\n",
            "Train:   0% 4/2000 [00:00<07:28,  4.45 step/s, accuracy=0.81250, loss=0.62900, step=56004]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 56000, best model saved. (accuracy=0.8744)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [03:44<00:00,  8.90 step/s, accuracy=0.84523, loss=0.57350, step=58000]\n",
            "Valid: 100% 6944/6944 [00:29<00:00, 233.50 uttr/s, accuracy=0.87716, loss=0.52609]\n",
            "Train:   0% 4/2000 [00:00<07:43,  4.31 step/s, accuracy=0.82031, loss=0.65003, step=58004]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 58000, best model saved. (accuracy=0.8772)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [03:45<00:00,  8.86 step/s, accuracy=0.84564, loss=0.56740, step=6e+4]\n",
            "Valid: 100% 6944/6944 [00:30<00:00, 228.31 uttr/s, accuracy=0.87198, loss=0.54547]\n",
            "Train:   0% 4/2000 [00:00<06:12,  5.37 step/s, accuracy=0.86719, loss=0.48727, step=6e+4]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 60000, best model saved. (accuracy=0.8772)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [03:46<00:00,  8.82 step/s, accuracy=0.85130, loss=0.54608, step=62000]\n",
            "Valid: 100% 6944/6944 [00:29<00:00, 234.11 uttr/s, accuracy=0.87918, loss=0.50224]\n",
            "Train:   0% 4/2000 [00:00<07:03,  4.72 step/s, accuracy=0.89062, loss=0.36236, step=62004]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 62000, best model saved. (accuracy=0.8792)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [03:50<00:00,  8.68 step/s, accuracy=0.85027, loss=0.54465, step=64000]\n",
            "Valid: 100% 6944/6944 [00:29<00:00, 236.25 uttr/s, accuracy=0.88018, loss=0.49406]\n",
            "Train:   0% 4/2000 [00:00<07:37,  4.37 step/s, accuracy=0.81250, loss=0.77562, step=64004]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 64000, best model saved. (accuracy=0.8802)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [03:51<00:00,  8.66 step/s, accuracy=0.85166, loss=0.54152, step=66000]\n",
            "Valid: 100% 6944/6944 [00:29<00:00, 234.73 uttr/s, accuracy=0.87442, loss=0.51111]\n",
            "Train:   0% 4/2000 [00:00<06:58,  4.77 step/s, accuracy=0.89062, loss=0.43548, step=66004]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 66000, best model saved. (accuracy=0.8802)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [03:52<00:00,  8.59 step/s, accuracy=0.85817, loss=0.51991, step=68000]\n",
            "Valid: 100% 6944/6944 [00:29<00:00, 237.69 uttr/s, accuracy=0.87946, loss=0.50964]\n",
            "Train:   0% 4/2000 [00:00<07:28,  4.45 step/s, accuracy=0.84375, loss=0.57728, step=68004]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 68000, best model saved. (accuracy=0.8802)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [03:53<00:00,  8.55 step/s, accuracy=0.85809, loss=0.51437, step=7e+4]\n",
            "Valid: 100% 6944/6944 [00:29<00:00, 232.18 uttr/s, accuracy=0.88378, loss=0.48784]\n",
            "Train:   0% 4/2000 [00:00<08:35,  3.87 step/s, accuracy=0.78125, loss=0.69507, step=7e+4]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 70000, best model saved. (accuracy=0.8838)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [03:56<00:00,  8.47 step/s, accuracy=0.86119, loss=0.50855, step=72000]\n",
            "Valid: 100% 6944/6944 [00:29<00:00, 236.42 uttr/s, accuracy=0.87817, loss=0.50714]\n",
            "Train:   0% 4/2000 [00:00<07:29,  4.44 step/s, accuracy=0.86719, loss=0.45456, step=72004]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 72000, best model saved. (accuracy=0.8838)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [03:56<00:00,  8.47 step/s, accuracy=0.86253, loss=0.50033, step=74000]\n",
            "Valid: 100% 6944/6944 [00:29<00:00, 237.88 uttr/s, accuracy=0.87961, loss=0.48919]\n",
            "Train:   0% 4/2000 [00:00<07:55,  4.20 step/s, accuracy=0.83594, loss=0.54612, step=74004]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 74000, best model saved. (accuracy=0.8838)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [03:57<00:00,  8.42 step/s, accuracy=0.86453, loss=0.49207, step=76000]\n",
            "Valid: 100% 6944/6944 [00:29<00:00, 235.79 uttr/s, accuracy=0.88753, loss=0.48502]\n",
            "Train:   0% 4/2000 [00:00<07:15,  4.58 step/s, accuracy=0.84375, loss=0.66413, step=76004]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 76000, best model saved. (accuracy=0.8875)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [03:57<00:00,  8.43 step/s, accuracy=0.86662, loss=0.48256, step=78000]\n",
            "Valid: 100% 6944/6944 [00:28<00:00, 243.83 uttr/s, accuracy=0.88321, loss=0.49195]\n",
            "Train:   0% 4/2000 [00:00<08:29,  3.92 step/s, accuracy=0.82812, loss=0.60741, step=78004]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 78000, best model saved. (accuracy=0.8875)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [03:57<00:00,  8.42 step/s, accuracy=0.86595, loss=0.48780, step=8e+4]\n",
            "Valid: 100% 6944/6944 [00:29<00:00, 239.26 uttr/s, accuracy=0.88393, loss=0.49070]\n",
            "Train:   0% 5/2000 [00:00<08:04,  4.12 step/s, accuracy=0.80000, loss=0.71149, step=8e+4]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 80000, best model saved. (accuracy=0.8875)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [03:57<00:00,  8.43 step/s, accuracy=0.86762, loss=0.47802, step=82000]\n",
            "Valid: 100% 6944/6944 [00:27<00:00, 254.68 uttr/s, accuracy=0.88695, loss=0.47241]\n",
            "Train:   0% 4/2000 [00:00<06:02,  5.50 step/s, accuracy=0.85938, loss=0.42395, step=82004]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 82000, best model saved. (accuracy=0.8875)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [03:57<00:00,  8.44 step/s, accuracy=0.86997, loss=0.47295, step=84000]\n",
            "Valid: 100% 6944/6944 [00:26<00:00, 258.44 uttr/s, accuracy=0.88522, loss=0.47621]\n",
            "Train:   0% 4/2000 [00:00<05:44,  5.80 step/s, accuracy=0.88281, loss=0.62506, step=84004]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 84000, best model saved. (accuracy=0.8875)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [03:57<00:00,  8.44 step/s, accuracy=0.87052, loss=0.46926, step=86000]\n",
            "Valid: 100% 6944/6944 [00:28<00:00, 247.58 uttr/s, accuracy=0.88335, loss=0.47422]\n",
            "Train:   0% 4/2000 [00:00<05:40,  5.86 step/s, accuracy=0.92969, loss=0.34294, step=86004]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 86000, best model saved. (accuracy=0.8875)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [03:56<00:00,  8.45 step/s, accuracy=0.87425, loss=0.45513, step=88000]\n",
            "Valid: 100% 6944/6944 [00:27<00:00, 254.21 uttr/s, accuracy=0.88666, loss=0.47441]\n",
            "Train:   0% 4/2000 [00:00<05:20,  6.23 step/s, accuracy=0.88281, loss=0.40947, step=88004]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 88000, best model saved. (accuracy=0.8875)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [03:56<00:00,  8.45 step/s, accuracy=0.87503, loss=0.45117, step=9e+4]\n",
            "Valid: 100% 6944/6944 [00:27<00:00, 249.64 uttr/s, accuracy=0.89516, loss=0.44430]\n",
            "Train:   0% 4/2000 [00:00<05:51,  5.68 step/s, accuracy=0.94531, loss=0.27336, step=9e+4]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 90000, best model saved. (accuracy=0.8952)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [03:56<00:00,  8.47 step/s, accuracy=0.87513, loss=0.44815, step=92000]\n",
            "Valid: 100% 6944/6944 [00:28<00:00, 240.10 uttr/s, accuracy=0.89545, loss=0.42761]\n",
            "Train:   0% 4/2000 [00:00<05:31,  6.02 step/s, accuracy=0.91406, loss=0.30177, step=92004]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 92000, best model saved. (accuracy=0.8954)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [03:56<00:00,  8.44 step/s, accuracy=0.87709, loss=0.44495, step=94000]\n",
            "Valid: 100% 6944/6944 [00:28<00:00, 244.66 uttr/s, accuracy=0.88436, loss=0.47697]\n",
            "Train:   0% 4/2000 [00:01<22:36,  1.47 step/s, accuracy=0.89844, loss=0.36272, step=94004]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 94000, best model saved. (accuracy=0.8954)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [03:56<00:00,  8.47 step/s, accuracy=0.87944, loss=0.43608, step=96000]\n",
            "Valid: 100% 6944/6944 [00:28<00:00, 241.25 uttr/s, accuracy=0.88998, loss=0.46385]\n",
            "Train:   0% 4/2000 [00:00<06:47,  4.90 step/s, accuracy=0.85156, loss=0.46828, step=96004]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 96000, best model saved. (accuracy=0.8954)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [03:55<00:00,  8.49 step/s, accuracy=0.87995, loss=0.43247, step=98000]\n",
            "Valid: 100% 6944/6944 [00:28<00:00, 243.08 uttr/s, accuracy=0.89099, loss=0.45692]\n",
            "Train:   0% 4/2000 [00:00<05:47,  5.75 step/s, accuracy=0.87500, loss=0.46707, step=98004]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 98000, best model saved. (accuracy=0.8954)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [03:53<00:00,  8.57 step/s, accuracy=0.87820, loss=0.43507, step=1e+5]\n",
            "Valid: 100% 6944/6944 [00:28<00:00, 246.36 uttr/s, accuracy=0.89055, loss=0.46881]\n",
            "Train:   0% 4/2000 [00:00<05:19,  6.25 step/s, accuracy=0.91406, loss=0.29560, step=1e+5]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 100000, best model saved. (accuracy=0.8954)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [03:53<00:00,  8.57 step/s, accuracy=0.88222, loss=0.42332, step=102000]\n",
            "Valid: 100% 6944/6944 [00:28<00:00, 242.41 uttr/s, accuracy=0.89372, loss=0.45005]\n",
            "Train:   0% 4/2000 [00:00<04:59,  6.67 step/s, accuracy=0.90625, loss=0.39642, step=102004]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 102000, best model saved. (accuracy=0.8954)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [03:52<00:00,  8.58 step/s, accuracy=0.88462, loss=0.41402, step=104000]\n",
            "Valid: 100% 6944/6944 [00:29<00:00, 233.52 uttr/s, accuracy=0.89574, loss=0.44676]\n",
            "Train:   0% 4/2000 [00:00<05:24,  6.14 step/s, accuracy=0.88281, loss=0.38115, step=104004]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 104000, best model saved. (accuracy=0.8957)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [03:53<00:00,  8.58 step/s, accuracy=0.88348, loss=0.41749, step=106000]\n",
            "Valid: 100% 6944/6944 [00:29<00:00, 235.63 uttr/s, accuracy=0.89905, loss=0.43146]\n",
            "Train:   0% 4/2000 [00:00<05:04,  6.56 step/s, accuracy=0.85156, loss=0.40832, step=106004]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 106000, best model saved. (accuracy=0.8990)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [03:51<00:00,  8.62 step/s, accuracy=0.88255, loss=0.41961, step=108000]\n",
            "Valid: 100% 6944/6944 [00:29<00:00, 235.36 uttr/s, accuracy=0.90092, loss=0.43305]\n",
            "Train:   0% 4/2000 [00:00<05:28,  6.08 step/s, accuracy=0.89844, loss=0.28487, step=108004]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 108000, best model saved. (accuracy=0.9009)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [03:52<00:00,  8.59 step/s, accuracy=0.88300, loss=0.41676, step=110000]\n",
            "Valid: 100% 6944/6944 [00:29<00:00, 238.97 uttr/s, accuracy=0.89401, loss=0.44960]\n",
            "Train:   0% 3/2000 [00:00<07:13,  4.61 step/s, accuracy=0.87500, loss=0.39825, step=110003]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 110000, best model saved. (accuracy=0.9009)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [03:52<00:00,  8.61 step/s, accuracy=0.88648, loss=0.40708, step=112000]\n",
            "Valid: 100% 6944/6944 [00:29<00:00, 231.58 uttr/s, accuracy=0.90135, loss=0.42426]\n",
            "Train:   0% 4/2000 [00:01<23:06,  1.44 step/s, accuracy=0.89062, loss=0.40884, step=112004]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 112000, best model saved. (accuracy=0.9014)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [03:52<00:00,  8.62 step/s, accuracy=0.88492, loss=0.40806, step=114000]\n",
            "Valid: 100% 6944/6944 [00:30<00:00, 230.14 uttr/s, accuracy=0.89862, loss=0.43007]\n",
            "Train:   0% 4/2000 [00:00<05:50,  5.70 step/s, accuracy=0.83594, loss=0.60916, step=114004]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 114000, best model saved. (accuracy=0.9014)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [03:51<00:00,  8.64 step/s, accuracy=0.88702, loss=0.40335, step=116000]\n",
            "Valid: 100% 6944/6944 [00:30<00:00, 229.44 uttr/s, accuracy=0.89559, loss=0.43832]\n",
            "Train:   0% 4/2000 [00:00<05:43,  5.80 step/s, accuracy=0.84375, loss=0.58772, step=116004]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 116000, best model saved. (accuracy=0.9014)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [03:48<00:00,  8.75 step/s, accuracy=0.88966, loss=0.39374, step=118000]\n",
            "Valid: 100% 6944/6944 [00:30<00:00, 224.62 uttr/s, accuracy=0.89689, loss=0.42935]\n",
            "Train:   0% 4/2000 [00:00<05:21,  6.20 step/s, accuracy=0.87500, loss=0.35571, step=118004]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 118000, best model saved. (accuracy=0.9014)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [03:47<00:00,  8.78 step/s, accuracy=0.88873, loss=0.39608, step=120000]\n",
            "Valid: 100% 6944/6944 [00:30<00:00, 227.06 uttr/s, accuracy=0.89271, loss=0.44252]\n",
            "Train:   0% 4/2000 [00:00<08:28,  3.93 step/s, accuracy=0.85156, loss=0.54777, step=120004]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 120000, best model saved. (accuracy=0.9014)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [03:49<00:00,  8.73 step/s, accuracy=0.88894, loss=0.38867, step=122000]\n",
            "Valid: 100% 6944/6944 [00:30<00:00, 226.70 uttr/s, accuracy=0.90020, loss=0.42911]\n",
            "Train:   0% 4/2000 [00:00<06:16,  5.30 step/s, accuracy=0.91406, loss=0.39054, step=122004]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 122000, best model saved. (accuracy=0.9014)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [03:48<00:00,  8.73 step/s, accuracy=0.88933, loss=0.39268, step=124000]\n",
            "Valid: 100% 6944/6944 [00:31<00:00, 217.13 uttr/s, accuracy=0.89891, loss=0.43259]\n",
            "Train:   0% 5/2000 [00:00<06:11,  5.37 step/s, accuracy=0.86250, loss=0.44853, step=124005]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 124000, best model saved. (accuracy=0.9014)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [03:48<00:00,  8.77 step/s, accuracy=0.89089, loss=0.39116, step=126000]\n",
            "Valid: 100% 6944/6944 [00:31<00:00, 223.39 uttr/s, accuracy=0.90611, loss=0.41337]\n",
            "Train:   0% 4/2000 [00:00<07:53,  4.22 step/s, accuracy=0.90625, loss=0.33887, step=126004]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 126000, best model saved. (accuracy=0.9061)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [03:47<00:00,  8.78 step/s, accuracy=0.89095, loss=0.38548, step=128000]\n",
            "Valid: 100% 6944/6944 [00:30<00:00, 228.52 uttr/s, accuracy=0.90783, loss=0.41017]\n",
            "Train:   0% 4/2000 [00:00<06:50,  4.86 step/s, accuracy=0.91406, loss=0.37385, step=128004]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 128000, best model saved. (accuracy=0.9078)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [03:47<00:00,  8.80 step/s, accuracy=0.89575, loss=0.37338, step=130000]\n",
            "Valid: 100% 6944/6944 [00:30<00:00, 226.54 uttr/s, accuracy=0.90207, loss=0.43806]\n",
            "Train:   0% 4/2000 [00:00<06:45,  4.92 step/s, accuracy=0.87500, loss=0.47300, step=130004]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 130000, best model saved. (accuracy=0.9078)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [03:50<00:00,  8.67 step/s, accuracy=0.89212, loss=0.37990, step=132000]\n",
            "Valid: 100% 6944/6944 [00:30<00:00, 224.73 uttr/s, accuracy=0.89862, loss=0.43244]\n",
            "Train:   0% 4/2000 [00:00<08:02,  4.14 step/s, accuracy=0.91406, loss=0.30290, step=132004]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 132000, best model saved. (accuracy=0.9078)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [03:49<00:00,  8.70 step/s, accuracy=0.89508, loss=0.37201, step=134000]\n",
            "Valid: 100% 6944/6944 [00:31<00:00, 222.65 uttr/s, accuracy=0.89977, loss=0.42320]\n",
            "Train:   0% 4/2000 [00:00<07:24,  4.49 step/s, accuracy=0.89062, loss=0.37686, step=134004]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 134000, best model saved. (accuracy=0.9078)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [03:51<00:00,  8.66 step/s, accuracy=0.89164, loss=0.38548, step=136000]\n",
            "Valid: 100% 6944/6944 [00:31<00:00, 220.70 uttr/s, accuracy=0.90740, loss=0.38159]\n",
            "Train:   0% 4/2000 [00:00<06:07,  5.43 step/s, accuracy=0.92188, loss=0.32327, step=136004]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 136000, best model saved. (accuracy=0.9078)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [03:51<00:00,  8.63 step/s, accuracy=0.89509, loss=0.37244, step=138000]\n",
            "Valid: 100% 6944/6944 [00:31<00:00, 223.77 uttr/s, accuracy=0.90711, loss=0.40077]\n",
            "Train:   0% 4/2000 [00:00<08:50,  3.76 step/s, accuracy=0.85938, loss=0.56201, step=138004]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 138000, best model saved. (accuracy=0.9078)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [03:52<00:00,  8.60 step/s, accuracy=0.89328, loss=0.37604, step=140000]\n",
            "Valid: 100% 6944/6944 [00:31<00:00, 220.77 uttr/s, accuracy=0.90179, loss=0.41712]\n",
            "Train:   0% 4/2000 [00:00<06:44,  4.93 step/s, accuracy=0.91406, loss=0.41098, step=140004]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 140000, best model saved. (accuracy=0.9078)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [03:56<00:00,  8.44 step/s, accuracy=0.89578, loss=0.37212, step=142000]\n",
            "Valid: 100% 6944/6944 [00:30<00:00, 226.90 uttr/s, accuracy=0.90207, loss=0.40119]\n",
            "Train:   0% 4/2000 [00:00<10:57,  3.03 step/s, accuracy=0.82031, loss=0.56154, step=142004]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 142000, best model saved. (accuracy=0.9078)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [03:57<00:00,  8.43 step/s, accuracy=0.89686, loss=0.36175, step=144000]\n",
            "Valid: 100% 6944/6944 [00:31<00:00, 221.91 uttr/s, accuracy=0.90827, loss=0.38829]\n",
            "Train:   0% 4/2000 [00:00<06:21,  5.23 step/s, accuracy=0.89062, loss=0.42174, step=144004]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 144000, best model saved. (accuracy=0.9083)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [03:59<00:00,  8.36 step/s, accuracy=0.89427, loss=0.37449, step=146000]\n",
            "Valid: 100% 6944/6944 [00:30<00:00, 229.76 uttr/s, accuracy=0.90683, loss=0.39697]\n",
            "Train:   0% 4/2000 [00:00<10:06,  3.29 step/s, accuracy=0.84375, loss=0.46878, step=146004]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 146000, best model saved. (accuracy=0.9083)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [04:01<00:00,  8.27 step/s, accuracy=0.89703, loss=0.36235, step=148000]\n",
            "Valid: 100% 6944/6944 [00:30<00:00, 227.32 uttr/s, accuracy=0.90495, loss=0.39575]\n",
            "Train:   0% 4/2000 [00:00<06:15,  5.32 step/s, accuracy=0.92188, loss=0.32398, step=148004]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 148000, best model saved. (accuracy=0.9083)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [04:02<00:00,  8.26 step/s, accuracy=0.89847, loss=0.36120, step=150000]\n",
            "Valid: 100% 6944/6944 [00:30<00:00, 231.10 uttr/s, accuracy=0.89919, loss=0.41564]\n",
            "Train:   0% 2/2000 [00:00<15:48,  2.11 step/s, accuracy=0.81250, loss=0.51498, step=150002]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 150000, best model saved. (accuracy=0.9083)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [04:03<00:00,  8.20 step/s, accuracy=0.89905, loss=0.35819, step=152000]\n",
            "Valid: 100% 6944/6944 [00:30<00:00, 230.36 uttr/s, accuracy=0.90092, loss=0.42006]\n",
            "Train:   0% 4/2000 [00:00<05:58,  5.57 step/s, accuracy=0.89062, loss=0.35275, step=152004]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 152000, best model saved. (accuracy=0.9083)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [04:04<00:00,  8.18 step/s, accuracy=0.89938, loss=0.35719, step=154000]\n",
            "Valid: 100% 6944/6944 [00:30<00:00, 228.42 uttr/s, accuracy=0.89876, loss=0.42008]\n",
            "Train:   0% 4/2000 [00:00<10:38,  3.13 step/s, accuracy=0.89844, loss=0.34157, step=154004]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 154000, best model saved. (accuracy=0.9083)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [04:05<00:00,  8.16 step/s, accuracy=0.89694, loss=0.36208, step=156000]\n",
            "Valid: 100% 6944/6944 [00:29<00:00, 232.80 uttr/s, accuracy=0.90567, loss=0.40455]\n",
            "Train:   0% 3/2000 [00:00<09:45,  3.41 step/s, accuracy=0.90625, loss=0.34871, step=156003]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 156000, best model saved. (accuracy=0.9083)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [04:04<00:00,  8.20 step/s, accuracy=0.90075, loss=0.34565, step=158000]\n",
            "Valid: 100% 6944/6944 [00:30<00:00, 230.49 uttr/s, accuracy=0.90639, loss=0.40398]\n",
            "Train:   0% 4/2000 [00:01<28:16,  1.18 step/s, accuracy=0.89062, loss=0.37750, step=158004]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 158000, best model saved. (accuracy=0.9083)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [04:06<00:00,  8.10 step/s, accuracy=0.89942, loss=0.35337, step=160000]\n",
            "Valid: 100% 6944/6944 [00:29<00:00, 233.31 uttr/s, accuracy=0.90495, loss=0.41157]\n",
            "Train:   0% 4/2000 [00:00<06:44,  4.94 step/s, accuracy=0.89844, loss=0.46231, step=160004]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 160000, best model saved. (accuracy=0.9083)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Train:  92% 1846/2000 [03:47<00:22,  6.74 step/s, accuracy=0.90037, loss=0.35240, step=161845]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0R2rx3AyHpQ-"
      },
      "source": [
        "# Inference (Testing)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pSuI3WY9Fz78"
      },
      "source": [
        "## Dataset of inference (Testing)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4evns0055Dsx"
      },
      "source": [
        "import os\n",
        "import json\n",
        "import torch\n",
        "from pathlib import Path\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class InferenceDataset(Dataset):\n",
        "  def __init__(self, data_dir):\n",
        "    testdata_path = Path(data_dir) / \"testdata.json\"\n",
        "    metadata = json.load(testdata_path.open())\n",
        "    self.data_dir = data_dir\n",
        "    self.data = metadata[\"utterances\"]\n",
        "    self.segment_len = CONFIG['SEGMENT_LEN']\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    utterance = self.data[index]\n",
        "    feat_path = utterance[\"feature_path\"]\n",
        "    mel = torch.load(os.path.join(self.data_dir, feat_path))\n",
        "\n",
        "    if len(mel) < self.segment_len:\n",
        "      mel_new = torch.zeros(self.segment_len, 40)\n",
        "      mel_new[:mel.shape[0], :40] = mel\n",
        "      mel = mel_new\n",
        "      mel = torch.FloatTensor(mel)\n",
        "\n",
        "    return feat_path, mel\n",
        "\n",
        "\n",
        "def inference_collate_batch(batch):\n",
        "  \"\"\"Collate a batch of data.\"\"\"\n",
        "  feat_paths, mels = zip(*batch)\n",
        "\n",
        "  return feat_paths, torch.stack(mels)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oAinHBG1GIWv"
      },
      "source": [
        "## Main funcrion of Inference (Testing)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQaTt7VDHoRI"
      },
      "source": [
        "import json\n",
        "import csv\n",
        "from pathlib import Path\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "def parse_args():\n",
        "  \"\"\"arguments\"\"\"\n",
        "  config = {\n",
        "    \"data_dir\": \"./Dataset\",\n",
        "    \"model_path\": CONFIG['MODEL_PATH'],\n",
        "    \"output_path\": \"./output.csv\",\n",
        "  }\n",
        "\n",
        "  return config\n",
        "\n",
        "def main(\n",
        "  data_dir,\n",
        "  model_path,\n",
        "  output_path,\n",
        "):\n",
        "  \"\"\"Main function.\"\"\"\n",
        "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "  print(f\"[Info]: Use {device} now!\")\n",
        "\n",
        "  mapping_path = Path(data_dir) / \"mapping.json\"\n",
        "  mapping = json.load(mapping_path.open())\n",
        "\n",
        "  dataset = InferenceDataset(data_dir)\n",
        "  dataloader = DataLoader(\n",
        "    dataset,\n",
        "    batch_size=1,\n",
        "    shuffle=False,\n",
        "    drop_last=False,\n",
        "    num_workers=8,\n",
        "    collate_fn=inference_collate_batch,\n",
        "  )\n",
        "  print(f\"[Info]: Finish loading data!\",flush = True)\n",
        "\n",
        "  speaker_num = len(mapping[\"id2speaker\"])\n",
        "  model = Classifier(n_spks=speaker_num).to(device)\n",
        "  model.zeros = model.zeros.to(device)\n",
        "  model.load_state_dict(torch.load(model_path))\n",
        "  model.eval()\n",
        "  print(f\"[Info]: Finish creating model!\",flush = True)\n",
        "\n",
        "  results = [[\"Id\", \"Category\"]]\n",
        "  for feat_paths, mels in tqdm(dataloader):\n",
        "    with torch.no_grad():\n",
        "      mels = mels.to(device)\n",
        "      outs = model(mels)\n",
        "      preds = outs.argmax(1).cpu().numpy()\n",
        "      for feat_path, pred in zip(feat_paths, preds):\n",
        "        results.append([feat_path, mapping[\"id2speaker\"][str(pred)]])\n",
        "  \n",
        "  with open(output_path, 'w', newline='') as csvfile:\n",
        "    writer = csv.writer(csvfile)\n",
        "    writer.writerows(results)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  main(**parse_args())\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}