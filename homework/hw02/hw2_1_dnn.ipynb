{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Copy_of_HW2_1_ver5.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OYlaRwNu7ojq"
      },
      "source": [
        "# **Homework 2-1 Phoneme Classification**"
      ]
    },
    {
      "source": [
        "## The DARPA TIMIT Acoustic-Phonetic Continuous Speech Corpus (TIMIT)\n",
        "The TIMIT corpus of reading speech has been designed to provide speech data for the acquisition of acoustic-phonetic knowledge and for the development and evaluation of automatic speech recognition systems.\n",
        "\n",
        "This homework is a multiclass classification task, \n",
        "we are going to train a deep neural network classifier to predict the phonemes for each frame from the speech corpus TIMIT.\n",
        "\n",
        "link: https://academictorrents.com/details/34e2b78745138186976cbc27939b1b34d18bd5b3"
      ],
      "cell_type": "markdown",
      "metadata": {
        "id": "emUd7uS7crTz"
      }
    },
    {
      "source": [
        "## Initialize"
      ],
      "cell_type": "markdown",
      "metadata": {
        "id": "FVqF2w3bFgJa"
      }
    },
    {
      "source": [
        "%reset -f"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "EzNp7OuDFf0v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KVUGfWTo7_Oj"
      },
      "source": [
        "## Download Data\n",
        "Download data from google drive, then unzip it.\n",
        "\n",
        "You should have `timit_11/train_11.npy`, `timit_11/train_label_11.npy`, and `timit_11/test_11.npy` after running this block.<br><br>\n",
        "`timit_11/`\n",
        "- `train_11.npy`: training data<br>\n",
        "- `train_label_11.npy`: training label<br>\n",
        "- `test_11.npy`:  testing data<br><br>\n",
        "\n",
        "**notes: if the google drive link is dead, you can download the data directly from Kaggle and upload it to the workspace**\n",
        "\n",
        "\n"
      ]
    },
    {
      "source": [
        "# !gdown --id '1HPkcmQmFGu-3OknddKIa5dNDsR05lIQR' --output data.zip\n",
        "# !unzip data.zip\n",
        "# !ls \n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OzkiMEcC3Foq",
        "outputId": "b29a5480-adfe-4506-d28f-c7c54d206304"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_L_4anls8Drv"
      },
      "source": [
        "## Preparing Data\n",
        "Load the training and testing data from the `.npy` file (NumPy array)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJjLT8em-y9G"
      },
      "source": [
        "from sklearn import preprocessing\n",
        "import numpy as np\n",
        "import gc\n",
        "\n",
        "class DataManager():\n",
        "    def getTrainData(self):\n",
        "        print('Loading data ...')\n",
        "        \n",
        "        data_root='gdrive/MyDrive/Colab Notebooks/HW2/HW2-1/timit_11/'\n",
        "        train = np.load(data_root + 'train_11.npy')\n",
        "        train_label = np.load(data_root + 'train_label_11.npy')\n",
        "        \n",
        "        # normalization\n",
        "        self.scaler = preprocessing.StandardScaler().fit(train)\n",
        "        train_scaled = self.scaler.transform(train)\n",
        "\n",
        "        # set loss_weighted, however, it make the result worse, so I cancel it.\n",
        "        train_label_int = train_label.astype(np.int)\n",
        "        label_num = max(train_label_int) - min(train_label_int) + 1 \n",
        "        loss_weights = [0] * label_num\n",
        "        for label in train_label_int:\n",
        "            loss_weights[label] += 1\n",
        "\n",
        "        for i in range(label_num):\n",
        "            loss_weights[i] = len(train_label_int) / loss_weights[i]\n",
        "\n",
        "        loss_weights_sum = sum(loss_weights)\n",
        "        for i in range(label_num):\n",
        "            # loss_weights[i] = loss_weights[i] / loss_weights_sum\n",
        "            loss_weights[i] = loss_weights[i] / loss_weights[i]\n",
        "\n",
        "        del train_label_int, train\n",
        "        gc.collect()\n",
        "\n",
        "        print('Size of training data: {}'.format(train_scaled.shape))\n",
        "\n",
        "        return train_scaled, train_label, loss_weights\n",
        "\n",
        "    def getTestData(self):\n",
        "        print('Loading data ...')\n",
        "\n",
        "        data_root='gdrive/MyDrive/Colab Notebooks/HW2/HW2-1/timit_11/'\n",
        "        test = np.load(data_root + 'test_11.npy')\n",
        "        test_scaled = self.scaler.transform(test)\n",
        "\n",
        "        del test\n",
        "        gc.collect()\n",
        "\n",
        "        print('Size of testing data: {}'.format(test_scaled.shape))\n",
        "\n",
        "        return test_scaled\n",
        "\n",
        "dataManager = DataManager()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mqvtgFoUizSO"
      },
      "source": [
        "## Configuration"
      ]
    },
    {
      "source": [
        "config = {\n",
        "    'BATCH_SIZE': 1024,\n",
        "    'INPUT_DIM': 429,\n",
        "    'OUTPUT_DIM': 39,\n",
        "    'NUM_EPOCH': 500,\n",
        "    # 'LEARNING_RATE': 0.0001,\n",
        "    'MODEL_PATH': './model.ckpt',\n",
        "    'MOMENTUM': 0.01,\n",
        "    'EARLY_STOP': 10,\n",
        "    'DROPOUT_PROB': 0.5,\n",
        "    'INPUT_DROPOUT_PROB': 0.2,\n",
        "    'TEST_SIZE': 0.1,\n",
        "    'WIGHT_DECAY': 0,\n",
        "    'NEGATIVE_SLOPE': 0.05\n",
        "}"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "43WYVgAGiy3l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "us5XW_x6udZQ"
      },
      "source": [
        "## Create Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fjf5EcmJtf4e"
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class TIMITDataset(Dataset):\n",
        "    def __init__(self, X, y=None):\n",
        "        self.data = torch.from_numpy(X).float()\n",
        "        if y is not None:\n",
        "            y = y.astype(np.int)\n",
        "            self.label = torch.LongTensor(y)\n",
        "        else:\n",
        "            self.label = None\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if self.label is not None:\n",
        "            return self.data[idx], self.label[idx]\n",
        "        else:\n",
        "            return self.data[idx]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "otIC6WhGeh9v"
      },
      "source": [
        "Split the labeled data into a training set and a validation set, you can modify the variable `VAL_RATIO` to change the ratio of validation data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dvEsNXH9fSJ5"
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def getTrainDataLoader():\n",
        "    # get data\n",
        "    train, train_label, loss_weights = dataManager.getTrainData()\n",
        "\n",
        "    # split data into training and validation\n",
        "    TEST_SIZE = config['TEST_SIZE']\n",
        "    train_x, val_x, train_y, val_y = train_test_split(train, train_label, test_size=TEST_SIZE, stratify=train_label, random_state=0)\n",
        "\n",
        "    print('Size of training set: {}'.format(train_x.shape))\n",
        "    print('Size of validation set: {}'.format(val_x.shape))\n",
        "    \n",
        "    # save memory\n",
        "    del train, train_label\n",
        "    gc.collect()\n",
        "\n",
        "    # create data loader\n",
        "    print('Creating data loader...')\n",
        "    BATCH_SIZE = config['BATCH_SIZE']\n",
        "    train_set = TIMITDataset(train_x, train_y)\n",
        "    val_set = TIMITDataset(val_x, val_y)\n",
        "    train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True) #only shuffle the training data\n",
        "    val_loader = DataLoader(val_set, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "    # save memory\n",
        "    del train_x, train_y, val_x, val_y\n",
        "    gc.collect()\n",
        "\n",
        "    return train_set, val_set, train_loader, val_loader, loss_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IRqKNvNZwe3V"
      },
      "source": [
        "## Create Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYr1ng5fh9pA"
      },
      "source": [
        "Define model architecture, you are encouraged to change and experiment with the model architecture."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbZrwT6Ny0XL"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchsummary import summary\n",
        "\n",
        "\n",
        "class Classifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Classifier, self).__init__()\n",
        "\n",
        "        INPUT_DIM = config['INPUT_DIM']\n",
        "        OUTPUT_DIM = config['OUTPUT_DIM']\n",
        "        MOMENTUM = config['MOMENTUM']\n",
        "        DROPOUT_PROB = config['DROPOUT_PROB']\n",
        "        NEGATIVE_SLOPE = config['NEGATIVE_SLOPE']\n",
        "        # INPUT_DROPOUT_PROB = config['INPUT_DROPOUT_PROB']\n",
        "\n",
        "\n",
        "        self.layer1 = nn.Linear(INPUT_DIM, 2048)\n",
        "        self.bn1 = nn.BatchNorm1d(2048, momentum=MOMENTUM)\n",
        "        self.layer2 = nn.Linear(2048, 2048)\n",
        "        self.bn2 = nn.BatchNorm1d(2048, momentum=MOMENTUM)\n",
        "        self.layer3 = nn.Linear(2048, 2048)\n",
        "        self.bn3 = nn.BatchNorm1d(2048, momentum=MOMENTUM)\n",
        "        self.layer4 = nn.Linear(2048, 1024)\n",
        "        self.bn4 = nn.BatchNorm1d(1024, momentum=MOMENTUM)\n",
        "        self.layer5 = nn.Linear(1024, 512)\n",
        "        self.bn5 = nn.BatchNorm1d(512, momentum=MOMENTUM)\n",
        "        self.layer6 = nn.Linear(512, 128)\n",
        "        self.bn6 = nn.BatchNorm1d(128, momentum=MOMENTUM)\n",
        "        self.out = nn.Linear(128, OUTPUT_DIM) \n",
        "\n",
        "        self.act_fn = nn.LeakyReLU(negative_slope=NEGATIVE_SLOPE)\n",
        "        self.dropout = nn.Dropout(p=DROPOUT_PROB)\n",
        "        # self.input_dropout = nn.Dropout(p=INPUT_DROPOUT_PROB)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x = self.bn0(x)\n",
        "        # x = self.input_dropout(x)\n",
        "        \n",
        "        x = self.layer1(x)\n",
        "        x = self.act_fn(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = self.layer2(x)\n",
        "        x = self.act_fn(x)\n",
        "        x = self.bn2(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = self.layer3(x)\n",
        "        x = self.act_fn(x)\n",
        "        x = self.bn3(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = self.layer4(x)\n",
        "        x = self.act_fn(x)\n",
        "        x = self.bn4(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = self.layer5(x)\n",
        "        x = self.act_fn(x)\n",
        "        x = self.bn5(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = self.layer6(x)\n",
        "        x = self.act_fn(x)\n",
        "        x = self.bn6(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = self.out(x)\n",
        "        \n",
        "        return x\n",
        "\n",
        "    def summary(self):\n",
        "        INPUT_DIM = config['INPUT_DIM']\n",
        "        summary(self, (INPUT_DIM, ))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "## Training"
      ],
      "cell_type": "markdown",
      "metadata": {
        "id": "VRYciXZvPbYh"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y114Vmm3Ja6o"
      },
      "source": [
        "#check device\n",
        "def get_device():\n",
        "  return 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sEX-yjHjhGuH"
      },
      "source": [
        "Fix random seeds for reproducibility."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88xPiUnm0tAd"
      },
      "source": [
        "# fix random seed\n",
        "def same_seeds(seed):\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)  \n",
        "    np.random.seed(seed)  \n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzg8XKMTc7GU"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "class Trainer():\n",
        "    def train(self):\n",
        "        # fix random seed for reproducibility\n",
        "        same_seeds(0)\n",
        "\n",
        "        # get device \n",
        "        device = get_device()\n",
        "        print(f'DEVICE: {device}')\n",
        "\n",
        "        # training parameters\n",
        "        NUM_EPOCH = config['NUM_EPOCH']               # number of training epoch\n",
        "        # LEARNING_RATE = config['LEARNING_RATE']       # learning rate\n",
        "        WIGHT_DECAY = config['WIGHT_DECAY']\n",
        "        EARLY_STOP = config['EARLY_STOP']\n",
        "        \n",
        "        # the path where checkpoint saved\n",
        "        MODEL_PATH = config['MODEL_PATH']\n",
        "\n",
        "        # load train data\n",
        "        train_set, val_set, train_loader, val_loader, loss_weights = getTrainDataLoader()\n",
        "\n",
        "        # create model, define a loss function, and optimizer\n",
        "        model = Classifier().to(device)\n",
        "        loss_weights = torch.FloatTensor(loss_weights).to(device)\n",
        "        criterion = nn.CrossEntropyLoss(weight = loss_weights)\n",
        "        optimizer = torch.optim.Adam(model.parameters(), weight_decay=WIGHT_DECAY)#, lr=LEARNING_RATE)\n",
        "\n",
        "        # start training\n",
        "        best_val_loss = float('inf')\n",
        "        best_val_acc = 0.0\n",
        "        best_train_loss = float('inf')\n",
        "        best_train_acc = 0.0\n",
        "        early_stop_count = 0\n",
        "        best_predict = []\n",
        "        best_true = []\n",
        "        for epoch in range(NUM_EPOCH):\n",
        "            train_acc = 0.0\n",
        "            train_loss = 0.0\n",
        "            val_acc = 0.0\n",
        "            val_loss = 0.0\n",
        "\n",
        "            # training\n",
        "            model.train() # set the model to training mode\n",
        "            for i, data in enumerate(train_loader):\n",
        "                inputs, labels = data\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                optimizer.zero_grad() \n",
        "                outputs = model(inputs) \n",
        "                batch_loss = criterion(outputs, labels)\n",
        "                _, train_pred = torch.max(outputs, 1) # get the index of the class with the highest probability\n",
        "                batch_loss.backward() \n",
        "                optimizer.step() \n",
        "\n",
        "                train_acc += (train_pred.cpu() == labels.cpu()).sum().item()\n",
        "                train_loss += batch_loss.item()\n",
        "\n",
        "            # validation\n",
        "            if len(val_set) > 0:\n",
        "                predict = []\n",
        "                true = []\n",
        "                model.eval() # set the model to evaluation mode\n",
        "                with torch.no_grad():\n",
        "                    for i, data in enumerate(val_loader):\n",
        "                        inputs, labels = data\n",
        "                        inputs, labels = inputs.to(device), labels.to(device)\n",
        "                        outputs = model(inputs)\n",
        "                        batch_loss = criterion(outputs, labels) \n",
        "                        _, val_pred = torch.max(outputs, 1) \n",
        "                    \n",
        "                        val_acc += (val_pred.cpu() == labels.cpu()).sum().item() # get the index of the class with the highest probability\n",
        "                        val_loss += batch_loss.item()\n",
        "\n",
        "                        for label in labels.cpu().numpy():\n",
        "                            true.append(label)\n",
        "\n",
        "                        for y in val_pred.cpu().numpy():\n",
        "                            predict.append(y)\n",
        "\n",
        "\n",
        "                    print('[{:03d}/{:03d}] Train Acc: {:3.6f} Loss: {:3.6f} | Val Acc: {:3.6f} loss: {:3.6f}'.format(\n",
        "                        epoch + 1, NUM_EPOCH, train_acc/len(train_set), train_loss/len(train_loader), val_acc/len(val_set), val_loss/len(val_loader)\n",
        "                    ))\n",
        "\n",
        "                    # if the model improves, save a checkpoint at this epoch\n",
        "                    if best_val_acc < val_acc:\n",
        "                        early_stop_count = 0\n",
        "\n",
        "                        best_predict = predict\n",
        "                        best_true = true\n",
        "\n",
        "                        best_val_loss = val_loss\n",
        "                        best_val_acc = val_acc\n",
        "                        best_train_loss = train_loss\n",
        "                        best_train_acc = train_acc\n",
        "                        torch.save(model.state_dict(), MODEL_PATH)\n",
        "                        print('saving model with acc {:.3f}'.format(best_val_acc/len(val_set)))\n",
        "\n",
        "                    else:\n",
        "                        early_stop_count += 1\n",
        "\n",
        "                    if early_stop_count > EARLY_STOP:\n",
        "                        break\n",
        "            else:\n",
        "                print('[{:03d}/{:03d}] Train Acc: {:3.6f} Loss: {:3.6f}'.format(\n",
        "                    epoch + 1, NUM_EPOCH, train_acc/len(train_set), train_loss/len(train_loader)\n",
        "                ))\n",
        "\n",
        "        # if not validating, save the last epoch\n",
        "        cf_matrix = None\n",
        "        if len(val_set) == 0:\n",
        "            torch.save(model.state_dict(), MODEL_PATH)\n",
        "            print('saving model at last epoch')\n",
        "\n",
        "        else:\n",
        "            cf_matrix = confusion_matrix(best_true, best_predict)\n",
        "\n",
        "        # print model layers\n",
        "        model.summary()\n",
        "\n",
        "        return best_train_acc/len(train_set), best_val_acc/len(val_set), best_train_loss/len(train_loader), best_val_loss/len(val_loader), cf_matrix\n",
        "\n",
        "\n",
        "\n",
        "trainer = Trainer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wxrtwPiIfISL",
        "outputId": "e3453f26-eb3b-4381-ef78-9f67f7c46fcb"
      },
      "source": [
        "import sys\n",
        "\n",
        "best_train_acc, best_val_acc, best_train_loss, best_val_loss, cf_matrix = trainer.train()\n",
        "\n",
        "print(f'best_train_acc: {best_train_acc}')\n",
        "print(f'best_val_acc: {best_val_acc}')\n",
        "print(f'best_train_loss:{best_train_loss}')\n",
        "print(f'best_val_loss:{best_val_loss}')\n",
        "print(f'config: {config}')\n",
        "\n",
        "# np.savetxt(sys.stdout, cf_matrix, fmt=\"%i\")\n",
        "for i in range(len(cf_matrix)):\n",
        "    print(f'class {i} acc: {cf_matrix[i][i] / cf_matrix[i].sum()}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DEVICE: cuda\n",
            "Loading data ...\n",
            "Size of training data: (1229932, 429)\n",
            "Size of training set: (1106938, 429)\n",
            "Size of validation set: (122994, 429)\n",
            "Creating data loader...\n",
            "[001/500] Train Acc: 0.562358 Loss: 1.489145 | Val Acc: 0.659967 loss: 1.099834\n",
            "saving model with acc 0.660\n",
            "[002/500] Train Acc: 0.633419 Loss: 1.214902 | Val Acc: 0.690229 loss: 0.984318\n",
            "saving model with acc 0.690\n",
            "[003/500] Train Acc: 0.657546 Loss: 1.129151 | Val Acc: 0.709132 loss: 0.918710\n",
            "saving model with acc 0.709\n",
            "[004/500] Train Acc: 0.672701 Loss: 1.073817 | Val Acc: 0.720141 loss: 0.871345\n",
            "saving model with acc 0.720\n",
            "[005/500] Train Acc: 0.684120 Loss: 1.033365 | Val Acc: 0.729702 loss: 0.839744\n",
            "saving model with acc 0.730\n",
            "[006/500] Train Acc: 0.692889 Loss: 0.999300 | Val Acc: 0.738768 loss: 0.807699\n",
            "saving model with acc 0.739\n",
            "[007/500] Train Acc: 0.700285 Loss: 0.972528 | Val Acc: 0.746451 loss: 0.782978\n",
            "saving model with acc 0.746\n",
            "[008/500] Train Acc: 0.706562 Loss: 0.949332 | Val Acc: 0.750362 loss: 0.765137\n",
            "saving model with acc 0.750\n",
            "[009/500] Train Acc: 0.711016 Loss: 0.930246 | Val Acc: 0.754435 loss: 0.750138\n",
            "saving model with acc 0.754\n",
            "[010/500] Train Acc: 0.716545 Loss: 0.912217 | Val Acc: 0.759110 loss: 0.733497\n",
            "saving model with acc 0.759\n",
            "[011/500] Train Acc: 0.720200 Loss: 0.896416 | Val Acc: 0.762850 loss: 0.719119\n",
            "saving model with acc 0.763\n",
            "[012/500] Train Acc: 0.724633 Loss: 0.879872 | Val Acc: 0.767216 loss: 0.706270\n",
            "saving model with acc 0.767\n",
            "[013/500] Train Acc: 0.728771 Loss: 0.866322 | Val Acc: 0.769452 loss: 0.697178\n",
            "saving model with acc 0.769\n",
            "[014/500] Train Acc: 0.732042 Loss: 0.853763 | Val Acc: 0.773501 loss: 0.682442\n",
            "saving model with acc 0.774\n",
            "[015/500] Train Acc: 0.734791 Loss: 0.843225 | Val Acc: 0.774550 loss: 0.678685\n",
            "saving model with acc 0.775\n",
            "[016/500] Train Acc: 0.737566 Loss: 0.832808 | Val Acc: 0.778404 loss: 0.665224\n",
            "saving model with acc 0.778\n",
            "[017/500] Train Acc: 0.740678 Loss: 0.821986 | Val Acc: 0.781542 loss: 0.658086\n",
            "saving model with acc 0.782\n",
            "[018/500] Train Acc: 0.742952 Loss: 0.814639 | Val Acc: 0.782835 loss: 0.650957\n",
            "saving model with acc 0.783\n",
            "[019/500] Train Acc: 0.745450 Loss: 0.805157 | Val Acc: 0.784396 loss: 0.646695\n",
            "saving model with acc 0.784\n",
            "[020/500] Train Acc: 0.747665 Loss: 0.797702 | Val Acc: 0.786266 loss: 0.639287\n",
            "saving model with acc 0.786\n",
            "[021/500] Train Acc: 0.748935 Loss: 0.790763 | Val Acc: 0.788770 loss: 0.631182\n",
            "saving model with acc 0.789\n",
            "[022/500] Train Acc: 0.751199 Loss: 0.783701 | Val Acc: 0.790551 loss: 0.626426\n",
            "saving model with acc 0.791\n",
            "[023/500] Train Acc: 0.752919 Loss: 0.776218 | Val Acc: 0.791640 loss: 0.620738\n",
            "saving model with acc 0.792\n",
            "[024/500] Train Acc: 0.755141 Loss: 0.769305 | Val Acc: 0.793242 loss: 0.616171\n",
            "saving model with acc 0.793\n",
            "[025/500] Train Acc: 0.756862 Loss: 0.763540 | Val Acc: 0.794275 loss: 0.610032\n",
            "saving model with acc 0.794\n",
            "[026/500] Train Acc: 0.758813 Loss: 0.757011 | Val Acc: 0.797055 loss: 0.602754\n",
            "saving model with acc 0.797\n",
            "[027/500] Train Acc: 0.759587 Loss: 0.752884 | Val Acc: 0.796982 loss: 0.601549\n",
            "[028/500] Train Acc: 0.761883 Loss: 0.746641 | Val Acc: 0.799332 loss: 0.593932\n",
            "saving model with acc 0.799\n",
            "[029/500] Train Acc: 0.763412 Loss: 0.740103 | Val Acc: 0.801478 loss: 0.589641\n",
            "saving model with acc 0.801\n",
            "[030/500] Train Acc: 0.764907 Loss: 0.734915 | Val Acc: 0.801828 loss: 0.586950\n",
            "saving model with acc 0.802\n",
            "[031/500] Train Acc: 0.765794 Loss: 0.731311 | Val Acc: 0.803039 loss: 0.581626\n",
            "saving model with acc 0.803\n",
            "[032/500] Train Acc: 0.767178 Loss: 0.726183 | Val Acc: 0.804291 loss: 0.578751\n",
            "saving model with acc 0.804\n",
            "[033/500] Train Acc: 0.768339 Loss: 0.720926 | Val Acc: 0.806446 loss: 0.572760\n",
            "saving model with acc 0.806\n",
            "[034/500] Train Acc: 0.769858 Loss: 0.716702 | Val Acc: 0.806966 loss: 0.571186\n",
            "saving model with acc 0.807\n",
            "[035/500] Train Acc: 0.771281 Loss: 0.711930 | Val Acc: 0.808714 loss: 0.565884\n",
            "saving model with acc 0.809\n",
            "[036/500] Train Acc: 0.772376 Loss: 0.709051 | Val Acc: 0.810308 loss: 0.562516\n",
            "saving model with acc 0.810\n",
            "[037/500] Train Acc: 0.773771 Loss: 0.703561 | Val Acc: 0.809283 loss: 0.561978\n",
            "[038/500] Train Acc: 0.774481 Loss: 0.700210 | Val Acc: 0.811243 loss: 0.556237\n",
            "saving model with acc 0.811\n",
            "[039/500] Train Acc: 0.775514 Loss: 0.697025 | Val Acc: 0.812845 loss: 0.552660\n",
            "saving model with acc 0.813\n",
            "[040/500] Train Acc: 0.776667 Loss: 0.694263 | Val Acc: 0.812064 loss: 0.550803\n",
            "[041/500] Train Acc: 0.778103 Loss: 0.688693 | Val Acc: 0.814243 loss: 0.546264\n",
            "saving model with acc 0.814\n",
            "[042/500] Train Acc: 0.779052 Loss: 0.685470 | Val Acc: 0.814820 loss: 0.544573\n",
            "saving model with acc 0.815\n",
            "[043/500] Train Acc: 0.779692 Loss: 0.681925 | Val Acc: 0.816072 loss: 0.540765\n",
            "saving model with acc 0.816\n",
            "[044/500] Train Acc: 0.781032 Loss: 0.677839 | Val Acc: 0.816861 loss: 0.537533\n",
            "saving model with acc 0.817\n",
            "[045/500] Train Acc: 0.781776 Loss: 0.675243 | Val Acc: 0.818040 loss: 0.535502\n",
            "saving model with acc 0.818\n",
            "[046/500] Train Acc: 0.782599 Loss: 0.673234 | Val Acc: 0.817243 loss: 0.533919\n",
            "[047/500] Train Acc: 0.783253 Loss: 0.669961 | Val Acc: 0.819536 loss: 0.527737\n",
            "saving model with acc 0.820\n",
            "[048/500] Train Acc: 0.784477 Loss: 0.665976 | Val Acc: 0.820300 loss: 0.525383\n",
            "saving model with acc 0.820\n",
            "[049/500] Train Acc: 0.785260 Loss: 0.662776 | Val Acc: 0.821300 loss: 0.524837\n",
            "saving model with acc 0.821\n",
            "[050/500] Train Acc: 0.785620 Loss: 0.662254 | Val Acc: 0.820739 loss: 0.524228\n",
            "[051/500] Train Acc: 0.787280 Loss: 0.656982 | Val Acc: 0.823130 loss: 0.520536\n",
            "saving model with acc 0.823\n",
            "[052/500] Train Acc: 0.787445 Loss: 0.655370 | Val Acc: 0.821788 loss: 0.519197\n",
            "[053/500] Train Acc: 0.788190 Loss: 0.651642 | Val Acc: 0.823869 loss: 0.515401\n",
            "saving model with acc 0.824\n",
            "[054/500] Train Acc: 0.788641 Loss: 0.649914 | Val Acc: 0.824463 loss: 0.513299\n",
            "saving model with acc 0.824\n",
            "[055/500] Train Acc: 0.789807 Loss: 0.647947 | Val Acc: 0.825479 loss: 0.512236\n",
            "saving model with acc 0.825\n",
            "[056/500] Train Acc: 0.791115 Loss: 0.644090 | Val Acc: 0.825187 loss: 0.511313\n",
            "[057/500] Train Acc: 0.790955 Loss: 0.642827 | Val Acc: 0.826487 loss: 0.507134\n",
            "saving model with acc 0.826\n",
            "[058/500] Train Acc: 0.792154 Loss: 0.639967 | Val Acc: 0.827414 loss: 0.505762\n",
            "saving model with acc 0.827\n",
            "[059/500] Train Acc: 0.792766 Loss: 0.637799 | Val Acc: 0.828105 loss: 0.505215\n",
            "saving model with acc 0.828\n",
            "[060/500] Train Acc: 0.793260 Loss: 0.634905 | Val Acc: 0.828423 loss: 0.501629\n",
            "saving model with acc 0.828\n",
            "[061/500] Train Acc: 0.794501 Loss: 0.632347 | Val Acc: 0.829886 loss: 0.498557\n",
            "saving model with acc 0.830\n",
            "[062/500] Train Acc: 0.794226 Loss: 0.630709 | Val Acc: 0.829130 loss: 0.498405\n",
            "[063/500] Train Acc: 0.795236 Loss: 0.628566 | Val Acc: 0.830634 loss: 0.497335\n",
            "saving model with acc 0.831\n",
            "[064/500] Train Acc: 0.795806 Loss: 0.626820 | Val Acc: 0.830089 loss: 0.496702\n",
            "[065/500] Train Acc: 0.796454 Loss: 0.623911 | Val Acc: 0.831024 loss: 0.492558\n",
            "saving model with acc 0.831\n",
            "[066/500] Train Acc: 0.796684 Loss: 0.622104 | Val Acc: 0.831366 loss: 0.493135\n",
            "saving model with acc 0.831\n",
            "[067/500] Train Acc: 0.798103 Loss: 0.619887 | Val Acc: 0.831642 loss: 0.489990\n",
            "saving model with acc 0.832\n",
            "[068/500] Train Acc: 0.798198 Loss: 0.618106 | Val Acc: 0.832732 loss: 0.488427\n",
            "saving model with acc 0.833\n",
            "[069/500] Train Acc: 0.799523 Loss: 0.615038 | Val Acc: 0.833016 loss: 0.487483\n",
            "saving model with acc 0.833\n",
            "[070/500] Train Acc: 0.800020 Loss: 0.613340 | Val Acc: 0.833789 loss: 0.485741\n",
            "saving model with acc 0.834\n",
            "[071/500] Train Acc: 0.800031 Loss: 0.611726 | Val Acc: 0.833561 loss: 0.485507\n",
            "[072/500] Train Acc: 0.800631 Loss: 0.610483 | Val Acc: 0.834992 loss: 0.480970\n",
            "saving model with acc 0.835\n",
            "[073/500] Train Acc: 0.801374 Loss: 0.608388 | Val Acc: 0.835764 loss: 0.480277\n",
            "saving model with acc 0.836\n",
            "[074/500] Train Acc: 0.802167 Loss: 0.606991 | Val Acc: 0.836569 loss: 0.477582\n",
            "saving model with acc 0.837\n",
            "[075/500] Train Acc: 0.802303 Loss: 0.604345 | Val Acc: 0.836529 loss: 0.478072\n",
            "[076/500] Train Acc: 0.802999 Loss: 0.603238 | Val Acc: 0.836919 loss: 0.475631\n",
            "saving model with acc 0.837\n",
            "[077/500] Train Acc: 0.803673 Loss: 0.601288 | Val Acc: 0.836829 loss: 0.474837\n",
            "[078/500] Train Acc: 0.803956 Loss: 0.599458 | Val Acc: 0.837496 loss: 0.474644\n",
            "saving model with acc 0.837\n",
            "[079/500] Train Acc: 0.804322 Loss: 0.596905 | Val Acc: 0.837773 loss: 0.471443\n",
            "saving model with acc 0.838\n",
            "[080/500] Train Acc: 0.804881 Loss: 0.595344 | Val Acc: 0.837846 loss: 0.472403\n",
            "saving model with acc 0.838\n",
            "[081/500] Train Acc: 0.805340 Loss: 0.595336 | Val Acc: 0.837846 loss: 0.470723\n",
            "[082/500] Train Acc: 0.805467 Loss: 0.593963 | Val Acc: 0.839073 loss: 0.467839\n",
            "saving model with acc 0.839\n",
            "[083/500] Train Acc: 0.806619 Loss: 0.590641 | Val Acc: 0.839561 loss: 0.467044\n",
            "saving model with acc 0.840\n",
            "[084/500] Train Acc: 0.806384 Loss: 0.590091 | Val Acc: 0.839578 loss: 0.465716\n",
            "saving model with acc 0.840\n",
            "[085/500] Train Acc: 0.806744 Loss: 0.589187 | Val Acc: 0.839870 loss: 0.465983\n",
            "saving model with acc 0.840\n",
            "[086/500] Train Acc: 0.807293 Loss: 0.587537 | Val Acc: 0.840529 loss: 0.462783\n",
            "saving model with acc 0.841\n",
            "[087/500] Train Acc: 0.808385 Loss: 0.584591 | Val Acc: 0.841594 loss: 0.461089\n",
            "saving model with acc 0.842\n",
            "[088/500] Train Acc: 0.808921 Loss: 0.583032 | Val Acc: 0.841732 loss: 0.460667\n",
            "saving model with acc 0.842\n",
            "[089/500] Train Acc: 0.808965 Loss: 0.582188 | Val Acc: 0.841521 loss: 0.460274\n",
            "[090/500] Train Acc: 0.809376 Loss: 0.581944 | Val Acc: 0.842553 loss: 0.458993\n",
            "saving model with acc 0.843\n",
            "[091/500] Train Acc: 0.810256 Loss: 0.579757 | Val Acc: 0.842415 loss: 0.457920\n",
            "[092/500] Train Acc: 0.810364 Loss: 0.577819 | Val Acc: 0.843350 loss: 0.455502\n",
            "saving model with acc 0.843\n",
            "[093/500] Train Acc: 0.810678 Loss: 0.576417 | Val Acc: 0.844960 loss: 0.454467\n",
            "saving model with acc 0.845\n",
            "[094/500] Train Acc: 0.811139 Loss: 0.575168 | Val Acc: 0.844529 loss: 0.454150\n",
            "[095/500] Train Acc: 0.811095 Loss: 0.574810 | Val Acc: 0.844074 loss: 0.452666\n",
            "[096/500] Train Acc: 0.811690 Loss: 0.573063 | Val Acc: 0.844334 loss: 0.451085\n",
            "[097/500] Train Acc: 0.812346 Loss: 0.571394 | Val Acc: 0.845212 loss: 0.449952\n",
            "saving model with acc 0.845\n",
            "[098/500] Train Acc: 0.812037 Loss: 0.571124 | Val Acc: 0.844749 loss: 0.450872\n",
            "[099/500] Train Acc: 0.813232 Loss: 0.568175 | Val Acc: 0.845797 loss: 0.448685\n",
            "saving model with acc 0.846\n",
            "[100/500] Train Acc: 0.813798 Loss: 0.567355 | Val Acc: 0.844992 loss: 0.450033\n",
            "[101/500] Train Acc: 0.814290 Loss: 0.564328 | Val Acc: 0.846448 loss: 0.446577\n",
            "saving model with acc 0.846\n",
            "[102/500] Train Acc: 0.813916 Loss: 0.565978 | Val Acc: 0.846497 loss: 0.447078\n",
            "saving model with acc 0.846\n",
            "[103/500] Train Acc: 0.814399 Loss: 0.563801 | Val Acc: 0.846993 loss: 0.445426\n",
            "saving model with acc 0.847\n",
            "[104/500] Train Acc: 0.814594 Loss: 0.563016 | Val Acc: 0.847749 loss: 0.444445\n",
            "saving model with acc 0.848\n",
            "[105/500] Train Acc: 0.815353 Loss: 0.561933 | Val Acc: 0.847741 loss: 0.444231\n",
            "[106/500] Train Acc: 0.815183 Loss: 0.559723 | Val Acc: 0.848480 loss: 0.442406\n",
            "saving model with acc 0.848\n",
            "[107/500] Train Acc: 0.815381 Loss: 0.560290 | Val Acc: 0.848123 loss: 0.440285\n",
            "[108/500] Train Acc: 0.816567 Loss: 0.557196 | Val Acc: 0.847570 loss: 0.442477\n",
            "[109/500] Train Acc: 0.816805 Loss: 0.556260 | Val Acc: 0.848537 loss: 0.438623\n",
            "saving model with acc 0.849\n",
            "[110/500] Train Acc: 0.816529 Loss: 0.555895 | Val Acc: 0.848204 loss: 0.440240\n",
            "[111/500] Train Acc: 0.817250 Loss: 0.555414 | Val Acc: 0.849090 loss: 0.438545\n",
            "saving model with acc 0.849\n",
            "[112/500] Train Acc: 0.817662 Loss: 0.553704 | Val Acc: 0.849074 loss: 0.436300\n",
            "[113/500] Train Acc: 0.818055 Loss: 0.552589 | Val Acc: 0.850448 loss: 0.434372\n",
            "saving model with acc 0.850\n",
            "[114/500] Train Acc: 0.817783 Loss: 0.552818 | Val Acc: 0.850521 loss: 0.433971\n",
            "saving model with acc 0.851\n",
            "[115/500] Train Acc: 0.818368 Loss: 0.550479 | Val Acc: 0.849789 loss: 0.435040\n",
            "[116/500] Train Acc: 0.818880 Loss: 0.550151 | Val Acc: 0.851521 loss: 0.431328\n",
            "saving model with acc 0.852\n",
            "[117/500] Train Acc: 0.819115 Loss: 0.548811 | Val Acc: 0.850188 loss: 0.433986\n",
            "[118/500] Train Acc: 0.819226 Loss: 0.547301 | Val Acc: 0.850976 loss: 0.432061\n",
            "[119/500] Train Acc: 0.819635 Loss: 0.547066 | Val Acc: 0.851765 loss: 0.430778\n",
            "saving model with acc 0.852\n",
            "[120/500] Train Acc: 0.819629 Loss: 0.545377 | Val Acc: 0.850708 loss: 0.429550\n",
            "[121/500] Train Acc: 0.819925 Loss: 0.544844 | Val Acc: 0.851497 loss: 0.429443\n",
            "[122/500] Train Acc: 0.820786 Loss: 0.542701 | Val Acc: 0.851594 loss: 0.428534\n",
            "[123/500] Train Acc: 0.820963 Loss: 0.541688 | Val Acc: 0.851773 loss: 0.429163\n",
            "saving model with acc 0.852\n",
            "[124/500] Train Acc: 0.821529 Loss: 0.540495 | Val Acc: 0.853464 loss: 0.426222\n",
            "saving model with acc 0.853\n",
            "[125/500] Train Acc: 0.821791 Loss: 0.540344 | Val Acc: 0.851781 loss: 0.426144\n",
            "[126/500] Train Acc: 0.822237 Loss: 0.539610 | Val Acc: 0.852489 loss: 0.425743\n",
            "[127/500] Train Acc: 0.822086 Loss: 0.538589 | Val Acc: 0.853139 loss: 0.425924\n",
            "[128/500] Train Acc: 0.822608 Loss: 0.537813 | Val Acc: 0.853196 loss: 0.425386\n",
            "[129/500] Train Acc: 0.822350 Loss: 0.537804 | Val Acc: 0.854009 loss: 0.423164\n",
            "saving model with acc 0.854\n",
            "[130/500] Train Acc: 0.823211 Loss: 0.536374 | Val Acc: 0.853985 loss: 0.422866\n",
            "[131/500] Train Acc: 0.823089 Loss: 0.535809 | Val Acc: 0.854253 loss: 0.422922\n",
            "saving model with acc 0.854\n",
            "[132/500] Train Acc: 0.823538 Loss: 0.534133 | Val Acc: 0.854684 loss: 0.421766\n",
            "saving model with acc 0.855\n",
            "[133/500] Train Acc: 0.824457 Loss: 0.532144 | Val Acc: 0.854643 loss: 0.420739\n",
            "[134/500] Train Acc: 0.824231 Loss: 0.532252 | Val Acc: 0.854773 loss: 0.419686\n",
            "saving model with acc 0.855\n",
            "[135/500] Train Acc: 0.824234 Loss: 0.531986 | Val Acc: 0.854456 loss: 0.421747\n",
            "[136/500] Train Acc: 0.824915 Loss: 0.529762 | Val Acc: 0.855090 loss: 0.419948\n",
            "saving model with acc 0.855\n",
            "[137/500] Train Acc: 0.824342 Loss: 0.530797 | Val Acc: 0.855830 loss: 0.417812\n",
            "saving model with acc 0.856\n",
            "[138/500] Train Acc: 0.824595 Loss: 0.529644 | Val Acc: 0.855619 loss: 0.418523\n",
            "[139/500] Train Acc: 0.825404 Loss: 0.528117 | Val Acc: 0.856139 loss: 0.415875\n",
            "saving model with acc 0.856\n",
            "[140/500] Train Acc: 0.825831 Loss: 0.527495 | Val Acc: 0.855603 loss: 0.417872\n",
            "[141/500] Train Acc: 0.825998 Loss: 0.525908 | Val Acc: 0.855977 loss: 0.416776\n",
            "[142/500] Train Acc: 0.826237 Loss: 0.525612 | Val Acc: 0.855822 loss: 0.415310\n",
            "[143/500] Train Acc: 0.826530 Loss: 0.524521 | Val Acc: 0.855887 loss: 0.414645\n",
            "[144/500] Train Acc: 0.826606 Loss: 0.524652 | Val Acc: 0.856733 loss: 0.414732\n",
            "saving model with acc 0.857\n",
            "[145/500] Train Acc: 0.826632 Loss: 0.522692 | Val Acc: 0.857790 loss: 0.413456\n",
            "saving model with acc 0.858\n",
            "[146/500] Train Acc: 0.826820 Loss: 0.523422 | Val Acc: 0.857692 loss: 0.412241\n",
            "[147/500] Train Acc: 0.827409 Loss: 0.522027 | Val Acc: 0.858009 loss: 0.411733\n",
            "saving model with acc 0.858\n",
            "[148/500] Train Acc: 0.827466 Loss: 0.520496 | Val Acc: 0.858400 loss: 0.410599\n",
            "saving model with acc 0.858\n",
            "[149/500] Train Acc: 0.827711 Loss: 0.519623 | Val Acc: 0.858237 loss: 0.412022\n",
            "[150/500] Train Acc: 0.827877 Loss: 0.519186 | Val Acc: 0.858765 loss: 0.411791\n",
            "saving model with acc 0.859\n",
            "[151/500] Train Acc: 0.828122 Loss: 0.518565 | Val Acc: 0.858351 loss: 0.410613\n",
            "[152/500] Train Acc: 0.828382 Loss: 0.519096 | Val Acc: 0.858383 loss: 0.409031\n",
            "[153/500] Train Acc: 0.829227 Loss: 0.517317 | Val Acc: 0.859261 loss: 0.409447\n",
            "saving model with acc 0.859\n",
            "[154/500] Train Acc: 0.828695 Loss: 0.517143 | Val Acc: 0.859164 loss: 0.408517\n",
            "[155/500] Train Acc: 0.829035 Loss: 0.517728 | Val Acc: 0.858318 loss: 0.410432\n",
            "[156/500] Train Acc: 0.829471 Loss: 0.515359 | Val Acc: 0.858822 loss: 0.408770\n",
            "[157/500] Train Acc: 0.829768 Loss: 0.513727 | Val Acc: 0.858831 loss: 0.407260\n",
            "[158/500] Train Acc: 0.830056 Loss: 0.513584 | Val Acc: 0.859896 loss: 0.406654\n",
            "saving model with acc 0.860\n",
            "[159/500] Train Acc: 0.829539 Loss: 0.513895 | Val Acc: 0.859831 loss: 0.406165\n",
            "[160/500] Train Acc: 0.829990 Loss: 0.512705 | Val Acc: 0.859887 loss: 0.407870\n",
            "[161/500] Train Acc: 0.830684 Loss: 0.510800 | Val Acc: 0.860595 loss: 0.404168\n",
            "saving model with acc 0.861\n",
            "[162/500] Train Acc: 0.830234 Loss: 0.511020 | Val Acc: 0.859692 loss: 0.404848\n",
            "[163/500] Train Acc: 0.831098 Loss: 0.509672 | Val Acc: 0.859887 loss: 0.404521\n",
            "[164/500] Train Acc: 0.831047 Loss: 0.509557 | Val Acc: 0.861018 loss: 0.403551\n",
            "saving model with acc 0.861\n",
            "[165/500] Train Acc: 0.830687 Loss: 0.510162 | Val Acc: 0.861692 loss: 0.402796\n",
            "saving model with acc 0.862\n",
            "[166/500] Train Acc: 0.831289 Loss: 0.507812 | Val Acc: 0.860603 loss: 0.401458\n",
            "[167/500] Train Acc: 0.831420 Loss: 0.508549 | Val Acc: 0.860920 loss: 0.402623\n",
            "[168/500] Train Acc: 0.831220 Loss: 0.508513 | Val Acc: 0.860798 loss: 0.402373\n",
            "[169/500] Train Acc: 0.831897 Loss: 0.505909 | Val Acc: 0.861432 loss: 0.402129\n",
            "[170/500] Train Acc: 0.832210 Loss: 0.506009 | Val Acc: 0.861009 loss: 0.402315\n",
            "[171/500] Train Acc: 0.832258 Loss: 0.505381 | Val Acc: 0.861790 loss: 0.398370\n",
            "saving model with acc 0.862\n",
            "[172/500] Train Acc: 0.832732 Loss: 0.504125 | Val Acc: 0.861863 loss: 0.397966\n",
            "saving model with acc 0.862\n",
            "[173/500] Train Acc: 0.832463 Loss: 0.504897 | Val Acc: 0.862050 loss: 0.398889\n",
            "saving model with acc 0.862\n",
            "[174/500] Train Acc: 0.832937 Loss: 0.502637 | Val Acc: 0.861115 loss: 0.398934\n",
            "[175/500] Train Acc: 0.833020 Loss: 0.502327 | Val Acc: 0.862164 loss: 0.397241\n",
            "saving model with acc 0.862\n",
            "[176/500] Train Acc: 0.833180 Loss: 0.502986 | Val Acc: 0.862465 loss: 0.397917\n",
            "saving model with acc 0.862\n",
            "[177/500] Train Acc: 0.833560 Loss: 0.501873 | Val Acc: 0.862603 loss: 0.397807\n",
            "saving model with acc 0.863\n",
            "[178/500] Train Acc: 0.833844 Loss: 0.501453 | Val Acc: 0.862188 loss: 0.399007\n",
            "[179/500] Train Acc: 0.833966 Loss: 0.499726 | Val Acc: 0.862936 loss: 0.395734\n",
            "saving model with acc 0.863\n",
            "[180/500] Train Acc: 0.833855 Loss: 0.501343 | Val Acc: 0.863042 loss: 0.397075\n",
            "saving model with acc 0.863\n",
            "[181/500] Train Acc: 0.834619 Loss: 0.498488 | Val Acc: 0.864432 loss: 0.395929\n",
            "saving model with acc 0.864\n",
            "[182/500] Train Acc: 0.834513 Loss: 0.497617 | Val Acc: 0.862790 loss: 0.397930\n",
            "[183/500] Train Acc: 0.834884 Loss: 0.497252 | Val Acc: 0.863343 loss: 0.394479\n",
            "[184/500] Train Acc: 0.834644 Loss: 0.497543 | Val Acc: 0.863611 loss: 0.392979\n",
            "[185/500] Train Acc: 0.834538 Loss: 0.497735 | Val Acc: 0.863188 loss: 0.393521\n",
            "[186/500] Train Acc: 0.835278 Loss: 0.495790 | Val Acc: 0.863489 loss: 0.394218\n",
            "[187/500] Train Acc: 0.835278 Loss: 0.496513 | Val Acc: 0.864205 loss: 0.393353\n",
            "[188/500] Train Acc: 0.835430 Loss: 0.495024 | Val Acc: 0.864359 loss: 0.393549\n",
            "[189/500] Train Acc: 0.835835 Loss: 0.493544 | Val Acc: 0.864937 loss: 0.392656\n",
            "saving model with acc 0.865\n",
            "[190/500] Train Acc: 0.835616 Loss: 0.494144 | Val Acc: 0.864075 loss: 0.394186\n",
            "[191/500] Train Acc: 0.836025 Loss: 0.493784 | Val Acc: 0.864075 loss: 0.392407\n",
            "[192/500] Train Acc: 0.836131 Loss: 0.492752 | Val Acc: 0.864758 loss: 0.391828\n",
            "[193/500] Train Acc: 0.837059 Loss: 0.491958 | Val Acc: 0.864871 loss: 0.392140\n",
            "[194/500] Train Acc: 0.836114 Loss: 0.492828 | Val Acc: 0.864538 loss: 0.392732\n",
            "[195/500] Train Acc: 0.836882 Loss: 0.490577 | Val Acc: 0.865302 loss: 0.391495\n",
            "saving model with acc 0.865\n",
            "[196/500] Train Acc: 0.836603 Loss: 0.491114 | Val Acc: 0.864839 loss: 0.391163\n",
            "[197/500] Train Acc: 0.837125 Loss: 0.489808 | Val Acc: 0.865343 loss: 0.392023\n",
            "saving model with acc 0.865\n",
            "[198/500] Train Acc: 0.836912 Loss: 0.490271 | Val Acc: 0.865164 loss: 0.391776\n",
            "[199/500] Train Acc: 0.837453 Loss: 0.488427 | Val Acc: 0.865530 loss: 0.390546\n",
            "saving model with acc 0.866\n",
            "[200/500] Train Acc: 0.838116 Loss: 0.487300 | Val Acc: 0.866156 loss: 0.387856\n",
            "saving model with acc 0.866\n",
            "[201/500] Train Acc: 0.837725 Loss: 0.487617 | Val Acc: 0.866246 loss: 0.388294\n",
            "saving model with acc 0.866\n",
            "[202/500] Train Acc: 0.837664 Loss: 0.487607 | Val Acc: 0.865644 loss: 0.388782\n",
            "[203/500] Train Acc: 0.838219 Loss: 0.487437 | Val Acc: 0.865969 loss: 0.386782\n",
            "[204/500] Train Acc: 0.838077 Loss: 0.487310 | Val Acc: 0.866441 loss: 0.386613\n",
            "saving model with acc 0.866\n",
            "[205/500] Train Acc: 0.838470 Loss: 0.485488 | Val Acc: 0.867059 loss: 0.387019\n",
            "saving model with acc 0.867\n",
            "[206/500] Train Acc: 0.838849 Loss: 0.485073 | Val Acc: 0.866311 loss: 0.388356\n",
            "[207/500] Train Acc: 0.838553 Loss: 0.485318 | Val Acc: 0.866246 loss: 0.387942\n",
            "[208/500] Train Acc: 0.838532 Loss: 0.484620 | Val Acc: 0.866985 loss: 0.387885\n",
            "[209/500] Train Acc: 0.838917 Loss: 0.484393 | Val Acc: 0.866563 loss: 0.387891\n",
            "[210/500] Train Acc: 0.839042 Loss: 0.484005 | Val Acc: 0.867815 loss: 0.387117\n",
            "saving model with acc 0.868\n",
            "[211/500] Train Acc: 0.839219 Loss: 0.484469 | Val Acc: 0.867473 loss: 0.384359\n",
            "[212/500] Train Acc: 0.839615 Loss: 0.482636 | Val Acc: 0.867278 loss: 0.385759\n",
            "[213/500] Train Acc: 0.839580 Loss: 0.483353 | Val Acc: 0.867254 loss: 0.386335\n",
            "[214/500] Train Acc: 0.839677 Loss: 0.481116 | Val Acc: 0.868181 loss: 0.383793\n",
            "saving model with acc 0.868\n",
            "[215/500] Train Acc: 0.839982 Loss: 0.481170 | Val Acc: 0.867579 loss: 0.383714\n",
            "[216/500] Train Acc: 0.839723 Loss: 0.480478 | Val Acc: 0.867725 loss: 0.383704\n",
            "[217/500] Train Acc: 0.839052 Loss: 0.482340 | Val Acc: 0.868018 loss: 0.382811\n",
            "[218/500] Train Acc: 0.840664 Loss: 0.478506 | Val Acc: 0.867742 loss: 0.382576\n",
            "[219/500] Train Acc: 0.840501 Loss: 0.479385 | Val Acc: 0.868823 loss: 0.383257\n",
            "saving model with acc 0.869\n",
            "[220/500] Train Acc: 0.840641 Loss: 0.478352 | Val Acc: 0.868441 loss: 0.383873\n",
            "[221/500] Train Acc: 0.840528 Loss: 0.478974 | Val Acc: 0.869067 loss: 0.381909\n",
            "saving model with acc 0.869\n",
            "[222/500] Train Acc: 0.840783 Loss: 0.477872 | Val Acc: 0.869018 loss: 0.380571\n",
            "[223/500] Train Acc: 0.840951 Loss: 0.477754 | Val Acc: 0.868400 loss: 0.380910\n",
            "[224/500] Train Acc: 0.840609 Loss: 0.477920 | Val Acc: 0.868457 loss: 0.381838\n",
            "[225/500] Train Acc: 0.841184 Loss: 0.476927 | Val Acc: 0.869181 loss: 0.378893\n",
            "saving model with acc 0.869\n",
            "[226/500] Train Acc: 0.841195 Loss: 0.475907 | Val Acc: 0.869018 loss: 0.379585\n",
            "[227/500] Train Acc: 0.841658 Loss: 0.475893 | Val Acc: 0.869051 loss: 0.380127\n",
            "[228/500] Train Acc: 0.841727 Loss: 0.475528 | Val Acc: 0.868668 loss: 0.379966\n",
            "[229/500] Train Acc: 0.841382 Loss: 0.476357 | Val Acc: 0.870229 loss: 0.377088\n",
            "saving model with acc 0.870\n",
            "[230/500] Train Acc: 0.842171 Loss: 0.474206 | Val Acc: 0.869652 loss: 0.379220\n",
            "[231/500] Train Acc: 0.841756 Loss: 0.474830 | Val Acc: 0.869294 loss: 0.378528\n",
            "[232/500] Train Acc: 0.842160 Loss: 0.473552 | Val Acc: 0.869327 loss: 0.378029\n",
            "[233/500] Train Acc: 0.842291 Loss: 0.473574 | Val Acc: 0.869782 loss: 0.377616\n",
            "[234/500] Train Acc: 0.842539 Loss: 0.473335 | Val Acc: 0.870286 loss: 0.378202\n",
            "saving model with acc 0.870\n",
            "[235/500] Train Acc: 0.842343 Loss: 0.472451 | Val Acc: 0.870262 loss: 0.377434\n",
            "[236/500] Train Acc: 0.842310 Loss: 0.472455 | Val Acc: 0.870425 loss: 0.377006\n",
            "saving model with acc 0.870\n",
            "[237/500] Train Acc: 0.842246 Loss: 0.471546 | Val Acc: 0.869855 loss: 0.376788\n",
            "[238/500] Train Acc: 0.842785 Loss: 0.471635 | Val Acc: 0.870587 loss: 0.376114\n",
            "saving model with acc 0.871\n",
            "[239/500] Train Acc: 0.843208 Loss: 0.470899 | Val Acc: 0.870847 loss: 0.376036\n",
            "saving model with acc 0.871\n",
            "[240/500] Train Acc: 0.843346 Loss: 0.469765 | Val Acc: 0.870238 loss: 0.376835\n",
            "[241/500] Train Acc: 0.843119 Loss: 0.470167 | Val Acc: 0.870400 loss: 0.377242\n",
            "[242/500] Train Acc: 0.843317 Loss: 0.469728 | Val Acc: 0.870498 loss: 0.374988\n",
            "[243/500] Train Acc: 0.843286 Loss: 0.469849 | Val Acc: 0.870555 loss: 0.376177\n",
            "[244/500] Train Acc: 0.843349 Loss: 0.469250 | Val Acc: 0.870758 loss: 0.375395\n",
            "[245/500] Train Acc: 0.843679 Loss: 0.468182 | Val Acc: 0.871278 loss: 0.374242\n",
            "saving model with acc 0.871\n",
            "[246/500] Train Acc: 0.843594 Loss: 0.468374 | Val Acc: 0.871555 loss: 0.373617\n",
            "saving model with acc 0.872\n",
            "[247/500] Train Acc: 0.843811 Loss: 0.467704 | Val Acc: 0.871002 loss: 0.372841\n",
            "[248/500] Train Acc: 0.844517 Loss: 0.466776 | Val Acc: 0.871506 loss: 0.372862\n",
            "[249/500] Train Acc: 0.844379 Loss: 0.467223 | Val Acc: 0.871595 loss: 0.372674\n",
            "saving model with acc 0.872\n",
            "[250/500] Train Acc: 0.844391 Loss: 0.466481 | Val Acc: 0.871888 loss: 0.374197\n",
            "saving model with acc 0.872\n",
            "[251/500] Train Acc: 0.844345 Loss: 0.467462 | Val Acc: 0.872205 loss: 0.372848\n",
            "saving model with acc 0.872\n",
            "[252/500] Train Acc: 0.844519 Loss: 0.465126 | Val Acc: 0.872173 loss: 0.373179\n",
            "[253/500] Train Acc: 0.844250 Loss: 0.466075 | Val Acc: 0.870953 loss: 0.374280\n",
            "[254/500] Train Acc: 0.844774 Loss: 0.466105 | Val Acc: 0.872018 loss: 0.372240\n",
            "[255/500] Train Acc: 0.844560 Loss: 0.465452 | Val Acc: 0.872286 loss: 0.372192\n",
            "saving model with acc 0.872\n",
            "[256/500] Train Acc: 0.845240 Loss: 0.464626 | Val Acc: 0.872067 loss: 0.370559\n",
            "[257/500] Train Acc: 0.845734 Loss: 0.463743 | Val Acc: 0.872498 loss: 0.371844\n",
            "saving model with acc 0.872\n",
            "[258/500] Train Acc: 0.845223 Loss: 0.463647 | Val Acc: 0.872506 loss: 0.373176\n",
            "saving model with acc 0.873\n",
            "[259/500] Train Acc: 0.844832 Loss: 0.464558 | Val Acc: 0.871888 loss: 0.370956\n",
            "[260/500] Train Acc: 0.845498 Loss: 0.463052 | Val Acc: 0.872896 loss: 0.370631\n",
            "saving model with acc 0.873\n",
            "[261/500] Train Acc: 0.845596 Loss: 0.462879 | Val Acc: 0.873116 loss: 0.370677\n",
            "saving model with acc 0.873\n",
            "[262/500] Train Acc: 0.845711 Loss: 0.461557 | Val Acc: 0.872482 loss: 0.372174\n",
            "[263/500] Train Acc: 0.845141 Loss: 0.463621 | Val Acc: 0.873295 loss: 0.370236\n",
            "saving model with acc 0.873\n",
            "[264/500] Train Acc: 0.846154 Loss: 0.460264 | Val Acc: 0.873075 loss: 0.368534\n",
            "[265/500] Train Acc: 0.847084 Loss: 0.459733 | Val Acc: 0.872961 loss: 0.369282\n",
            "[266/500] Train Acc: 0.846635 Loss: 0.460155 | Val Acc: 0.873587 loss: 0.368375\n",
            "saving model with acc 0.874\n",
            "[267/500] Train Acc: 0.846233 Loss: 0.461134 | Val Acc: 0.872758 loss: 0.369994\n",
            "[268/500] Train Acc: 0.846475 Loss: 0.459607 | Val Acc: 0.873587 loss: 0.368853\n",
            "[269/500] Train Acc: 0.846530 Loss: 0.459444 | Val Acc: 0.873392 loss: 0.368139\n",
            "[270/500] Train Acc: 0.846869 Loss: 0.459283 | Val Acc: 0.873197 loss: 0.370084\n",
            "[271/500] Train Acc: 0.846947 Loss: 0.458266 | Val Acc: 0.873661 loss: 0.367680\n",
            "saving model with acc 0.874\n",
            "[272/500] Train Acc: 0.846699 Loss: 0.459219 | Val Acc: 0.872807 loss: 0.369495\n",
            "[273/500] Train Acc: 0.847569 Loss: 0.457352 | Val Acc: 0.873352 loss: 0.368212\n",
            "[274/500] Train Acc: 0.847207 Loss: 0.458206 | Val Acc: 0.873652 loss: 0.370032\n",
            "[275/500] Train Acc: 0.847080 Loss: 0.458111 | Val Acc: 0.873392 loss: 0.368193\n",
            "[276/500] Train Acc: 0.847599 Loss: 0.456353 | Val Acc: 0.873482 loss: 0.367945\n",
            "[277/500] Train Acc: 0.847810 Loss: 0.457510 | Val Acc: 0.873677 loss: 0.367607\n",
            "saving model with acc 0.874\n",
            "[278/500] Train Acc: 0.847404 Loss: 0.457035 | Val Acc: 0.873758 loss: 0.367760\n",
            "saving model with acc 0.874\n",
            "[279/500] Train Acc: 0.847606 Loss: 0.456406 | Val Acc: 0.873734 loss: 0.365823\n",
            "[280/500] Train Acc: 0.848154 Loss: 0.455942 | Val Acc: 0.873522 loss: 0.367258\n",
            "[281/500] Train Acc: 0.847645 Loss: 0.455796 | Val Acc: 0.873661 loss: 0.367728\n",
            "[282/500] Train Acc: 0.848157 Loss: 0.455572 | Val Acc: 0.873677 loss: 0.367709\n",
            "[283/500] Train Acc: 0.848388 Loss: 0.454657 | Val Acc: 0.873945 loss: 0.365045\n",
            "saving model with acc 0.874\n",
            "[284/500] Train Acc: 0.847905 Loss: 0.454850 | Val Acc: 0.874262 loss: 0.364573\n",
            "saving model with acc 0.874\n",
            "[285/500] Train Acc: 0.847739 Loss: 0.454370 | Val Acc: 0.873953 loss: 0.367979\n",
            "[286/500] Train Acc: 0.848419 Loss: 0.454996 | Val Acc: 0.874547 loss: 0.365852\n",
            "saving model with acc 0.875\n",
            "[287/500] Train Acc: 0.848906 Loss: 0.453750 | Val Acc: 0.874449 loss: 0.367515\n",
            "[288/500] Train Acc: 0.848697 Loss: 0.453033 | Val Acc: 0.874579 loss: 0.365145\n",
            "saving model with acc 0.875\n",
            "[289/500] Train Acc: 0.849036 Loss: 0.453609 | Val Acc: 0.873774 loss: 0.366128\n",
            "[290/500] Train Acc: 0.848247 Loss: 0.453204 | Val Acc: 0.874799 loss: 0.364846\n",
            "saving model with acc 0.875\n",
            "[291/500] Train Acc: 0.848914 Loss: 0.453072 | Val Acc: 0.875482 loss: 0.363618\n",
            "saving model with acc 0.875\n",
            "[292/500] Train Acc: 0.848977 Loss: 0.452462 | Val Acc: 0.875124 loss: 0.364017\n",
            "[293/500] Train Acc: 0.849095 Loss: 0.452411 | Val Acc: 0.875311 loss: 0.364139\n",
            "[294/500] Train Acc: 0.849035 Loss: 0.451160 | Val Acc: 0.874896 loss: 0.364669\n",
            "[295/500] Train Acc: 0.849299 Loss: 0.450408 | Val Acc: 0.874978 loss: 0.365373\n",
            "[296/500] Train Acc: 0.849322 Loss: 0.451355 | Val Acc: 0.874799 loss: 0.363976\n",
            "[297/500] Train Acc: 0.849645 Loss: 0.450256 | Val Acc: 0.874758 loss: 0.364226\n",
            "[298/500] Train Acc: 0.849218 Loss: 0.449413 | Val Acc: 0.875815 loss: 0.362772\n",
            "saving model with acc 0.876\n",
            "[299/500] Train Acc: 0.849997 Loss: 0.449756 | Val Acc: 0.874677 loss: 0.363222\n",
            "[300/500] Train Acc: 0.849979 Loss: 0.449958 | Val Acc: 0.875750 loss: 0.362200\n",
            "[301/500] Train Acc: 0.850211 Loss: 0.448724 | Val Acc: 0.874970 loss: 0.363160\n",
            "[302/500] Train Acc: 0.850476 Loss: 0.448379 | Val Acc: 0.874872 loss: 0.364177\n",
            "[303/500] Train Acc: 0.849936 Loss: 0.448442 | Val Acc: 0.876148 loss: 0.361823\n",
            "saving model with acc 0.876\n",
            "[304/500] Train Acc: 0.849911 Loss: 0.448820 | Val Acc: 0.876409 loss: 0.360675\n",
            "saving model with acc 0.876\n",
            "[305/500] Train Acc: 0.850436 Loss: 0.448314 | Val Acc: 0.876254 loss: 0.358736\n",
            "[306/500] Train Acc: 0.849810 Loss: 0.447594 | Val Acc: 0.875986 loss: 0.361907\n",
            "[307/500] Train Acc: 0.850971 Loss: 0.446713 | Val Acc: 0.876279 loss: 0.361934\n",
            "[308/500] Train Acc: 0.850404 Loss: 0.447746 | Val Acc: 0.875839 loss: 0.360969\n",
            "[309/500] Train Acc: 0.850412 Loss: 0.447164 | Val Acc: 0.875921 loss: 0.360946\n",
            "[310/500] Train Acc: 0.850638 Loss: 0.447290 | Val Acc: 0.876425 loss: 0.360266\n",
            "saving model with acc 0.876\n",
            "[311/500] Train Acc: 0.851327 Loss: 0.445487 | Val Acc: 0.876750 loss: 0.360016\n",
            "saving model with acc 0.877\n",
            "[312/500] Train Acc: 0.851028 Loss: 0.445325 | Val Acc: 0.876693 loss: 0.359632\n",
            "[313/500] Train Acc: 0.851131 Loss: 0.445493 | Val Acc: 0.876718 loss: 0.359974\n",
            "[314/500] Train Acc: 0.851026 Loss: 0.445957 | Val Acc: 0.876823 loss: 0.360760\n",
            "saving model with acc 0.877\n",
            "[315/500] Train Acc: 0.851465 Loss: 0.445144 | Val Acc: 0.875636 loss: 0.361579\n",
            "[316/500] Train Acc: 0.851555 Loss: 0.445046 | Val Acc: 0.876823 loss: 0.360013\n",
            "[317/500] Train Acc: 0.851129 Loss: 0.444945 | Val Acc: 0.876864 loss: 0.360052\n",
            "saving model with acc 0.877\n",
            "[318/500] Train Acc: 0.850967 Loss: 0.444450 | Val Acc: 0.876596 loss: 0.359952\n",
            "[319/500] Train Acc: 0.851779 Loss: 0.444018 | Val Acc: 0.877140 loss: 0.359309\n",
            "saving model with acc 0.877\n",
            "[320/500] Train Acc: 0.851295 Loss: 0.443516 | Val Acc: 0.877376 loss: 0.360303\n",
            "saving model with acc 0.877\n",
            "[321/500] Train Acc: 0.851693 Loss: 0.443171 | Val Acc: 0.877506 loss: 0.358180\n",
            "saving model with acc 0.878\n",
            "[322/500] Train Acc: 0.851881 Loss: 0.442891 | Val Acc: 0.877474 loss: 0.357979\n",
            "[323/500] Train Acc: 0.851734 Loss: 0.443039 | Val Acc: 0.877018 loss: 0.359854\n",
            "[324/500] Train Acc: 0.852412 Loss: 0.441757 | Val Acc: 0.877181 loss: 0.359279\n",
            "[325/500] Train Acc: 0.851815 Loss: 0.442078 | Val Acc: 0.876449 loss: 0.359373\n",
            "[326/500] Train Acc: 0.852008 Loss: 0.442528 | Val Acc: 0.877571 loss: 0.358487\n",
            "saving model with acc 0.878\n",
            "[327/500] Train Acc: 0.852359 Loss: 0.441955 | Val Acc: 0.876726 loss: 0.358133\n",
            "[328/500] Train Acc: 0.852131 Loss: 0.442745 | Val Acc: 0.877563 loss: 0.356991\n",
            "[329/500] Train Acc: 0.852811 Loss: 0.440329 | Val Acc: 0.877888 loss: 0.357964\n",
            "saving model with acc 0.878\n",
            "[330/500] Train Acc: 0.852551 Loss: 0.441117 | Val Acc: 0.877506 loss: 0.358886\n",
            "[331/500] Train Acc: 0.852721 Loss: 0.440637 | Val Acc: 0.878059 loss: 0.356995\n",
            "saving model with acc 0.878\n",
            "[332/500] Train Acc: 0.853112 Loss: 0.439414 | Val Acc: 0.877588 loss: 0.357966\n",
            "[333/500] Train Acc: 0.852592 Loss: 0.440377 | Val Acc: 0.877368 loss: 0.358129\n",
            "[334/500] Train Acc: 0.853116 Loss: 0.439900 | Val Acc: 0.878067 loss: 0.356436\n",
            "saving model with acc 0.878\n",
            "[335/500] Train Acc: 0.852850 Loss: 0.439132 | Val Acc: 0.877482 loss: 0.357330\n",
            "[336/500] Train Acc: 0.853005 Loss: 0.439385 | Val Acc: 0.877067 loss: 0.357575\n",
            "[337/500] Train Acc: 0.852920 Loss: 0.439906 | Val Acc: 0.877742 loss: 0.356808\n",
            "[338/500] Train Acc: 0.853284 Loss: 0.438710 | Val Acc: 0.877661 loss: 0.356909\n",
            "[339/500] Train Acc: 0.853659 Loss: 0.439229 | Val Acc: 0.877775 loss: 0.355420\n",
            "[340/500] Train Acc: 0.853444 Loss: 0.438619 | Val Acc: 0.877661 loss: 0.356659\n",
            "[341/500] Train Acc: 0.853344 Loss: 0.437712 | Val Acc: 0.877140 loss: 0.358878\n",
            "[342/500] Train Acc: 0.853453 Loss: 0.438214 | Val Acc: 0.878409 loss: 0.355583\n",
            "saving model with acc 0.878\n",
            "[343/500] Train Acc: 0.853653 Loss: 0.438227 | Val Acc: 0.878132 loss: 0.355580\n",
            "[344/500] Train Acc: 0.853748 Loss: 0.437256 | Val Acc: 0.877709 loss: 0.356361\n",
            "[345/500] Train Acc: 0.853911 Loss: 0.437217 | Val Acc: 0.878563 loss: 0.355151\n",
            "saving model with acc 0.879\n",
            "[346/500] Train Acc: 0.853784 Loss: 0.437765 | Val Acc: 0.877596 loss: 0.356819\n",
            "[347/500] Train Acc: 0.853992 Loss: 0.435797 | Val Acc: 0.877335 loss: 0.356619\n",
            "[348/500] Train Acc: 0.853787 Loss: 0.435916 | Val Acc: 0.877994 loss: 0.356466\n",
            "[349/500] Train Acc: 0.853997 Loss: 0.436803 | Val Acc: 0.878140 loss: 0.354583\n",
            "[350/500] Train Acc: 0.853828 Loss: 0.436391 | Val Acc: 0.878872 loss: 0.355060\n",
            "saving model with acc 0.879\n",
            "[351/500] Train Acc: 0.853827 Loss: 0.436646 | Val Acc: 0.878677 loss: 0.356102\n",
            "[352/500] Train Acc: 0.854313 Loss: 0.435723 | Val Acc: 0.878100 loss: 0.355510\n",
            "[353/500] Train Acc: 0.854227 Loss: 0.435496 | Val Acc: 0.878531 loss: 0.354299\n",
            "[354/500] Train Acc: 0.854225 Loss: 0.435600 | Val Acc: 0.879189 loss: 0.352973\n",
            "saving model with acc 0.879\n",
            "[355/500] Train Acc: 0.854528 Loss: 0.435515 | Val Acc: 0.879319 loss: 0.354338\n",
            "saving model with acc 0.879\n",
            "[356/500] Train Acc: 0.854731 Loss: 0.434533 | Val Acc: 0.879124 loss: 0.352522\n",
            "[357/500] Train Acc: 0.855216 Loss: 0.433422 | Val Acc: 0.878441 loss: 0.354563\n",
            "[358/500] Train Acc: 0.854891 Loss: 0.433958 | Val Acc: 0.878490 loss: 0.354047\n",
            "[359/500] Train Acc: 0.854986 Loss: 0.432466 | Val Acc: 0.879181 loss: 0.353843\n",
            "[360/500] Train Acc: 0.854930 Loss: 0.433790 | Val Acc: 0.879043 loss: 0.353992\n",
            "[361/500] Train Acc: 0.854568 Loss: 0.434419 | Val Acc: 0.878677 loss: 0.355614\n",
            "[362/500] Train Acc: 0.855532 Loss: 0.432005 | Val Acc: 0.878466 loss: 0.354529\n",
            "[363/500] Train Acc: 0.855040 Loss: 0.433651 | Val Acc: 0.878888 loss: 0.352849\n",
            "[364/500] Train Acc: 0.855302 Loss: 0.432540 | Val Acc: 0.878986 loss: 0.352748\n",
            "[365/500] Train Acc: 0.855499 Loss: 0.432553 | Val Acc: 0.879620 loss: 0.352926\n",
            "saving model with acc 0.880\n",
            "[366/500] Train Acc: 0.855209 Loss: 0.432714 | Val Acc: 0.878783 loss: 0.353983\n",
            "[367/500] Train Acc: 0.855525 Loss: 0.431426 | Val Acc: 0.879929 loss: 0.351352\n",
            "saving model with acc 0.880\n",
            "[368/500] Train Acc: 0.855521 Loss: 0.431984 | Val Acc: 0.879384 loss: 0.353803\n",
            "[369/500] Train Acc: 0.855988 Loss: 0.431080 | Val Acc: 0.879262 loss: 0.352826\n",
            "[370/500] Train Acc: 0.855118 Loss: 0.432432 | Val Acc: 0.879165 loss: 0.352033\n",
            "[371/500] Train Acc: 0.855533 Loss: 0.431398 | Val Acc: 0.878962 loss: 0.353716\n",
            "[372/500] Train Acc: 0.856173 Loss: 0.430226 | Val Acc: 0.880140 loss: 0.351379\n",
            "saving model with acc 0.880\n",
            "[373/500] Train Acc: 0.855912 Loss: 0.430790 | Val Acc: 0.879872 loss: 0.350562\n",
            "[374/500] Train Acc: 0.856374 Loss: 0.429882 | Val Acc: 0.879693 loss: 0.351933\n",
            "[375/500] Train Acc: 0.855869 Loss: 0.430762 | Val Acc: 0.879604 loss: 0.352148\n",
            "[376/500] Train Acc: 0.856294 Loss: 0.429530 | Val Acc: 0.879856 loss: 0.351363\n",
            "[377/500] Train Acc: 0.856183 Loss: 0.430636 | Val Acc: 0.879742 loss: 0.352571\n",
            "[378/500] Train Acc: 0.856267 Loss: 0.430396 | Val Acc: 0.879945 loss: 0.350726\n",
            "[379/500] Train Acc: 0.856236 Loss: 0.430407 | Val Acc: 0.880466 loss: 0.349599\n",
            "saving model with acc 0.880\n",
            "[380/500] Train Acc: 0.856282 Loss: 0.429986 | Val Acc: 0.880612 loss: 0.349536\n",
            "saving model with acc 0.881\n",
            "[381/500] Train Acc: 0.856546 Loss: 0.428808 | Val Acc: 0.880035 loss: 0.352212\n",
            "[382/500] Train Acc: 0.856991 Loss: 0.428091 | Val Acc: 0.879921 loss: 0.351103\n",
            "[383/500] Train Acc: 0.855984 Loss: 0.430023 | Val Acc: 0.879799 loss: 0.352598\n",
            "[384/500] Train Acc: 0.856421 Loss: 0.428947 | Val Acc: 0.880523 loss: 0.350955\n",
            "[385/500] Train Acc: 0.856717 Loss: 0.428094 | Val Acc: 0.880271 loss: 0.351000\n",
            "[386/500] Train Acc: 0.856693 Loss: 0.427835 | Val Acc: 0.880677 loss: 0.351210\n",
            "saving model with acc 0.881\n",
            "[387/500] Train Acc: 0.856948 Loss: 0.427420 | Val Acc: 0.880384 loss: 0.351414\n",
            "[388/500] Train Acc: 0.856707 Loss: 0.427636 | Val Acc: 0.879823 loss: 0.351062\n",
            "[389/500] Train Acc: 0.856513 Loss: 0.428449 | Val Acc: 0.880311 loss: 0.350615\n",
            "[390/500] Train Acc: 0.856838 Loss: 0.428263 | Val Acc: 0.880466 loss: 0.350521\n",
            "[391/500] Train Acc: 0.857129 Loss: 0.427581 | Val Acc: 0.879848 loss: 0.352029\n",
            "[392/500] Train Acc: 0.856978 Loss: 0.425996 | Val Acc: 0.880514 loss: 0.350089\n",
            "[393/500] Train Acc: 0.857225 Loss: 0.424708 | Val Acc: 0.880344 loss: 0.350500\n",
            "[394/500] Train Acc: 0.857445 Loss: 0.426273 | Val Acc: 0.880197 loss: 0.351052\n",
            "[395/500] Train Acc: 0.857307 Loss: 0.425702 | Val Acc: 0.880067 loss: 0.350780\n",
            "[396/500] Train Acc: 0.857233 Loss: 0.425969 | Val Acc: 0.881067 loss: 0.347903\n",
            "saving model with acc 0.881\n",
            "[397/500] Train Acc: 0.857081 Loss: 0.426239 | Val Acc: 0.881084 loss: 0.347951\n",
            "saving model with acc 0.881\n",
            "[398/500] Train Acc: 0.857822 Loss: 0.424747 | Val Acc: 0.881246 loss: 0.348140\n",
            "saving model with acc 0.881\n",
            "[399/500] Train Acc: 0.857911 Loss: 0.425274 | Val Acc: 0.880718 loss: 0.349147\n",
            "[400/500] Train Acc: 0.857577 Loss: 0.424210 | Val Acc: 0.881100 loss: 0.348927\n",
            "[401/500] Train Acc: 0.857938 Loss: 0.424342 | Val Acc: 0.880994 loss: 0.348176\n",
            "[402/500] Train Acc: 0.857948 Loss: 0.424816 | Val Acc: 0.881010 loss: 0.347353\n",
            "[403/500] Train Acc: 0.857910 Loss: 0.423694 | Val Acc: 0.880864 loss: 0.348866\n",
            "[404/500] Train Acc: 0.857661 Loss: 0.425069 | Val Acc: 0.881157 loss: 0.347063\n",
            "[405/500] Train Acc: 0.858122 Loss: 0.425108 | Val Acc: 0.882067 loss: 0.346457\n",
            "saving model with acc 0.882\n",
            "[406/500] Train Acc: 0.858389 Loss: 0.423294 | Val Acc: 0.881807 loss: 0.348052\n",
            "[407/500] Train Acc: 0.858281 Loss: 0.423157 | Val Acc: 0.880954 loss: 0.347279\n",
            "[408/500] Train Acc: 0.858576 Loss: 0.423297 | Val Acc: 0.881141 loss: 0.346708\n",
            "[409/500] Train Acc: 0.858520 Loss: 0.423489 | Val Acc: 0.881571 loss: 0.346865\n",
            "[410/500] Train Acc: 0.858257 Loss: 0.422716 | Val Acc: 0.880856 loss: 0.347991\n",
            "[411/500] Train Acc: 0.858322 Loss: 0.422966 | Val Acc: 0.881384 loss: 0.347777\n",
            "[412/500] Train Acc: 0.857964 Loss: 0.424258 | Val Acc: 0.880945 loss: 0.348031\n",
            "[413/500] Train Acc: 0.859003 Loss: 0.421903 | Val Acc: 0.882059 loss: 0.347054\n",
            "[414/500] Train Acc: 0.858514 Loss: 0.422124 | Val Acc: 0.881100 loss: 0.346403\n",
            "[415/500] Train Acc: 0.858858 Loss: 0.420817 | Val Acc: 0.881124 loss: 0.345157\n",
            "[416/500] Train Acc: 0.859044 Loss: 0.420472 | Val Acc: 0.881059 loss: 0.347796\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Linear-1                 [-1, 4096]       1,761,280\n",
            "         LeakyReLU-2                 [-1, 4096]               0\n",
            "       BatchNorm1d-3                 [-1, 4096]           8,192\n",
            "           Dropout-4                 [-1, 4096]               0\n",
            "            Linear-5                 [-1, 2048]       8,390,656\n",
            "         LeakyReLU-6                 [-1, 2048]               0\n",
            "       BatchNorm1d-7                 [-1, 2048]           4,096\n",
            "           Dropout-8                 [-1, 2048]               0\n",
            "            Linear-9                 [-1, 2048]       4,196,352\n",
            "        LeakyReLU-10                 [-1, 2048]               0\n",
            "      BatchNorm1d-11                 [-1, 2048]           4,096\n",
            "          Dropout-12                 [-1, 2048]               0\n",
            "           Linear-13                 [-1, 1024]       2,098,176\n",
            "        LeakyReLU-14                 [-1, 1024]               0\n",
            "      BatchNorm1d-15                 [-1, 1024]           2,048\n",
            "          Dropout-16                 [-1, 1024]               0\n",
            "           Linear-17                  [-1, 512]         524,800\n",
            "        LeakyReLU-18                  [-1, 512]               0\n",
            "      BatchNorm1d-19                  [-1, 512]           1,024\n",
            "          Dropout-20                  [-1, 512]               0\n",
            "           Linear-21                  [-1, 128]          65,664\n",
            "        LeakyReLU-22                  [-1, 128]               0\n",
            "      BatchNorm1d-23                  [-1, 128]             256\n",
            "          Dropout-24                  [-1, 128]               0\n",
            "           Linear-25                   [-1, 39]           5,031\n",
            "================================================================\n",
            "Total params: 17,061,671\n",
            "Trainable params: 17,061,671\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.30\n",
            "Params size (MB): 65.09\n",
            "Estimated Total Size (MB): 65.39\n",
            "----------------------------------------------------------------\n",
            "best_train_acc: 0.8581221351150652\n",
            "best_val_acc: 0.8820674179228255\n",
            "best_train_loss:0.42510813728291935\n",
            "best_val_loss:0.3464571072542963\n",
            "config: {'BATCH_SIZE': 1024, 'INPUT_DIM': 429, 'OUTPUT_DIM': 39, 'NUM_EPOCH': 500, 'MODEL_PATH': './model.ckpt', 'MOMENTUM': 0.01, 'EARLY_STOP': 10, 'DROPOUT_PROB': 0.5, 'INPUT_DROPOUT_PROB': 0.2, 'TEST_SIZE': 0.1, 'WIGHT_DECAY': 0, 'NEGATIVE_SLOPE': 0.05}\n",
            "class 0 acc: 0.8992186254185935\n",
            "class 1 acc: 0.8236417910447761\n",
            "class 2 acc: 0.8299572039942938\n",
            "class 3 acc: 0.9307131966796545\n",
            "class 4 acc: 0.7906498844079116\n",
            "class 5 acc: 0.9082638362395754\n",
            "class 6 acc: 0.6955445544554455\n",
            "class 7 acc: 0.9143979412163077\n",
            "class 8 acc: 0.9100694444444445\n",
            "class 9 acc: 0.9320501603966171\n",
            "class 10 acc: 0.9628286491387126\n",
            "class 11 acc: 0.9171648163962425\n",
            "class 12 acc: 0.9063083240014931\n",
            "class 13 acc: 0.8820548260769407\n",
            "class 14 acc: 0.8623041940373927\n",
            "class 15 acc: 0.8253968253968254\n",
            "class 16 acc: 0.8766730401529637\n",
            "class 17 acc: 0.9101494275179507\n",
            "class 18 acc: 0.9145950280673617\n",
            "class 19 acc: 0.8850403739906503\n",
            "class 20 acc: 0.8484136310223267\n",
            "class 21 acc: 0.8375706214689266\n",
            "class 22 acc: 0.8411347517730496\n",
            "class 23 acc: 0.799249530956848\n",
            "class 24 acc: 0.6365979381443299\n",
            "class 25 acc: 0.6496350364963503\n",
            "class 26 acc: 0.7777777777777778\n",
            "class 27 acc: 0.7887788778877888\n",
            "class 28 acc: 0.8677110530896431\n",
            "class 29 acc: 0.843407900999524\n",
            "class 30 acc: 0.902788844621514\n",
            "class 31 acc: 0.823213156230234\n",
            "class 32 acc: 0.795\n",
            "class 33 acc: 0.9127018769096464\n",
            "class 34 acc: 0.791907514450867\n",
            "class 35 acc: 0.9344533838144817\n",
            "class 36 acc: 0.9198966408268734\n",
            "class 37 acc: 0.8799435028248588\n",
            "class 38 acc: 0.8963684181075485\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Hi7jTn3PX-m"
      },
      "source": [
        "## Testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NfUECMFCn5VG"
      },
      "source": [
        "Create a testing dataset, and load model from the saved checkpoint."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1PKjtAScPWtr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10568655-fcb0-4116-cc3a-82e410976365"
      },
      "source": [
        "# create testing dataset\n",
        "BATCH_SIZE = config['BATCH_SIZE']\n",
        "MODEL_PATH = config['MODEL_PATH']\n",
        "test = dataManager.getTestData()\n",
        "test_set = TIMITDataset(test, None)\n",
        "test_loader = DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "# create model and load weights from checkpoint\n",
        "device = get_device()\n",
        "model = Classifier().to(device)\n",
        "model.load_state_dict(torch.load(MODEL_PATH))\n",
        "\n",
        "# Make prediction.\n",
        "print('Predicting...')\n",
        "predict = []\n",
        "model.eval() # set the model to evaluation mode\n",
        "with torch.no_grad():\n",
        "    for i, data in enumerate(test_loader):\n",
        "        inputs = data\n",
        "        inputs = inputs.to(device)\n",
        "        outputs = model(inputs)\n",
        "        _, test_pred = torch.max(outputs, 1) # get the index of the class with the highest probability\n",
        "\n",
        "        for y in test_pred.cpu().numpy():\n",
        "            predict.append(y)\n",
        "\n",
        "# Write prediction to a CSV file.\n",
        "print('Saving...')\n",
        "with open('prediction.csv', 'w') as f:\n",
        "    f.write('Id,Class\\n')\n",
        "    for i, y in enumerate(predict):\n",
        "        f.write('{},{}\\n'.format(i, y))\n",
        "\n",
        "print('Finishing...')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading data ...\n",
            "Size of testing data: (451552, 429)\n",
            "Predicting...\n",
            "Saving...\n",
            "Finishing...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "source": [
        "# Reference\n",
        "- https://colab.research.google.com/github/ga642381/ML2021-Spring/blob/main/HW02/HW02-1.ipynb"
      ],
      "cell_type": "markdown",
      "metadata": {}
    }
  ]
}