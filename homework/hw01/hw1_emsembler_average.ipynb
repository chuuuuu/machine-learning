{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "feature_selection.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "wS_4-77xHk44",
        "g0pdrhQAO41L",
        "aQikz3IPiyPf",
        "nfrVxqJanGpE",
        "9tmCwXgpot3t"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mz0_QVkxCrX3"
      },
      "source": [
        "# **Homework 1: COVID-19 Cases Prediction (Regression)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMj55YDKG6ch",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "486a4022-3093-49a4-f2dd-0ebdc54653d7"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!gdown --id '19CCyCgJrUxtvgZF53vnctJiOJ23T5mqF' --output covid.train.csv\n",
        "!gdown --id '1CE240jLm2npU-tdz81-oVKEF3T2yfT1O' --output covid.test.csv"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=19CCyCgJrUxtvgZF53vnctJiOJ23T5mqF\n",
            "To: /content/covid.train.csv\n",
            "100% 2.00M/2.00M [00:00<00:00, 62.9MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1CE240jLm2npU-tdz81-oVKEF3T2yfT1O\n",
            "To: /content/covid.test.csv\n",
            "100% 651k/651k [00:00<00:00, 94.5MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uF-QTQLkv5h8"
      },
      "source": [
        "# PyTorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# For data preprocess\n",
        "import numpy as np\n",
        "import csv\n",
        "import os\n",
        "\n",
        "# For plotting\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import figure\n",
        "\n",
        "# set a random seed for reproducibility\n",
        "myseed = 42069\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "np.random.seed(myseed)\n",
        "torch.manual_seed(myseed)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(myseed)\n",
        "\n",
        "os.makedirs('models', exist_ok=True)\n",
        "\n",
        "config = {\n",
        "    # 'INPUT_DIM': 14,\n",
        "    'INPUT_DIM': 90,\n",
        "    'TRAIN_PATH': 'covid.train.csv',\n",
        "    'TEST_PATH': 'covid.test.csv',\n",
        "    'MODEL_PATH': 'models/model.pth',\n",
        "    'PRED_PATH': 'pred.csv',\n",
        "\n",
        "    'EPOCH_NUM': 30000,\n",
        "    'BATCH_SIZE': 4096,\n",
        "    'VAL_RATIO': 0.1,\n",
        "    'OPTIMIZER': 'Adam',\n",
        "    'OPTIM_PARAMS': {\n",
        "        'lr': 5e-2,\n",
        "        # 'weight_decay': 1e-4,\n",
        "    },\n",
        "    # 'DECAY_RATE': 0.999,\n",
        "    'DECAY_RATE': 1,\n",
        "    'MIN_LR': 1e-4,\n",
        "    'EARLY_STOP': 300,\n",
        "    'MODEL_NUM': 10,\n",
        "    'STATE': 1,\n",
        "}"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RaRGyPYGvvV5"
      },
      "source": [
        "class Drawer():\n",
        "    def plot_learning_curve(self, loss_record, title=''):\n",
        "        ''' Plot learning curve of your DNN (train & dev loss) '''\n",
        "        total_steps = len(loss_record['train'])\n",
        "        x_1 = range(total_steps)\n",
        "        x_2 = x_1[::len(loss_record['train']) // len(loss_record['val'])]\n",
        "        figure(figsize=(6, 4))\n",
        "        plt.plot(x_1, loss_record['train'], c='tab:red', label='train')\n",
        "        plt.plot(x_2, loss_record['val'], c='tab:cyan', label='val')\n",
        "        plt.ylim(0.0, 5.)\n",
        "        plt.xlabel('Training steps')\n",
        "        plt.ylabel('MSE loss')\n",
        "        plt.title('Learning curve of {}'.format(title))\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "    def plot_pred(self, dv_set, model, device, lim=35., preds=None, targets=None):\n",
        "        ''' Plot prediction of your DNN '''\n",
        "        if preds is None or targets is None:\n",
        "            model.eval()\n",
        "            preds, targets = [], []\n",
        "            for x, y in dv_set:\n",
        "                x, y = x.to(device), y.to(device)\n",
        "                with torch.no_grad():\n",
        "                    pred = model(x)\n",
        "                    preds.append(pred.detach().cpu())\n",
        "                    targets.append(y.detach().cpu())\n",
        "            preds = torch.cat(preds, dim=0).numpy()\n",
        "            targets = torch.cat(targets, dim=0).numpy()\n",
        "\n",
        "        figure(figsize=(5, 5))\n",
        "        plt.scatter(targets, preds, c='r', alpha=0.5)\n",
        "        plt.plot([-0.2, lim], [-0.2, lim], c='b')\n",
        "        plt.xlim(-0.2, lim)\n",
        "        plt.ylim(-0.2, lim)\n",
        "        plt.xlabel('ground truth value')\n",
        "        plt.ylabel('predicted value')\n",
        "        plt.title('Ground Truth v.s. Prediction')\n",
        "        plt.show()"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7uazKiUCwD9U"
      },
      "source": [
        "from sklearn.feature_selection import f_regression, SelectKBest, mutual_info_regression\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "class DataManager():\n",
        "    def __init__(self):\n",
        "        print('init data manager...')\n",
        "        TRAIN_PATH = config['TRAIN_PATH']\n",
        "        INPUT_DIM = config['INPUT_DIM']\n",
        "\n",
        "        with open(TRAIN_PATH, 'r') as f:\n",
        "            self.data = list(csv.reader(f))\n",
        "            self.data = np.array(self.data[1:])[:, 1:].astype(np.float32)\n",
        "\n",
        "        self.X = self.data[:, :-1]\n",
        "        self.y = self.data[:, -1]\n",
        "\n",
        "        selector = SelectKBest(f_regression, k=INPUT_DIM)\n",
        "        selector.fit(self.X, self.y)\n",
        "        self.cols = selector.get_support(indices=True)\n",
        "\n",
        "        self.X = self.X[:, self.cols]\n",
        "\n",
        "    def get_train_data(self):\n",
        "        print('getting train data...')\n",
        "        VAL_RATIO = config['VAL_RATIO']\n",
        "        STATE = config['STATE']\n",
        "\n",
        "        X_train, X_val, y_train, y_val = train_test_split(self.X, self.y, test_size=VAL_RATIO, random_state=STATE)\n",
        "        config['STATE'] += 1\n",
        "\n",
        "        return X_train, X_val, y_train, y_val\n",
        "    \n",
        "    def get_test_data(self):\n",
        "        print('getting test data...')\n",
        "        TEST_PATH = config['TEST_PATH']\n",
        "        with open(TEST_PATH, 'r') as f:\n",
        "            data = list(csv.reader(f))\n",
        "            data = np.array(data[1:])[:, 1:].astype(np.float32)\n",
        "        X_test = data[:, self.cols]\n",
        "        return X_test\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d3N7YzC72Ykp"
      },
      "source": [
        "class CovidDataset(Dataset):\n",
        "    def __init__(self, X, y=None):\n",
        "        print('init dataset...')\n",
        "        self.X = torch.from_numpy(X).float()\n",
        "        if y is None:\n",
        "            self.y = None\n",
        "        else:\n",
        "            self.y = torch.from_numpy(y).float()\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if self.y is None:\n",
        "            return self.X[idx]\n",
        "\n",
        "        return self.X[idx], self.y[idx]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oGJ7r5sQ4bTU"
      },
      "source": [
        "from torchsummary import summary\n",
        "\n",
        "class NeuralNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        print('init neural net...')\n",
        "        super(NeuralNet, self).__init__()\n",
        "\n",
        "        INPUT_DIM = config['INPUT_DIM']\n",
        "\n",
        "        # for input_dim == 14\n",
        "        # 12: 0.844\n",
        "        # 16: 0.860\n",
        "        # 14: 0.855\n",
        "        self.net = nn.Sequential(\n",
        "            # nn.BatchNorm1d(INPUT_DIM),\n",
        "            # nn.Linear(INPUT_DIM, 16),\n",
        "            # nn.ReLU(),\n",
        "            # nn.Linear(16, 1),\n",
        "            nn.BatchNorm1d(INPUT_DIM),\n",
        "            nn.Linear(INPUT_DIM, 16),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(16, 1),\n",
        "        )\n",
        "\n",
        "        self.criterion = nn.MSELoss(reduction='mean')\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x).squeeze(1)\n",
        "\n",
        "    def get_loss(self, y_pred, y):\n",
        "        return self.criterion(y_pred, y)\n",
        "\n",
        "    def summary(self):\n",
        "        INPUT_DIM = config['INPUT_DIM']\n",
        "        summary(self, (INPUT_DIM, ))"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cxNvo1sv5Qyb"
      },
      "source": [
        "class Trainer():\n",
        "    def __init__(self):\n",
        "        print('init trainer')\n",
        "        self.set_device()\n",
        "        self.set_model()\n",
        "        self.set_data_loader()\n",
        "        self.set_drawer()\n",
        "        self.set_optim()\n",
        "\n",
        "        self.loss_record = {'train': [], 'val': []}\n",
        "\n",
        "    def set_drawer(self):\n",
        "        self.drawer = Drawer()\n",
        "\n",
        "    def draw_learning_curve(self):\n",
        "        self.drawer.plot_learning_curve(self.loss_record, title='deep model')\n",
        "\n",
        "    def draw_val_results(self):\n",
        "        MODEL_PATH = config['MODEL_PATH']\n",
        "        del self.model\n",
        "        self.set_model()\n",
        "\n",
        "        ckpt = torch.load(MODEL_PATH, map_location='cpu')\n",
        "        self.model.load_state_dict(ckpt)\n",
        "        self.drawer.plot_pred(self.val_loader, self.model, self.device)\n",
        "\n",
        "    def pred_y_test(self):\n",
        "        print('predicting...')\n",
        "        BATCH_SIZE = config['BATCH_SIZE']\n",
        "        PRED_PATH = config['PRED_PATH']\n",
        "\n",
        "        X_test = self.dataManager.get_test_data()\n",
        "        test_loader = DataLoader(X_test, BATCH_SIZE, False, drop_last=False, num_workers=0, pin_memory=True)\n",
        "\n",
        "        self.model.eval()\n",
        "        y_preds = []\n",
        "        for x in test_loader:\n",
        "            x = x.to(self.device)\n",
        "            with torch.no_grad():\n",
        "                y_pred = self.model(x)\n",
        "                y_preds.append(y_pred.detach().cpu())\n",
        "        \n",
        "        y_preds = torch.cat(y_preds, dim=0).numpy()\n",
        "        return y_preds\n",
        "\n",
        "    def set_device(self):\n",
        "        ''' Get device (if GPU is available, use GPU) '''\n",
        "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "    def set_data_loader(self):\n",
        "        BATCH_SIZE = config['BATCH_SIZE']\n",
        "        self.dataManager = DataManager()\n",
        "        X_train, X_val, y_train, y_val = self.dataManager.get_train_data()   \n",
        "\n",
        "        train_set = CovidDataset(X_train, y_train)\n",
        "        self.train_loader = DataLoader(train_set, BATCH_SIZE, True, drop_last=False, num_workers=0, pin_memory=True)\n",
        "\n",
        "        val_set = CovidDataset(X_val, y_val)\n",
        "        self.val_loader = DataLoader(val_set, BATCH_SIZE, False, drop_last=False, num_workers=0, pin_memory=True)\n",
        "\n",
        "    def set_model(self):\n",
        "        self.model = NeuralNet().to(self.device)\n",
        "\n",
        "    def set_optim(self):\n",
        "        OPTIMIZER = config['OPTIMIZER']\n",
        "        OPTIM_PARAMS = config['OPTIM_PARAMS']\n",
        "\n",
        "        self.optimizer = getattr(torch.optim, OPTIMIZER)(self.model.parameters(), **OPTIM_PARAMS)\n",
        "\n",
        "    def train(self):\n",
        "        EPOCH_NUM = config['EPOCH_NUM']\n",
        "        MODEL_PATH = config['MODEL_PATH']\n",
        "        EARLY_STOP = config['EARLY_STOP']\n",
        "\n",
        "        min_val_loss = float('inf')\n",
        "        early_stop_count = 0\n",
        "        for epoch in range(EPOCH_NUM):\n",
        "            self.model.train()\n",
        "            for x, y in self.train_loader:\n",
        "                self.optimizer.zero_grad()\n",
        "                x, y = x.to(self.device), y.to(self.device)\n",
        "                y_pred = self.model(x)\n",
        "                loss = self.model.get_loss(y_pred, y)\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "\n",
        "            self.update_lr()\n",
        "            val_loss = self.get_loss(self.val_loader)\n",
        "            train_loss = self.get_loss(self.train_loader)\n",
        "            if epoch % 100 == 0:\n",
        "                print(f'epoch: {epoch+1}, train_loss: {train_loss}, val_loss: {val_loss}')\n",
        "\n",
        "            if val_loss < min_val_loss:\n",
        "                min_val_loss = val_loss\n",
        "                print(f'Saving model, epoch: {epoch+1}, train_loss: {train_loss}, val_loss: {val_loss}')\n",
        "                torch.save(self.model.state_dict(), MODEL_PATH)\n",
        "                early_stop_cnt = 0\n",
        "\n",
        "            else:\n",
        "                early_stop_cnt += 1\n",
        "\n",
        "            self.loss_record['val'].append(val_loss)\n",
        "            self.loss_record['train'].append(train_loss)\n",
        "\n",
        "            if early_stop_cnt > EARLY_STOP:\n",
        "                break\n",
        "\n",
        "        # print(f'Saving model, epoch: {epoch+1}, train_loss: {train_loss}, val_loss: {val_loss}')\n",
        "        # torch.save(self.model.state_dict(), MODEL_PATH)\n",
        "        ckpt = torch.load(MODEL_PATH, map_location='cpu')  # Load your best model\n",
        "        self.model.load_state_dict(ckpt)\n",
        "\n",
        "        print(f'finished training after {epoch+1} epochs')\n",
        "        self.model.summary()\n",
        "\n",
        "    \n",
        "    def update_lr(self):\n",
        "        DECAY_RATE = config['DECAY_RATE']\n",
        "        MIN_LR = config['MIN_LR']\n",
        "        for param_group in self.optimizer.param_groups:\n",
        "            param_group['lr'] = param_group['lr'] * DECAY_RATE\n",
        "            param_group['lr'] = max(MIN_LR, param_group['lr'])\n",
        "\n",
        "    def get_loss(self, loader):\n",
        "        self.model.eval()\n",
        "        total_loss = 0\n",
        "        for x, y in loader:\n",
        "            x, y = x.to(self.device), y.to(self.device)\n",
        "            with torch.no_grad():\n",
        "                y_pred = self.model(x)\n",
        "                loss = self.model.get_loss(y_pred, y)\n",
        "            \n",
        "            total_loss += loss.detach().cpu().item() * len(x)\n",
        "        total_loss /= len(loader.dataset)\n",
        "\n",
        "        return total_loss"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ikKiqeHNUTUK"
      },
      "source": [
        "class Emssembler():\n",
        "    def __init__(self):\n",
        "        MODEL_NUM = config['MODEL_NUM']\n",
        "        self.trainers = []\n",
        "        for i in range(MODEL_NUM):\n",
        "            self.trainers.append(Trainer())\n",
        "\n",
        "    def train(self):\n",
        "        MODEL_NUM = config['MODEL_NUM']\n",
        "        for trainer in self.trainers:\n",
        "            trainer.train()\n",
        "\n",
        "    def pred(self):\n",
        "        MODEL_NUM = config['MODEL_NUM']\n",
        "        PRED_PATH = config['PRED_PATH']\n",
        "        \n",
        "        y_preds = None\n",
        "        for trainer in self.trainers:\n",
        "            if y_preds is None:\n",
        "                y_preds = trainer.pred_y_test()\n",
        "            else:\n",
        "                y_preds += trainer.pred_y_test()\n",
        "\n",
        "        y_preds /= MODEL_NUM\n",
        "\n",
        "        with open(PRED_PATH, 'w') as f:\n",
        "            writer = csv.writer(f)\n",
        "            writer.writerow(['id', 'tested_positive'])\n",
        "            for i, p in enumerate(y_preds):\n",
        "                writer.writerow([i, p])\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "bMBMUOu0ng0Y",
        "outputId": "742bebc7-8dee-4dc8-b83c-769d930b7101"
      },
      "source": [
        "# trainer = Trainer()\n",
        "# trainer.train()\n",
        "# trainer.draw_learning_curve()\n",
        "# trainer.draw_val_results()\n",
        "# trainer.pred_y_test()\n",
        "emssembler = Emssembler()\n",
        "emssembler.train()\n",
        "emssembler.pred()\n",
        "print(f'config: {config}')\n",
        "\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "init trainer\n",
            "init neural net...\n",
            "init data manager...\n",
            "getting train data...\n",
            "init dataset...\n",
            "init dataset...\n",
            "init trainer\n",
            "init neural net...\n",
            "init data manager...\n",
            "getting train data...\n",
            "init dataset...\n",
            "init dataset...\n",
            "init trainer\n",
            "init neural net...\n",
            "init data manager...\n",
            "getting train data...\n",
            "init dataset...\n",
            "init dataset...\n",
            "init trainer\n",
            "init neural net...\n",
            "init data manager...\n",
            "getting train data...\n",
            "init dataset...\n",
            "init dataset...\n",
            "init trainer\n",
            "init neural net...\n",
            "init data manager...\n",
            "getting train data...\n",
            "init dataset...\n",
            "init dataset...\n",
            "init trainer\n",
            "init neural net...\n",
            "init data manager...\n",
            "getting train data...\n",
            "init dataset...\n",
            "init dataset...\n",
            "init trainer\n",
            "init neural net...\n",
            "init data manager...\n",
            "getting train data...\n",
            "init dataset...\n",
            "init dataset...\n",
            "init trainer\n",
            "init neural net...\n",
            "init data manager...\n",
            "getting train data...\n",
            "init dataset...\n",
            "init dataset...\n",
            "init trainer\n",
            "init neural net...\n",
            "init data manager...\n",
            "getting train data...\n",
            "init dataset...\n",
            "init dataset...\n",
            "init trainer\n",
            "init neural net...\n",
            "init data manager...\n",
            "getting train data...\n",
            "init dataset...\n",
            "init dataset...\n",
            "epoch: 1, train_loss: 212.09690856933594, val_loss: 209.4459991455078\n",
            "Saving model, epoch: 1, train_loss: 212.09690856933594, val_loss: 209.4459991455078\n",
            "Saving model, epoch: 2, train_loss: 159.77122497558594, val_loss: 158.0316162109375\n",
            "Saving model, epoch: 3, train_loss: 85.23641204833984, val_loss: 83.5174789428711\n",
            "Saving model, epoch: 4, train_loss: 33.00653839111328, val_loss: 31.39931869506836\n",
            "Saving model, epoch: 10, train_loss: 20.869508743286133, val_loss: 20.82136344909668\n",
            "Saving model, epoch: 18, train_loss: 20.456989288330078, val_loss: 19.473011016845703\n",
            "Saving model, epoch: 19, train_loss: 15.571864128112793, val_loss: 14.791425704956055\n",
            "Saving model, epoch: 22, train_loss: 13.49113941192627, val_loss: 13.15392780303955\n",
            "Saving model, epoch: 23, train_loss: 11.734114646911621, val_loss: 11.399767875671387\n",
            "Saving model, epoch: 31, train_loss: 9.903642654418945, val_loss: 9.308976173400879\n",
            "Saving model, epoch: 32, train_loss: 7.331693649291992, val_loss: 6.817150115966797\n",
            "Saving model, epoch: 33, train_loss: 6.368098735809326, val_loss: 5.974486351013184\n",
            "Saving model, epoch: 36, train_loss: 5.827244281768799, val_loss: 5.609752178192139\n",
            "Saving model, epoch: 37, train_loss: 5.586349010467529, val_loss: 5.32923698425293\n",
            "Saving model, epoch: 44, train_loss: 4.862543106079102, val_loss: 4.617474555969238\n",
            "Saving model, epoch: 45, train_loss: 4.089585781097412, val_loss: 3.9585163593292236\n",
            "Saving model, epoch: 46, train_loss: 3.863833427429199, val_loss: 3.862776517868042\n",
            "Saving model, epoch: 49, train_loss: 3.6085832118988037, val_loss: 3.7564663887023926\n",
            "Saving model, epoch: 50, train_loss: 3.464120388031006, val_loss: 3.5757129192352295\n",
            "Saving model, epoch: 56, train_loss: 3.0417895317077637, val_loss: 3.315199136734009\n",
            "Saving model, epoch: 57, train_loss: 2.8556220531463623, val_loss: 3.2049307823181152\n",
            "Saving model, epoch: 60, train_loss: 2.7726495265960693, val_loss: 3.1986660957336426\n",
            "Saving model, epoch: 61, train_loss: 2.635270595550537, val_loss: 3.024231433868408\n",
            "Saving model, epoch: 62, train_loss: 2.5592644214630127, val_loss: 2.89882493019104\n",
            "Saving model, epoch: 63, train_loss: 2.582369565963745, val_loss: 2.8753702640533447\n",
            "Saving model, epoch: 65, train_loss: 2.5902416706085205, val_loss: 2.833235740661621\n",
            "Saving model, epoch: 66, train_loss: 2.4641647338867188, val_loss: 2.7100086212158203\n",
            "Saving model, epoch: 67, train_loss: 2.326930284500122, val_loss: 2.5888423919677734\n",
            "Saving model, epoch: 68, train_loss: 2.2553069591522217, val_loss: 2.5423331260681152\n",
            "Saving model, epoch: 70, train_loss: 2.2173960208892822, val_loss: 2.531364679336548\n",
            "Saving model, epoch: 71, train_loss: 2.147386074066162, val_loss: 2.4460999965667725\n",
            "Saving model, epoch: 72, train_loss: 2.0733494758605957, val_loss: 2.3429105281829834\n",
            "Saving model, epoch: 73, train_loss: 2.0413615703582764, val_loss: 2.280533790588379\n",
            "Saving model, epoch: 74, train_loss: 2.03798508644104, val_loss: 2.254490375518799\n",
            "Saving model, epoch: 75, train_loss: 2.014115333557129, val_loss: 2.220365285873413\n",
            "Saving model, epoch: 76, train_loss: 1.9519051313400269, val_loss: 2.1607754230499268\n",
            "Saving model, epoch: 77, train_loss: 1.8850762844085693, val_loss: 2.105457305908203\n",
            "Saving model, epoch: 78, train_loss: 1.8503810167312622, val_loss: 2.085315465927124\n",
            "Saving model, epoch: 80, train_loss: 1.8149789571762085, val_loss: 2.0613439083099365\n",
            "Saving model, epoch: 81, train_loss: 1.769924521446228, val_loss: 2.002758026123047\n",
            "Saving model, epoch: 82, train_loss: 1.7297515869140625, val_loss: 1.9434535503387451\n",
            "Saving model, epoch: 83, train_loss: 1.7107634544372559, val_loss: 1.9075398445129395\n",
            "Saving model, epoch: 84, train_loss: 1.6974306106567383, val_loss: 1.884130597114563\n",
            "Saving model, epoch: 85, train_loss: 1.6697410345077515, val_loss: 1.8548239469528198\n",
            "Saving model, epoch: 86, train_loss: 1.63246750831604, val_loss: 1.8228846788406372\n",
            "Saving model, epoch: 87, train_loss: 1.6046466827392578, val_loss: 1.8033299446105957\n",
            "Saving model, epoch: 88, train_loss: 1.5894821882247925, val_loss: 1.7950903177261353\n",
            "Saving model, epoch: 89, train_loss: 1.5725246667861938, val_loss: 1.7795538902282715\n",
            "Saving model, epoch: 90, train_loss: 1.5467255115509033, val_loss: 1.749210000038147\n",
            "Saving model, epoch: 91, train_loss: 1.5221794843673706, val_loss: 1.71722412109375\n",
            "Saving model, epoch: 92, train_loss: 1.5072485208511353, val_loss: 1.6956791877746582\n",
            "Saving model, epoch: 93, train_loss: 1.4945921897888184, val_loss: 1.6799553632736206\n",
            "Saving model, epoch: 94, train_loss: 1.4752520322799683, val_loss: 1.662227749824524\n",
            "Saving model, epoch: 95, train_loss: 1.4529160261154175, val_loss: 1.6454907655715942\n",
            "Saving model, epoch: 96, train_loss: 1.4362529516220093, val_loss: 1.6361632347106934\n",
            "Saving model, epoch: 97, train_loss: 1.4246835708618164, val_loss: 1.6304742097854614\n",
            "Saving model, epoch: 98, train_loss: 1.410770297050476, val_loss: 1.6182142496109009\n",
            "Saving model, epoch: 99, train_loss: 1.3933970928192139, val_loss: 1.5979864597320557\n",
            "Saving model, epoch: 100, train_loss: 1.3784449100494385, val_loss: 1.577561616897583\n",
            "epoch: 101, train_loss: 1.3675309419631958, val_loss: 1.5619152784347534\n",
            "Saving model, epoch: 101, train_loss: 1.3675309419631958, val_loss: 1.5619152784347534\n",
            "Saving model, epoch: 102, train_loss: 1.3559612035751343, val_loss: 1.5479835271835327\n",
            "Saving model, epoch: 103, train_loss: 1.3415415287017822, val_loss: 1.5335791110992432\n",
            "Saving model, epoch: 104, train_loss: 1.3278642892837524, val_loss: 1.5214263200759888\n",
            "Saving model, epoch: 105, train_loss: 1.3174151182174683, val_loss: 1.511552095413208\n",
            "Saving model, epoch: 106, train_loss: 1.307584285736084, val_loss: 1.5004199743270874\n",
            "Saving model, epoch: 107, train_loss: 1.2960561513900757, val_loss: 1.4857712984085083\n",
            "Saving model, epoch: 108, train_loss: 1.2845813035964966, val_loss: 1.4700229167938232\n",
            "Saving model, epoch: 109, train_loss: 1.2754802703857422, val_loss: 1.4564841985702515\n",
            "Saving model, epoch: 110, train_loss: 1.2669614553451538, val_loss: 1.444799542427063\n",
            "Saving model, epoch: 111, train_loss: 1.25717294216156, val_loss: 1.4334237575531006\n",
            "Saving model, epoch: 112, train_loss: 1.247450590133667, val_loss: 1.4233511686325073\n",
            "Saving model, epoch: 113, train_loss: 1.2393956184387207, val_loss: 1.4153192043304443\n",
            "Saving model, epoch: 114, train_loss: 1.2317746877670288, val_loss: 1.407262921333313\n",
            "Saving model, epoch: 115, train_loss: 1.2233730554580688, val_loss: 1.3977280855178833\n",
            "Saving model, epoch: 116, train_loss: 1.2152787446975708, val_loss: 1.388170838356018\n",
            "Saving model, epoch: 117, train_loss: 1.2083603143692017, val_loss: 1.3802787065505981\n",
            "Saving model, epoch: 118, train_loss: 1.2016584873199463, val_loss: 1.3738120794296265\n",
            "Saving model, epoch: 119, train_loss: 1.1944069862365723, val_loss: 1.367867112159729\n",
            "Saving model, epoch: 120, train_loss: 1.1873449087142944, val_loss: 1.3628857135772705\n",
            "Saving model, epoch: 121, train_loss: 1.1810939311981201, val_loss: 1.3585997819900513\n",
            "Saving model, epoch: 122, train_loss: 1.1749480962753296, val_loss: 1.353596806526184\n",
            "Saving model, epoch: 123, train_loss: 1.1685404777526855, val_loss: 1.3474843502044678\n",
            "Saving model, epoch: 124, train_loss: 1.1625068187713623, val_loss: 1.3413431644439697\n",
            "Saving model, epoch: 125, train_loss: 1.1570709943771362, val_loss: 1.3357816934585571\n",
            "Saving model, epoch: 126, train_loss: 1.1515709161758423, val_loss: 1.3308796882629395\n",
            "Saving model, epoch: 127, train_loss: 1.1458603143692017, val_loss: 1.326492428779602\n",
            "Saving model, epoch: 128, train_loss: 1.1404722929000854, val_loss: 1.322667121887207\n",
            "Saving model, epoch: 129, train_loss: 1.1355335712432861, val_loss: 1.318824291229248\n",
            "Saving model, epoch: 130, train_loss: 1.1306202411651611, val_loss: 1.3142606019973755\n",
            "Saving model, epoch: 131, train_loss: 1.1257323026657104, val_loss: 1.309095025062561\n",
            "Saving model, epoch: 132, train_loss: 1.1212289333343506, val_loss: 1.3040456771850586\n",
            "Saving model, epoch: 133, train_loss: 1.116907000541687, val_loss: 1.2992724180221558\n",
            "Saving model, epoch: 134, train_loss: 1.1124764680862427, val_loss: 1.2945724725723267\n",
            "Saving model, epoch: 135, train_loss: 1.1080890893936157, val_loss: 1.2899863719940186\n",
            "Saving model, epoch: 136, train_loss: 1.1039670705795288, val_loss: 1.2855310440063477\n",
            "Saving model, epoch: 137, train_loss: 1.0999786853790283, val_loss: 1.2808984518051147\n",
            "Saving model, epoch: 138, train_loss: 1.0959886312484741, val_loss: 1.275904655456543\n",
            "Saving model, epoch: 139, train_loss: 1.0921390056610107, val_loss: 1.2709089517593384\n",
            "Saving model, epoch: 140, train_loss: 1.088432788848877, val_loss: 1.266269326210022\n",
            "Saving model, epoch: 141, train_loss: 1.0846768617630005, val_loss: 1.2619520425796509\n",
            "Saving model, epoch: 142, train_loss: 1.0809117555618286, val_loss: 1.2578637599945068\n",
            "Saving model, epoch: 143, train_loss: 1.0772703886032104, val_loss: 1.2540746927261353\n",
            "Saving model, epoch: 144, train_loss: 1.0737348794937134, val_loss: 1.2504072189331055\n",
            "Saving model, epoch: 145, train_loss: 1.0702399015426636, val_loss: 1.2466826438903809\n",
            "Saving model, epoch: 146, train_loss: 1.0668143033981323, val_loss: 1.2429076433181763\n",
            "Saving model, epoch: 147, train_loss: 1.0634815692901611, val_loss: 1.239065170288086\n",
            "Saving model, epoch: 148, train_loss: 1.0601720809936523, val_loss: 1.2352180480957031\n",
            "Saving model, epoch: 149, train_loss: 1.0568490028381348, val_loss: 1.2312886714935303\n",
            "Saving model, epoch: 150, train_loss: 1.0535950660705566, val_loss: 1.2273995876312256\n",
            "Saving model, epoch: 151, train_loss: 1.0504156351089478, val_loss: 1.2234299182891846\n",
            "Saving model, epoch: 152, train_loss: 1.0472376346588135, val_loss: 1.219407558441162\n",
            "Saving model, epoch: 153, train_loss: 1.044109582901001, val_loss: 1.2154463529586792\n",
            "Saving model, epoch: 154, train_loss: 1.0410361289978027, val_loss: 1.211647391319275\n",
            "Saving model, epoch: 155, train_loss: 1.0379694700241089, val_loss: 1.2080663442611694\n",
            "Saving model, epoch: 156, train_loss: 1.0348705053329468, val_loss: 1.2046582698822021\n",
            "Saving model, epoch: 157, train_loss: 1.0318092107772827, val_loss: 1.201416015625\n",
            "Saving model, epoch: 158, train_loss: 1.0287892818450928, val_loss: 1.1982908248901367\n",
            "Saving model, epoch: 159, train_loss: 1.0257750749588013, val_loss: 1.195383906364441\n",
            "Saving model, epoch: 160, train_loss: 1.022819995880127, val_loss: 1.1926090717315674\n",
            "Saving model, epoch: 161, train_loss: 1.0199339389801025, val_loss: 1.1899336576461792\n",
            "Saving model, epoch: 162, train_loss: 1.0170725584030151, val_loss: 1.1871131658554077\n",
            "Saving model, epoch: 163, train_loss: 1.014260172843933, val_loss: 1.184215784072876\n",
            "Saving model, epoch: 164, train_loss: 1.0115171670913696, val_loss: 1.1812844276428223\n",
            "Saving model, epoch: 165, train_loss: 1.0088289976119995, val_loss: 1.1784465312957764\n",
            "Saving model, epoch: 166, train_loss: 1.0061864852905273, val_loss: 1.1756075620651245\n",
            "Saving model, epoch: 167, train_loss: 1.003577470779419, val_loss: 1.1727919578552246\n",
            "Saving model, epoch: 168, train_loss: 1.0010062456130981, val_loss: 1.1699838638305664\n",
            "Saving model, epoch: 169, train_loss: 0.9984568953514099, val_loss: 1.1671392917633057\n",
            "Saving model, epoch: 170, train_loss: 0.9959514737129211, val_loss: 1.1643240451812744\n",
            "Saving model, epoch: 171, train_loss: 0.9934911727905273, val_loss: 1.1614768505096436\n",
            "Saving model, epoch: 172, train_loss: 0.9910743832588196, val_loss: 1.158683180809021\n",
            "Saving model, epoch: 173, train_loss: 0.9886939525604248, val_loss: 1.1559215784072876\n",
            "Saving model, epoch: 174, train_loss: 0.9863502979278564, val_loss: 1.1531927585601807\n",
            "Saving model, epoch: 175, train_loss: 0.9840436577796936, val_loss: 1.1504732370376587\n",
            "Saving model, epoch: 176, train_loss: 0.9817408919334412, val_loss: 1.1477446556091309\n",
            "Saving model, epoch: 177, train_loss: 0.9794307947158813, val_loss: 1.1449991464614868\n",
            "Saving model, epoch: 178, train_loss: 0.9771490097045898, val_loss: 1.142407774925232\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-3e368130d37d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# trainer.pred_y_test()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0memssembler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEmssembler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0memssembler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0memssembler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'config: {config}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-19-c2fd6d0bdcf6>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mMODEL_NUM\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'MODEL_NUM'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m             \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-18-3107287739e4>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPOCH_NUM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m                 \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    515\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-4ecc9af51f8b>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}