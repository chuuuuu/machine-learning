{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "hw13_Network_Compression-2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5150aa0d04d744ff92f42f7bc3efe328": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ecdaf7eef02543989ff7fec6d2f0abff",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_babdeda82c86453c8902d93b444f2dcf",
              "IPY_MODEL_9b34fdfa757c4fecaa93ff4f1baaae30"
            ]
          }
        },
        "ecdaf7eef02543989ff7fec6d2f0abff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "babdeda82c86453c8902d93b444f2dcf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_08c685c3002e4d27b4ce2e2e870edabc",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 54,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 54,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5f0fae6b1fff401697431295ee847b3a"
          }
        },
        "9b34fdfa757c4fecaa93ff4f1baaae30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4e91693b9907466d831e2fd4e6492fcc",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 54/54 [00:58&lt;00:00,  1.08s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bcb23f24b1fa43bba173002c9dfcbf09"
          }
        },
        "08c685c3002e4d27b4ce2e2e870edabc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5f0fae6b1fff401697431295ee847b3a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4e91693b9907466d831e2fd4e6492fcc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bcb23f24b1fa43bba173002c9dfcbf09": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "416fc27caaf8499992a401f37c10c122": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_def91a183bb647d1853565010763b2e5",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ab6dad2c7c0746c6838a20988103186a",
              "IPY_MODEL_26af8132ca174a3c8b4e682f06df54cb"
            ]
          }
        },
        "def91a183bb647d1853565010763b2e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ab6dad2c7c0746c6838a20988103186a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e10aba05e7bf492e83c5c1507e49f68d",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 77,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 77,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a5183fe0808e4564b747efad1eb5ec24"
          }
        },
        "26af8132ca174a3c8b4e682f06df54cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8e778c1a017f48b696e82598fdc6aadf",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 77/77 [01:54&lt;00:00,  1.49s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_07a0dacbd8be459cb9e2d1342b73e8fe"
          }
        },
        "e10aba05e7bf492e83c5c1507e49f68d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a5183fe0808e4564b747efad1eb5ec24": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8e778c1a017f48b696e82598fdc6aadf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "07a0dacbd8be459cb9e2d1342b73e8fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c8766e29597543d596b6e3ad9e93f29c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d8372e1d6f5a480582b67137e3a98e6a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e31bdbe15a0b4b2a8526619c5969e166",
              "IPY_MODEL_3cdc51151e8346349826b7274ce34418"
            ]
          }
        },
        "d8372e1d6f5a480582b67137e3a98e6a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e31bdbe15a0b4b2a8526619c5969e166": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_668e552ededd4ab89fce20f47fe534c7",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 6,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 6,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6df1a00671bc4dfbb55a74d88c468ea8"
          }
        },
        "3cdc51151e8346349826b7274ce34418": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a9350e7bd543445eb8625faa07ccf413",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 6/6 [00:04&lt;00:00,  1.23it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6a3dee83d40a44329387feecea29a47d"
          }
        },
        "668e552ededd4ab89fce20f47fe534c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6df1a00671bc4dfbb55a74d88c468ea8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a9350e7bd543445eb8625faa07ccf413": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6a3dee83d40a44329387feecea29a47d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "234edd1c12b94a01ac011264a707f899": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1750851ccef446f9a957ceb91c19ded3",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e61511b20d9d424aabb810db33fd3b15",
              "IPY_MODEL_a2fa96d712104a6da3a8b65864b680c7"
            ]
          }
        },
        "1750851ccef446f9a957ceb91c19ded3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e61511b20d9d424aabb810db33fd3b15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_0303ed92770b4965a3b03b3fd0868b5b",
            "_dom_classes": [],
            "description": "  3%",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 77,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 2,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7c7bd973273041898848a6f1baaeac3c"
          }
        },
        "a2fa96d712104a6da3a8b65864b680c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3a12bd0ee2474b1a96f936c24440c70d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 2/77 [00:03&lt;01:53,  1.52s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_068e9a50df87483ca03ccfff85a1ea4d"
          }
        },
        "0303ed92770b4965a3b03b3fd0868b5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7c7bd973273041898848a6f1baaeac3c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3a12bd0ee2474b1a96f936c24440c70d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "068e9a50df87483ca03ccfff85a1ea4d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "df075f36ad104e818390db83821aa9a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2d9b7a2778fd46e1b00aa9d22b640f3e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3444098ecbd94f6faf015843a67c33a1",
              "IPY_MODEL_1658a2a841744df191363696473430d6"
            ]
          }
        },
        "2d9b7a2778fd46e1b00aa9d22b640f3e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3444098ecbd94f6faf015843a67c33a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f818870110094436a9a55079bbcc0623",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 27,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 27,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0a646e77c4f349e0bbd604080013fa5c"
          }
        },
        "1658a2a841744df191363696473430d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_eb3d0a6229bb46c7aff44452289ec546",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 27/27 [13:48&lt;00:00, 30.67s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_24501e8267ad44479bcc3742f1420dc4"
          }
        },
        "f818870110094436a9a55079bbcc0623": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0a646e77c4f349e0bbd604080013fa5c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "eb3d0a6229bb46c7aff44452289ec546": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "24501e8267ad44479bcc3742f1420dc4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AeGB_b7IbKs1"
      },
      "source": [
        "Homework 13 - Network Compression\n",
        "===\n",
        "\n",
        "> Author: Arvin Liu (r09922071@ntu.edu.tw), this colab is modified from ML2021-HW3\n",
        "\n",
        "If you have any questions, feel free to ask: ntu-ml-2021spring-ta@googlegroups.com"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JY4wUHY3bNx1"
      },
      "source": [
        "## **Intro**\n",
        "\n",
        "HW13 is about network compression\n",
        "\n",
        "There are many types of Network/Model Compression,  here we introduce two:\n",
        "* Knowledge Distillation\n",
        "* Design Architecture\n",
        "\n",
        "\n",
        "The process of this notebook is as follows: <br/>\n",
        "1. Introduce depthwise, pointwise and group convolution in MobileNet.\n",
        "2. Design the model of this colab\n",
        "3. Introduce Knowledge-Distillation\n",
        "4. Set up TeacherNet and it would be helpful in training\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ilEnbgu-0CmB"
      },
      "source": [
        "## reset colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sMCMOQfc0CU6"
      },
      "source": [
        "# # lookup the pid table\n",
        "# !ps\n",
        "# # kill jupyter-notebook process\n",
        "# !kill 2008"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8FAsb3Mjh25Z"
      },
      "source": [
        "## GPU && RAM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a3bnxMYkh3Nb",
        "outputId": "d07bdc89-df08-4761-b7cf-c847a04dc402"
      },
      "source": [
        "# check if using a good GPU(P100 or V100)\n",
        "gpu_info = !nvidia-smi\n",
        "gpu_info = \"\\n\".join(gpu_info)\n",
        "if gpu_info.find(\"failed\") >= 0:\n",
        "  print(\"Select the Runtime > 'Change runtime type' menu to enable a GPU accelerator, \")\n",
        "  print(\"and then re-execute this cell.\")\n",
        "else:\n",
        "  print(gpu_info)\n",
        "\n",
        "# check if using high-RAM\n",
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print(\"Your runtime has {:.1f} gigabytes of available RAM\\n\".format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print(\"To enable a high-RAM runtime, select the Runtime > 'Change runtime type'\")\n",
        "  print(\"menu, and then select High-RAM in the Runtime shape dropdown. Then, \")\n",
        "  print(\"re-execute this cell.\")\n",
        "else:\n",
        "  print(\"You are using a high-RAM runtime!\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sat Jun 26 16:32:19 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.27       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   54C    P0    29W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n",
            "Your runtime has 27.3 gigabytes of available RAM\n",
            "\n",
            "You are using a high-RAM runtime!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3PoggZ91dRA"
      },
      "source": [
        "## **About the Dataset**  *(same as HW3)*\n",
        "\n",
        "The dataset used here is food-11, a collection of food images in 11 classes.\n",
        "\n",
        "For the requirement in the homework, TAs slightly modified the data.\n",
        "Please DO NOT access the original fully-labeled training data or testing labels.\n",
        "\n",
        "Also, the modified dataset is for this course only, and any further distribution or commercial use is forbidden."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BiNaf9gu1pu2",
        "outputId": "5236004a-edb0-4f09-aea3-b41bf6f0da42"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "DATA_PATH = 'gdrive/MyDrive/ColabNotebooks/HW13/food-11/'"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vg8nOEmK1saF"
      },
      "source": [
        "## **Import Packages**  *(same as HW3)*\n",
        "\n",
        "First, we need to import packages that will be used later.\n",
        "\n",
        "In this homework, we highly rely on **torchvision**, a library of PyTorch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAk_whhx1xuf"
      },
      "source": [
        "### This block is same as HW3 ###\n",
        "# Import necessary packages.\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "\n",
        "from PIL import Image\n",
        "# \"ConcatDataset\" and \"Subset\" are possibly useful when doing semi-supervised learning.\n",
        "from torch.utils.data import ConcatDataset, DataLoader, Subset\n",
        "from torchvision.datasets import DatasetFolder\n",
        "\n",
        "# This is for the progress bar.\n",
        "from tqdm.auto import tqdm"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vPjS3Q9WRakn"
      },
      "source": [
        "## **Dataset, Data Loader, and Transforms** *(similar to HW3)*\n",
        "\n",
        "Torchvision provides lots of useful utilities for image preprocessing, data wrapping as well as data augmentation.\n",
        "\n",
        "Here, since our data are stored in folders by class labels, we can directly apply **torchvision.datasets.DatasetFolder** for wrapping data without much effort.\n",
        "\n",
        "Please refer to [PyTorch official website](https://pytorch.org/vision/stable/transforms.html) for details about different transforms.\n",
        "\n",
        "---\n",
        "**The only diffference with HW3 is that the transform functions are different.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IImuu-Po11L-"
      },
      "source": [
        "### This block is similar to HW3 ###\n",
        "# It is important to do data augmentation in training.\n",
        "# However, not every augmentation is useful.\n",
        "# Please think about what kind of augmentation is helpful for food recognition.\n",
        "\n",
        "train_tfm = transforms.Compose([\n",
        "  # Resize the image into a fixed shape (height = width = 142)\n",
        "\ttransforms.Resize((142, 142)),\n",
        "  transforms.RandomHorizontalFlip(),\n",
        "  transforms.RandomRotation(15),\n",
        "\ttransforms.RandomCrop(128),\n",
        "\ttransforms.ToTensor(),\n",
        "])\n",
        "\n",
        "# We don't need augmentations in testing and validation.\n",
        "# All we need here is to resize the PIL image and transform it into Tensor.\n",
        "test_tfm = transforms.Compose([\n",
        "    # Resize the image into a fixed shape (height = width = 142)\n",
        "    transforms.Resize((142, 142)),\n",
        "    transforms.CenterCrop(128),\n",
        "    transforms.ToTensor(),\n",
        "])\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rcU_xd_C12ce"
      },
      "source": [
        "### This block is similar to HW3 ###\n",
        "# Batch size for training, validation, and testing.\n",
        "# A greater batch size usually gives a more stable gradient.\n",
        "# But the GPU memory is limited, so please adjust it carefully.\n",
        "batch_size = 128\n",
        "\n",
        "# Construct datasets.\n",
        "# The argument \"loader\" tells how torchvision reads the data.\n",
        "train_set = DatasetFolder(f\"{DATA_PATH}/training/labeled\", loader=lambda x: Image.open(x), extensions=\"jpg\", transform=train_tfm)\n",
        "valid_set = DatasetFolder(f\"{DATA_PATH}/validation\", loader=lambda x: Image.open(x), extensions=\"jpg\", transform=test_tfm)\n",
        "unlabeled_set = DatasetFolder(f\"{DATA_PATH}/training/unlabeled\", loader=lambda x: Image.open(x), extensions=\"jpg\", transform=train_tfm)\n",
        "test_set = DatasetFolder(f\"{DATA_PATH}/testing\", loader=lambda x: Image.open(x), extensions=\"jpg\", transform=test_tfm)\n",
        "\n",
        "# Construct data loaders.\n",
        "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
        "valid_loader = DataLoader(valid_set, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
        "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zggTBkI6bPkn"
      },
      "source": [
        "# **Architecture / Model Design**\n",
        "The following are types of convolution layer design that has fewer parameters.\n",
        "\n",
        "## **Depthwise & Pointwise Convolution**\n",
        "![](https://i.imgur.com/FBgcA0s.png)\n",
        "> Blue: the connection between layers \\\n",
        "> Green: the expansion of **receptive field** \\\n",
        "> (reference: arxiv:1810.04231)\n",
        "\n",
        "(a) normal convolution layer: It is fully connected. The difference between fully connected layer and fully connected convolution layer is the operation. (multiply --> convolution)\n",
        "\n",
        "(b) Depthwise convolution layer(DW): You can consider each feature map pass through their own filter and then pass through pointwise convolution layer(PW) to combine the information of all pixels in feature maps.\n",
        "\n",
        "\n",
        "(c) Group convolution layer(GC): Group the feature maps. Each group passes their filter then concate together. If group_size = input_feature_size, then GC becomes DC (channels are independent). If group_size = 1, then GC becomes fully connected.\n",
        "\n",
        "<img src=\"https://i.imgur.com/Hqhg0Q9.png\" width=\"500px\">\n",
        "\n",
        "\n",
        "## **Implementation details**\n",
        "```python\n",
        "# Regular Convolution, # of params = in_chs * out_chs * kernel_size^2\n",
        "nn.Conv2d(in_chs, out_chs, kernel_size, stride, padding)\n",
        "\n",
        "# Group Convolution, \"groups\" controls the connections between inputs and\n",
        "# outputs. in_chs and out_chs must both be divisible by groups.\n",
        "nn.Conv2d(in_chs, out_chs, kernel_size, stride, padding, groups=groups)\n",
        "\n",
        "# Depthwise Convolution, out_chs=in_chs=groups, # of params = in_chs * kernel_size^2\n",
        "nn.Conv2d(in_chs, out_chs=in_chs, kernel_size, stride, padding, groups=in_chs)\n",
        "\n",
        "# Pointwise Convolution, a.k.a 1 by 1 convolution, # of params = in_chs * out_chs\n",
        "nn.Conv2d(in_chs, out_chs, 1)\n",
        "\n",
        "# Merge Depthwise and Pointwise Convolution (without )\n",
        "def dwpw_conv(in_chs, out_chs, kernel_size, stride, padding):\n",
        "    return nn.Sequential(\n",
        "        nn.Conv2d(in_chs, in_chs, kernels, stride, padding, groups=in_chs),\n",
        "        nn.Conv2d(in_chs, out_chs, 1),\n",
        "    )\n",
        "```\n",
        "\n",
        "## **Model**\n",
        "\n",
        "The basic model here is simply a stack of convolutional layers followed by some fully-connected layers. You can take advatage of depthwise & pointwise convolution to make your model deeper, but still follow the size constraint."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRwpE9eebVXK"
      },
      "source": [
        "class dwpw_conv_block(nn.Module):\n",
        "    def __init__(self, in_chs, out_chs, kernel_size=3, stride=1, padding=1, t=8):\n",
        "        super(dwpw_conv_block, self).__init__()\n",
        "        assert(in_chs == out_chs)\n",
        "\n",
        "        hidden_chs = in_chs * t\n",
        "\n",
        "        self.layers = nn.Sequential(\n",
        "            # pw\n",
        "            nn.Conv2d(in_chs, hidden_chs, 1, 1, 0, bias=False),\n",
        "            nn.BatchNorm2d(hidden_chs),\n",
        "            nn.ReLU6(),\n",
        "\n",
        "            # dw\n",
        "            # analysis information in high dimension\n",
        "            nn.Conv2d(hidden_chs, hidden_chs, kernel_size, stride, padding, groups=hidden_chs, bias=False),\n",
        "            nn.BatchNorm2d(hidden_chs),\n",
        "            nn.ReLU6(),\n",
        "\n",
        "            # pw\n",
        "            # pass information in low dimension\n",
        "            nn.Conv2d(hidden_chs, out_chs, 1, 1, 0, bias=False),\n",
        "            nn.BatchNorm2d(out_chs),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x) + x\n",
        "\n",
        "class conv_block(nn.Module):\n",
        "    def __init__(self, in_chs, out_chs, kernel_size=3, stride=1, padding=1):\n",
        "        super(conv_block, self).__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Conv2d(in_chs, out_chs, kernel_size, stride, padding, bias=False),\n",
        "            nn.BatchNorm2d(out_chs),\n",
        "            nn.ReLU6(),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)\n",
        "\n",
        "class StudentNet(nn.Module):\n",
        "    def __init__(self):\n",
        "      super(StudentNet, self).__init__()\n",
        "\n",
        "      # ---------- TODO ----------\n",
        "      # Modify your model architecture\n",
        "\n",
        "      self.cnn = nn.Sequential(\n",
        "        conv_block(3, 16),\n",
        "        dwpw_conv_block(16, 16),\n",
        "        nn.MaxPool2d(2, 2, 0),\n",
        "\n",
        "        dwpw_conv_block(16, 16),\n",
        "        dwpw_conv_block(16, 16),\n",
        "        nn.MaxPool2d(2, 2, 0),     \n",
        "\n",
        "        dwpw_conv_block(16, 16),\n",
        "        dwpw_conv_block(16, 16),\n",
        "        nn.MaxPool2d(2, 2, 0),     \n",
        "\n",
        "        dwpw_conv_block(16, 16),\n",
        "        dwpw_conv_block(16, 16),\n",
        "        nn.MaxPool2d(2, 2, 0),     \n",
        "\n",
        "        dwpw_conv_block(16, 16),\n",
        "        dwpw_conv_block(16, 16),\n",
        "\n",
        "        dwpw_conv_block(16, 16),\n",
        "        dwpw_conv_block(16, 16),\n",
        "\n",
        "        dwpw_conv_block(16, 16),\n",
        "        dwpw_conv_block(16, 16),\n",
        "\n",
        "        dwpw_conv_block(16, 16),\n",
        "        dwpw_conv_block(16, 16),\n",
        "\n",
        "        dwpw_conv_block(16, 16),\n",
        "        dwpw_conv_block(16, 16),\n",
        "\n",
        "        # Here we adopt Global Average Pooling for various input size.\n",
        "        nn.AdaptiveAvgPool2d((1, 1)),\n",
        "      )\n",
        "\n",
        "      self.fc = nn.Sequential(\n",
        "        nn.Linear(16, 11),\n",
        "      )\n",
        "      \n",
        "    def forward(self, x):\n",
        "      out = self.cnn(x)\n",
        "      out = out.view(out.size()[0], -1)\n",
        "      return self.fc(out)\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MvHiN7q1BCRs"
      },
      "source": [
        "## **Model Analysis**\n",
        "\n",
        "Use `torchsummary` to get your model architecture (screenshot or pasting text are allowed.) and numbers of \n",
        "parameters, these two information should be submit to your NTU Cool questions.\n",
        "\n",
        "Note that the number of parameters **should not greater than 100,000**, or you'll get penalty in this homework.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0gB2f5dO-ktA",
        "outputId": "63ba0461-21f1-4c2f-a39c-4456b48a9786"
      },
      "source": [
        "from torchsummary import summary\n",
        "from os import path\n",
        "\n",
        "student_net = StudentNet().cuda()\n",
        "summary(student_net, (3, 128, 128))\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 16, 128, 128]             432\n",
            "       BatchNorm2d-2         [-1, 16, 128, 128]              32\n",
            "             ReLU6-3         [-1, 16, 128, 128]               0\n",
            "        conv_block-4         [-1, 16, 128, 128]               0\n",
            "            Conv2d-5        [-1, 128, 128, 128]           2,048\n",
            "       BatchNorm2d-6        [-1, 128, 128, 128]             256\n",
            "             ReLU6-7        [-1, 128, 128, 128]               0\n",
            "            Conv2d-8        [-1, 128, 128, 128]           1,152\n",
            "       BatchNorm2d-9        [-1, 128, 128, 128]             256\n",
            "            ReLU6-10        [-1, 128, 128, 128]               0\n",
            "           Conv2d-11         [-1, 16, 128, 128]           2,048\n",
            "      BatchNorm2d-12         [-1, 16, 128, 128]              32\n",
            "  dwpw_conv_block-13         [-1, 16, 128, 128]               0\n",
            "        MaxPool2d-14           [-1, 16, 64, 64]               0\n",
            "           Conv2d-15          [-1, 128, 64, 64]           2,048\n",
            "      BatchNorm2d-16          [-1, 128, 64, 64]             256\n",
            "            ReLU6-17          [-1, 128, 64, 64]               0\n",
            "           Conv2d-18          [-1, 128, 64, 64]           1,152\n",
            "      BatchNorm2d-19          [-1, 128, 64, 64]             256\n",
            "            ReLU6-20          [-1, 128, 64, 64]               0\n",
            "           Conv2d-21           [-1, 16, 64, 64]           2,048\n",
            "      BatchNorm2d-22           [-1, 16, 64, 64]              32\n",
            "  dwpw_conv_block-23           [-1, 16, 64, 64]               0\n",
            "           Conv2d-24          [-1, 128, 64, 64]           2,048\n",
            "      BatchNorm2d-25          [-1, 128, 64, 64]             256\n",
            "            ReLU6-26          [-1, 128, 64, 64]               0\n",
            "           Conv2d-27          [-1, 128, 64, 64]           1,152\n",
            "      BatchNorm2d-28          [-1, 128, 64, 64]             256\n",
            "            ReLU6-29          [-1, 128, 64, 64]               0\n",
            "           Conv2d-30           [-1, 16, 64, 64]           2,048\n",
            "      BatchNorm2d-31           [-1, 16, 64, 64]              32\n",
            "  dwpw_conv_block-32           [-1, 16, 64, 64]               0\n",
            "        MaxPool2d-33           [-1, 16, 32, 32]               0\n",
            "           Conv2d-34          [-1, 128, 32, 32]           2,048\n",
            "      BatchNorm2d-35          [-1, 128, 32, 32]             256\n",
            "            ReLU6-36          [-1, 128, 32, 32]               0\n",
            "           Conv2d-37          [-1, 128, 32, 32]           1,152\n",
            "      BatchNorm2d-38          [-1, 128, 32, 32]             256\n",
            "            ReLU6-39          [-1, 128, 32, 32]               0\n",
            "           Conv2d-40           [-1, 16, 32, 32]           2,048\n",
            "      BatchNorm2d-41           [-1, 16, 32, 32]              32\n",
            "  dwpw_conv_block-42           [-1, 16, 32, 32]               0\n",
            "           Conv2d-43          [-1, 128, 32, 32]           2,048\n",
            "      BatchNorm2d-44          [-1, 128, 32, 32]             256\n",
            "            ReLU6-45          [-1, 128, 32, 32]               0\n",
            "           Conv2d-46          [-1, 128, 32, 32]           1,152\n",
            "      BatchNorm2d-47          [-1, 128, 32, 32]             256\n",
            "            ReLU6-48          [-1, 128, 32, 32]               0\n",
            "           Conv2d-49           [-1, 16, 32, 32]           2,048\n",
            "      BatchNorm2d-50           [-1, 16, 32, 32]              32\n",
            "  dwpw_conv_block-51           [-1, 16, 32, 32]               0\n",
            "        MaxPool2d-52           [-1, 16, 16, 16]               0\n",
            "           Conv2d-53          [-1, 128, 16, 16]           2,048\n",
            "      BatchNorm2d-54          [-1, 128, 16, 16]             256\n",
            "            ReLU6-55          [-1, 128, 16, 16]               0\n",
            "           Conv2d-56          [-1, 128, 16, 16]           1,152\n",
            "      BatchNorm2d-57          [-1, 128, 16, 16]             256\n",
            "            ReLU6-58          [-1, 128, 16, 16]               0\n",
            "           Conv2d-59           [-1, 16, 16, 16]           2,048\n",
            "      BatchNorm2d-60           [-1, 16, 16, 16]              32\n",
            "  dwpw_conv_block-61           [-1, 16, 16, 16]               0\n",
            "           Conv2d-62          [-1, 128, 16, 16]           2,048\n",
            "      BatchNorm2d-63          [-1, 128, 16, 16]             256\n",
            "            ReLU6-64          [-1, 128, 16, 16]               0\n",
            "           Conv2d-65          [-1, 128, 16, 16]           1,152\n",
            "      BatchNorm2d-66          [-1, 128, 16, 16]             256\n",
            "            ReLU6-67          [-1, 128, 16, 16]               0\n",
            "           Conv2d-68           [-1, 16, 16, 16]           2,048\n",
            "      BatchNorm2d-69           [-1, 16, 16, 16]              32\n",
            "  dwpw_conv_block-70           [-1, 16, 16, 16]               0\n",
            "        MaxPool2d-71             [-1, 16, 8, 8]               0\n",
            "           Conv2d-72            [-1, 128, 8, 8]           2,048\n",
            "      BatchNorm2d-73            [-1, 128, 8, 8]             256\n",
            "            ReLU6-74            [-1, 128, 8, 8]               0\n",
            "           Conv2d-75            [-1, 128, 8, 8]           1,152\n",
            "      BatchNorm2d-76            [-1, 128, 8, 8]             256\n",
            "            ReLU6-77            [-1, 128, 8, 8]               0\n",
            "           Conv2d-78             [-1, 16, 8, 8]           2,048\n",
            "      BatchNorm2d-79             [-1, 16, 8, 8]              32\n",
            "  dwpw_conv_block-80             [-1, 16, 8, 8]               0\n",
            "           Conv2d-81            [-1, 128, 8, 8]           2,048\n",
            "      BatchNorm2d-82            [-1, 128, 8, 8]             256\n",
            "            ReLU6-83            [-1, 128, 8, 8]               0\n",
            "           Conv2d-84            [-1, 128, 8, 8]           1,152\n",
            "      BatchNorm2d-85            [-1, 128, 8, 8]             256\n",
            "            ReLU6-86            [-1, 128, 8, 8]               0\n",
            "           Conv2d-87             [-1, 16, 8, 8]           2,048\n",
            "      BatchNorm2d-88             [-1, 16, 8, 8]              32\n",
            "  dwpw_conv_block-89             [-1, 16, 8, 8]               0\n",
            "           Conv2d-90            [-1, 128, 8, 8]           2,048\n",
            "      BatchNorm2d-91            [-1, 128, 8, 8]             256\n",
            "            ReLU6-92            [-1, 128, 8, 8]               0\n",
            "           Conv2d-93            [-1, 128, 8, 8]           1,152\n",
            "      BatchNorm2d-94            [-1, 128, 8, 8]             256\n",
            "            ReLU6-95            [-1, 128, 8, 8]               0\n",
            "           Conv2d-96             [-1, 16, 8, 8]           2,048\n",
            "      BatchNorm2d-97             [-1, 16, 8, 8]              32\n",
            "  dwpw_conv_block-98             [-1, 16, 8, 8]               0\n",
            "           Conv2d-99            [-1, 128, 8, 8]           2,048\n",
            "     BatchNorm2d-100            [-1, 128, 8, 8]             256\n",
            "           ReLU6-101            [-1, 128, 8, 8]               0\n",
            "          Conv2d-102            [-1, 128, 8, 8]           1,152\n",
            "     BatchNorm2d-103            [-1, 128, 8, 8]             256\n",
            "           ReLU6-104            [-1, 128, 8, 8]               0\n",
            "          Conv2d-105             [-1, 16, 8, 8]           2,048\n",
            "     BatchNorm2d-106             [-1, 16, 8, 8]              32\n",
            " dwpw_conv_block-107             [-1, 16, 8, 8]               0\n",
            "          Conv2d-108            [-1, 128, 8, 8]           2,048\n",
            "     BatchNorm2d-109            [-1, 128, 8, 8]             256\n",
            "           ReLU6-110            [-1, 128, 8, 8]               0\n",
            "          Conv2d-111            [-1, 128, 8, 8]           1,152\n",
            "     BatchNorm2d-112            [-1, 128, 8, 8]             256\n",
            "           ReLU6-113            [-1, 128, 8, 8]               0\n",
            "          Conv2d-114             [-1, 16, 8, 8]           2,048\n",
            "     BatchNorm2d-115             [-1, 16, 8, 8]              32\n",
            " dwpw_conv_block-116             [-1, 16, 8, 8]               0\n",
            "          Conv2d-117            [-1, 128, 8, 8]           2,048\n",
            "     BatchNorm2d-118            [-1, 128, 8, 8]             256\n",
            "           ReLU6-119            [-1, 128, 8, 8]               0\n",
            "          Conv2d-120            [-1, 128, 8, 8]           1,152\n",
            "     BatchNorm2d-121            [-1, 128, 8, 8]             256\n",
            "           ReLU6-122            [-1, 128, 8, 8]               0\n",
            "          Conv2d-123             [-1, 16, 8, 8]           2,048\n",
            "     BatchNorm2d-124             [-1, 16, 8, 8]              32\n",
            " dwpw_conv_block-125             [-1, 16, 8, 8]               0\n",
            "          Conv2d-126            [-1, 128, 8, 8]           2,048\n",
            "     BatchNorm2d-127            [-1, 128, 8, 8]             256\n",
            "           ReLU6-128            [-1, 128, 8, 8]               0\n",
            "          Conv2d-129            [-1, 128, 8, 8]           1,152\n",
            "     BatchNorm2d-130            [-1, 128, 8, 8]             256\n",
            "           ReLU6-131            [-1, 128, 8, 8]               0\n",
            "          Conv2d-132             [-1, 16, 8, 8]           2,048\n",
            "     BatchNorm2d-133             [-1, 16, 8, 8]              32\n",
            " dwpw_conv_block-134             [-1, 16, 8, 8]               0\n",
            "          Conv2d-135            [-1, 128, 8, 8]           2,048\n",
            "     BatchNorm2d-136            [-1, 128, 8, 8]             256\n",
            "           ReLU6-137            [-1, 128, 8, 8]               0\n",
            "          Conv2d-138            [-1, 128, 8, 8]           1,152\n",
            "     BatchNorm2d-139            [-1, 128, 8, 8]             256\n",
            "           ReLU6-140            [-1, 128, 8, 8]               0\n",
            "          Conv2d-141             [-1, 16, 8, 8]           2,048\n",
            "     BatchNorm2d-142             [-1, 16, 8, 8]              32\n",
            " dwpw_conv_block-143             [-1, 16, 8, 8]               0\n",
            "          Conv2d-144            [-1, 128, 8, 8]           2,048\n",
            "     BatchNorm2d-145            [-1, 128, 8, 8]             256\n",
            "           ReLU6-146            [-1, 128, 8, 8]               0\n",
            "          Conv2d-147            [-1, 128, 8, 8]           1,152\n",
            "     BatchNorm2d-148            [-1, 128, 8, 8]             256\n",
            "           ReLU6-149            [-1, 128, 8, 8]               0\n",
            "          Conv2d-150             [-1, 16, 8, 8]           2,048\n",
            "     BatchNorm2d-151             [-1, 16, 8, 8]              32\n",
            " dwpw_conv_block-152             [-1, 16, 8, 8]               0\n",
            "          Conv2d-153            [-1, 128, 8, 8]           2,048\n",
            "     BatchNorm2d-154            [-1, 128, 8, 8]             256\n",
            "           ReLU6-155            [-1, 128, 8, 8]               0\n",
            "          Conv2d-156            [-1, 128, 8, 8]           1,152\n",
            "     BatchNorm2d-157            [-1, 128, 8, 8]             256\n",
            "           ReLU6-158            [-1, 128, 8, 8]               0\n",
            "          Conv2d-159             [-1, 16, 8, 8]           2,048\n",
            "     BatchNorm2d-160             [-1, 16, 8, 8]              32\n",
            " dwpw_conv_block-161             [-1, 16, 8, 8]               0\n",
            "AdaptiveAvgPool2d-162             [-1, 16, 1, 1]               0\n",
            "          Linear-163                   [-1, 11]             187\n",
            "================================================================\n",
            "Total params: 99,115\n",
            "Trainable params: 99,115\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.19\n",
            "Forward/backward pass size (MB): 181.59\n",
            "Params size (MB): 0.38\n",
            "Estimated Total Size (MB): 182.15\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQXY4vLmR8ae"
      },
      "source": [
        "## **Knowledge Distillation**\n",
        "\n",
        "<img src=\"https://i.imgur.com/H2aF7Rv.png=100x\" width=\"500px\">\n",
        "\n",
        "Since we have a learned big model, let it teach the other small model. In implementation, let the training target be the prediction of big model instead of the ground truth.\n",
        "\n",
        "## **Why it works?**\n",
        "* If the data is not clean, then the prediction of big model could ignore the noise of the data with wrong labeled.\n",
        "* The labels might have some relations. Number 8 is more similar to 6, 9, 0 than 1, 7, for example.\n",
        "\n",
        "\n",
        "## **How to implement?**\n",
        "* $Loss = \\alpha T^2 \\times KL(\\frac{\\text{Teacher's Logits}}{T} || \\frac{\\text{Student's Logits}}{T}) + (1-\\alpha)(\\text{Original Loss})$\n",
        "* Note that the logits here should have passed softmax."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6TMCyqrWTSsz"
      },
      "source": [
        "class HKD(nn.Module):\n",
        "    def forward(self, student, teacher):\n",
        "        # T = 4\n",
        "        # log_probs = F.log_softmax(student/T, dim=-1)\n",
        "        # teacher_probs = F.softmax(teacher/T, dim=-1)\n",
        "        # loss = (T**2) * F.kl_div(log_probs, teacher_probs, reduction='mean')\n",
        "\n",
        "        T = 20\n",
        "        log_probs = F.softmax(student/T, dim=-1)\n",
        "        teacher_probs = F.softmax(teacher/T, dim=-1)\n",
        "        loss = (log_probs * (log_probs / teacher_probs).log()).mean()\n",
        "\n",
        "        return loss\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dc6n1eJRH8ac"
      },
      "source": [
        "## RKd loss\n",
        "reference: \n",
        "1. https://github.com/lenscloth/RKD\n",
        "2. https://arxiv.org/pdf/1904.05068.pdf"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jDDsJeZ4IHe3"
      },
      "source": [
        "# def pdist(e, squared=False, eps=1e-12):\n",
        "#     e_square = e.pow(2).sum(dim=1)\n",
        "#     prod = e @ e.t()\n",
        "#     res = (e_square.unsqueeze(1) + e_square.unsqueeze(0) - 2 * prod).clamp(min=eps)\n",
        "\n",
        "#     if not squared:\n",
        "#         res = res.sqrt()\n",
        "\n",
        "#     res = res.clone()\n",
        "#     res[range(len(e)), range(len(e))] = 0\n",
        "#     return res\n",
        "\n",
        "# class RKDAngle(nn.Module):\n",
        "#     def forward(self, student, teacher):\n",
        "#         # N x C\n",
        "#         # N x N x C\n",
        "\n",
        "#         with torch.no_grad():\n",
        "#             td = (teacher.unsqueeze(0) - teacher.unsqueeze(1))\n",
        "#             norm_td = F.normalize(td, p=2, dim=2)\n",
        "#             t_angle = torch.bmm(norm_td, norm_td.transpose(1, 2)).view(-1)\n",
        "\n",
        "#         sd = (student.unsqueeze(0) - student.unsqueeze(1))\n",
        "#         norm_sd = F.normalize(sd, p=2, dim=2)\n",
        "#         s_angle = torch.bmm(norm_sd, norm_sd.transpose(1, 2)).view(-1)\n",
        "\n",
        "#         loss = F.smooth_l1_loss(s_angle, t_angle, reduction='mean')\n",
        "#         return 50 * loss\n",
        "\n",
        "\n",
        "# class RKDDistance(nn.Module):\n",
        "#     def forward(self, student, teacher):\n",
        "#         with torch.no_grad():\n",
        "#             t_d = pdist(teacher, squared=False)\n",
        "#             mean_td = t_d[t_d>0].mean()\n",
        "#             t_d = t_d / mean_td\n",
        "\n",
        "#         d = pdist(student, squared=False)\n",
        "#         mean_d = d[d>0].mean()\n",
        "#         d = d / mean_d\n",
        "\n",
        "#         loss = F.smooth_l1_loss(d, t_d, reduction='mean')\n",
        "#         return 25 * loss"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "97zXxEd3Thlb"
      },
      "source": [
        "## **Teacher Model Setting**\n",
        "We provide a well-trained teacher model to help you knowledge distillation to student model.\n",
        "Note that if you want to change the transform function, you should consider  if suitable for this well-trained teacher model.\n",
        "* If you cannot successfully gdown, you can change a link. (Backup link is provided at the bottom of this colab tutorial).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nR9J169XTjki",
        "outputId": "8a041c33-b561-46cb-8b63-aa7bff43aef0"
      },
      "source": [
        "# Download teacherNet\n",
        "!gdown --id '1zH1x39Y8a0XyOORG7TWzAnFf_YPY8e-m' --output teacher_net.ckpt\n",
        "# Load teacherNet\n",
        "teacher_net = torch.load('./teacher_net.ckpt').cuda()\n",
        "teacher_net.eval()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1zH1x39Y8a0XyOORG7TWzAnFf_YPY8e-m\n",
            "To: /content/teacher_net.ckpt\n",
            "44.8MB [00:00, 143MB/s] \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=512, out_features=11, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0DMKD-bnuIRF"
      },
      "source": [
        "## **Generate Pseudo Labels in Unlabeled Data**\n",
        "\n",
        "Since we have a well-trained model, we can use this model to predict pseudo-labels and help the student network train well. Note that you \n",
        "**CANNOT** use well-trained model to pseudo-label the test data. \n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "**AGAIN, DO NOT USE TEST DATA FOR PURPOSE OTHER THAN INFERENCING**\n",
        "\n",
        "* Because If you use teacher network to predict pseudo-labels of the test data, you can only use student network to overfit these pseudo-labels without train/unlabeled data. In this way, your kaggle accuracy will be as high as the teacher network, but the fact is that you just overfit the test data and your true testing accuracy is very low. \n",
        "* These contradict the purpose of these assignment (network compression); therefore, you should not misuse the test data.\n",
        "* If you have any concerns, you can email us.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83,
          "referenced_widgets": [
            "5150aa0d04d744ff92f42f7bc3efe328",
            "ecdaf7eef02543989ff7fec6d2f0abff",
            "babdeda82c86453c8902d93b444f2dcf",
            "9b34fdfa757c4fecaa93ff4f1baaae30",
            "08c685c3002e4d27b4ce2e2e870edabc",
            "5f0fae6b1fff401697431295ee847b3a",
            "4e91693b9907466d831e2fd4e6492fcc",
            "bcb23f24b1fa43bba173002c9dfcbf09"
          ]
        },
        "id": "tyRc7MktuJQN",
        "outputId": "82c997b3-8318-4321-8497-b3f80a4c778e"
      },
      "source": [
        "# \"cuda\" only when GPUs are available.\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f'using {device}')\n",
        "\n",
        "# Whether to do pseudo label.\n",
        "do_semi = True\n",
        "\n",
        "def get_pseudo_labels(dataset, model):\n",
        "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=False, pin_memory=True)\n",
        "    pseudo_labels = []\n",
        "    for batch in tqdm(loader):\n",
        "        # A batch consists of image data and corresponding labels.\n",
        "        img, _ = batch\n",
        "\n",
        "        # Forward the data\n",
        "        # Using torch.no_grad() accelerates the forward process.\n",
        "        with torch.no_grad():\n",
        "            logits = model(img.to(device))\n",
        "            pseudo_labels.append(logits.argmax(dim=-1).detach().cpu())\n",
        "        # Obtain the probability distributions by applying softmax on logits.\n",
        "    pseudo_labels = torch.cat(pseudo_labels)\n",
        "    # Update the labels by replacing with pseudo labels.\n",
        "    for idx, ((img, _), pseudo_label) in enumerate(zip(dataset.samples, pseudo_labels)):\n",
        "        dataset.samples[idx] = (img, pseudo_label.item())\n",
        "    return dataset\n",
        "\n",
        "if do_semi:\n",
        "    # Generate new trainloader with unlabeled set.\n",
        "    unlabeled_set = get_pseudo_labels(unlabeled_set, teacher_net)\n",
        "    concat_dataset = ConcatDataset([train_set, unlabeled_set])\n",
        "    train_loader = DataLoader(concat_dataset, batch_size=batch_size, shuffle=True, pin_memory=True, drop_last=True)\n",
        "\n",
        "\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "using cuda\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5150aa0d04d744ff92f42f7bc3efe328",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=54.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XeprOVBhT7cJ"
      },
      "source": [
        "## **Training** *(similar to HW3)*\n",
        "\n",
        "You can finish supervised learning by simply running the provided code without any modification.\n",
        "\n",
        "The function \"get_pseudo_labels\" is used for semi-supervised learning.\n",
        "It is expected to get better performance if you use unlabeled data for semi-supervised learning.\n",
        "However, you have to implement the function on your own and need to adjust several hyperparameters manually.\n",
        "\n",
        "For more details about semi-supervised learning, please refer to [Prof. Lee's slides](https://speech.ee.ntu.edu.tw/~tlkagk/courses/ML_2016/Lecture/semi%20(v3).pdf).\n",
        "\n",
        "Again, please notice that utilizing external data (or pre-trained model) for training is **prohibited**.\n",
        "\n",
        "---\n",
        "**The only diffference with HW3 is that you should use loss in  knowledge distillation.**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573,
          "referenced_widgets": [
            "416fc27caaf8499992a401f37c10c122",
            "def91a183bb647d1853565010763b2e5",
            "ab6dad2c7c0746c6838a20988103186a",
            "26af8132ca174a3c8b4e682f06df54cb",
            "e10aba05e7bf492e83c5c1507e49f68d",
            "a5183fe0808e4564b747efad1eb5ec24",
            "8e778c1a017f48b696e82598fdc6aadf",
            "07a0dacbd8be459cb9e2d1342b73e8fe",
            "c8766e29597543d596b6e3ad9e93f29c",
            "d8372e1d6f5a480582b67137e3a98e6a",
            "e31bdbe15a0b4b2a8526619c5969e166",
            "3cdc51151e8346349826b7274ce34418",
            "668e552ededd4ab89fce20f47fe534c7",
            "6df1a00671bc4dfbb55a74d88c468ea8",
            "a9350e7bd543445eb8625faa07ccf413",
            "6a3dee83d40a44329387feecea29a47d",
            "234edd1c12b94a01ac011264a707f899",
            "1750851ccef446f9a957ceb91c19ded3",
            "e61511b20d9d424aabb810db33fd3b15",
            "a2fa96d712104a6da3a8b65864b680c7",
            "0303ed92770b4965a3b03b3fd0868b5b",
            "7c7bd973273041898848a6f1baaeac3c",
            "3a12bd0ee2474b1a96f936c24440c70d",
            "068e9a50df87483ca03ccfff85a1ea4d"
          ]
        },
        "id": "tOm3Z55wDMOK",
        "outputId": "a7a062f8-85c7-4dee-e974-36572a257fb3"
      },
      "source": [
        "# loss criterion\n",
        "hkd_criterion = HKD()\n",
        "\n",
        "# Initialize optimizer, you may fine-tune some hyperparameters such as learning rate on your own.\n",
        "# RKD performing better without l2 normalization.\n",
        "optimizer = torch.optim.AdamW(student_net.parameters())\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, len(train_loader), eta_min=1e-6, last_epoch=-1, verbose=False)\n",
        "\n",
        "# The number of training epochs.\n",
        "n_epochs = 80\n",
        "\n",
        "# record the best model\n",
        "best_val_acc = -1\n",
        "\n",
        "# load best prev_state\n",
        "SAVING_PATH = \"/content/gdrive/MyDrive/ColabNotebooks/HW13/checkpoint_fc_256_11_\"\n",
        "if path.exists(SAVING_PATH):\n",
        "    print('loading...')\n",
        "    checkpoint = torch.load(SAVING_PATH)\n",
        "    student_net.load_state_dict(checkpoint['student_net'])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "    scheduler.load_state_dict(checkpoint['scheduler'])\n",
        "    best_val_acc = checkpoint['best_val_acc']\n",
        "    print(f'best_val_acc: {best_val_acc}')\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    # ---------- Training ----------\n",
        "    # Make sure the model is in train mode before training.\n",
        "    student_net.train()\n",
        "\n",
        "    # These are used to record information in training.\n",
        "    train_loss = []\n",
        "    train_accs = []\n",
        "\n",
        "    # Iterate the training set by batches.\n",
        "    for batch in tqdm(train_loader):\n",
        "\n",
        "        # A batch consists of image data and corresponding labels.\n",
        "        imgs, labels = batch\n",
        "\n",
        "        # Forward the data. (Make sure data and model are on the same device.)\n",
        "        logits = student_net(imgs.to(device))\n",
        "\n",
        "        # Teacher net will not be updated. And we use torch.no_grad\n",
        "        # to tell torch do not retain the intermediate values\n",
        "        # (which are for backpropgation) and save the memory.\n",
        "        with torch.no_grad():\n",
        "          soft_labels = teacher_net(imgs.to(device))\n",
        "        \n",
        "        # Calculate the loss in knowledge distillation method.\n",
        "        kd_loss = hkd_criterion(logits, soft_labels)\n",
        "        loss = kd_loss\n",
        "\n",
        "        # Gradients stored in the parameters in the previous step should be cleared out first.\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Compute the gradients for parameters.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the gradient norms for stable training.\n",
        "        grad_norm = nn.utils.clip_grad_norm_(student_net.parameters(), max_norm=10)\n",
        "\n",
        "        # Update the parameters with computed gradients.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Compute the accuracy for current batch.\n",
        "        acc = (logits.argmax(dim=-1) == labels.to(device)).float().mean()\n",
        "\n",
        "        # Record the loss and accuracy.\n",
        "        train_loss.append(loss.item())\n",
        "        train_accs.append(acc)\n",
        "\n",
        "        # update learning rate\n",
        "        scheduler.step()\n",
        "\n",
        "    # The average loss and accuracy of the training set is the average of the recorded values.\n",
        "    train_loss = sum(train_loss) / len(train_loss)\n",
        "    train_acc = sum(train_accs) / len(train_accs)\n",
        "\n",
        "    # Print the information.\n",
        "    print(f\"[ Train | {epoch + 1:03d}/{n_epochs:03d} ] loss = {train_loss:.5f}, acc = {train_acc:.5f}\")\n",
        "\n",
        "\n",
        "    # ---------- Validation ----------\n",
        "    # Make sure the model is in eval mode so that some modules like dropout are disabled and work normally.\n",
        "    student_net.eval()\n",
        "\n",
        "    # These are used to record information in validation.\n",
        "    valid_loss = []\n",
        "    valid_accs = []\n",
        "\n",
        "    # Iterate the validation set by batches.\n",
        "    for batch in tqdm(valid_loader):\n",
        "\n",
        "        # A batch consists of image data and corresponding labels.\n",
        "        imgs, labels = batch\n",
        "\n",
        "        # We don't need gradient in validation.\n",
        "        # Using torch.no_grad() accelerates the forward process.\n",
        "        with torch.no_grad():\n",
        "          logits = student_net(imgs.to(device))\n",
        "          soft_labels = teacher_net(imgs.to(device))\n",
        "        # We can still compute the loss (but not the gradient).\n",
        "        kd_loss = hkd_criterion(logits, soft_labels)\n",
        "        loss = kd_loss\n",
        "\n",
        "        # Compute the accuracy for current batch.\n",
        "        acc = (logits.argmax(dim=-1) == labels.to(device)).float().detach().cpu().view(-1).numpy()\n",
        "\n",
        "        # Record the loss and accuracy.\n",
        "        valid_loss.append(loss.item())\n",
        "        valid_accs += list(acc)\n",
        "\n",
        "    # The average loss and accuracy for entire validation set is the average of the recorded values.\n",
        "    valid_loss = sum(valid_loss) / len(valid_loss)\n",
        "    valid_acc = sum(valid_accs) / len(valid_accs)\n",
        "\n",
        "    if valid_acc >= best_val_acc:\n",
        "        best_val_acc = valid_acc\n",
        "        print(f'best_val_acc: {best_val_acc}, saving...')\n",
        "        checkpoint = {\n",
        "            \"student_net\": student_net.state_dict(),\n",
        "            \"optimizer\": optimizer.state_dict(),\n",
        "            \"scheduler\": scheduler.state_dict(),\n",
        "            \"best_val_acc\": best_val_acc,\n",
        "        }\n",
        "        torch.save(checkpoint, SAVING_PATH)\n",
        "\n",
        "    # Print the information.\n",
        "    print(f\"[ Valid | {epoch + 1:03d}/{n_epochs:03d} ] loss = {valid_loss:.5f}, acc = {valid_acc:.5f}\")\n",
        "\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loading...\n",
            "best_val_acc: 0.8166666666666667\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "416fc27caaf8499992a401f37c10c122",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=77.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[ Train | 001/080 ] loss = 0.00088, acc = 0.96814\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c8766e29597543d596b6e3ad9e93f29c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=6.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[ Valid | 001/080 ] loss = 0.00277, acc = 0.81212\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "234edd1c12b94a01ac011264a707f899",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=77.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-39f6f0134a30>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;31m# Iterate the training set by batches.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;31m# A batch consists of image data and corresponding labels.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tqdm/notebook.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m                 \u001b[0;31m# return super(tqdm...) will not catch exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 fp_write=getattr(self.fp, 'write', sys.stderr.write))\n\u001b[1;32m   1103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1104\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1105\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1106\u001b[0m             \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m             \u001b[0msample_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcumulative_sizes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset_idx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msample_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m             \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m             \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0mPIL\u001b[0m \u001b[0mImage\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mRescaled\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m         \"\"\"\n\u001b[0;32m--> 297\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mantialias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(img, size, interpolation, max_size, antialias)\u001b[0m\n\u001b[1;32m    399\u001b[0m             )\n\u001b[1;32m    400\u001b[0m         \u001b[0mpil_interpolation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpil_modes_mapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 401\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF_pil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpil_interpolation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    402\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mF_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mantialias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mantialias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional_pil.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(img, size, interpolation, max_size)\u001b[0m\n\u001b[1;32m    239\u001b[0m                 \u001b[0;34m\"i.e. size should be an int or a sequence of length 1 in torchscript mode.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m             )\n\u001b[0;32m--> 241\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(self, size, resample, box, reducing_gap)\u001b[0m\n\u001b[1;32m   1884\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1885\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1886\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1888\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreducing_gap\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mresample\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mNEAREST\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/PIL/ImageFile.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m                             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m                             \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nAIDw2P-l2lN"
      },
      "source": [
        "## **Testing** *(same as HW3)*\n",
        "\n",
        "For inference, we need to make sure the model is in eval mode, and the order of the dataset should not be shuffled (\"shuffle=False\" in test_loader).\n",
        "\n",
        "Last but not least, don't forget to save the predictions into a single CSV file.\n",
        "The format of CSV file should follow the rules mentioned in the slides.\n",
        "\n",
        "### **WARNING -- Keep in Mind**\n",
        "\n",
        "Cheating includes but not limited to:\n",
        "1.   using testing labels,\n",
        "2.   submitting results to previous Kaggle competitions,\n",
        "3.   sharing predictions with others,\n",
        "4.   copying codes from any creatures on Earth,\n",
        "5.   asking other people to do it for you.\n",
        "\n",
        "Any violations bring you punishments from getting a discount on the final grade to failing the course.\n",
        "\n",
        "It is your responsibility to check whether your code violates the rules.\n",
        "When citing codes from the Internet, you should know what these codes exactly do.\n",
        "You will **NOT** be tolerated if you break the rule and claim you don't know what these codes do.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJfC0qOD3z05",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100,
          "referenced_widgets": [
            "df075f36ad104e818390db83821aa9a7",
            "2d9b7a2778fd46e1b00aa9d22b640f3e",
            "3444098ecbd94f6faf015843a67c33a1",
            "1658a2a841744df191363696473430d6",
            "f818870110094436a9a55079bbcc0623",
            "0a646e77c4f349e0bbd604080013fa5c",
            "eb3d0a6229bb46c7aff44452289ec546",
            "24501e8267ad44479bcc3742f1420dc4"
          ]
        },
        "outputId": "6254541b-9886-4a4d-dd22-e26fb4b7cd70"
      },
      "source": [
        "print('loading...')\n",
        "checkpoint = torch.load(SAVING_PATH)\n",
        "student_net.load_state_dict(checkpoint['student_net'])\n",
        "optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "scheduler.load_state_dict(checkpoint['scheduler'])\n",
        "best_val_acc = checkpoint['best_val_acc']\n",
        "print(f'best_val_acc: {best_val_acc}')\n",
        "\n",
        "### This block is same as HW3 ###\n",
        "# Make sure the model is in eval mode.\n",
        "# Some modules like Dropout or BatchNorm affect if the model is in training mode.\n",
        "student_net.eval()\n",
        "\n",
        "# Initialize a list to store the predictions.\n",
        "predictions = []\n",
        "\n",
        "# Iterate the testing set by batches.\n",
        "for batch in tqdm(test_loader):\n",
        "    # A batch consists of image data and corresponding labels.\n",
        "    # But here the variable \"labels\" is useless since we do not have the ground-truth.\n",
        "    # If printing out the labels, you will find that it is always 0.\n",
        "    # This is because the wrapper (DatasetFolder) returns images and labels for each batch,\n",
        "    # so we have to create fake labels to make it work normally.\n",
        "    imgs, labels = batch\n",
        "\n",
        "    # We don't need gradient in testing, and we don't even have labels to compute loss.\n",
        "    # Using torch.no_grad() accelerates the forward process.\n",
        "    with torch.no_grad():\n",
        "        logits = student_net(imgs.to(device))\n",
        "\n",
        "    # Take the class with greatest logit as prediction and record it.\n",
        "    predictions.extend(logits.argmax(dim=-1).cpu().numpy().tolist())"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loading...\n",
            "best_val_acc: 0.8166666666666667\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "df075f36ad104e818390db83821aa9a7",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=27.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wSHk4ockETPT"
      },
      "source": [
        "### This block is same as HW3 ###\n",
        "# Save predictions into the file.\n",
        "with open(\"predict.csv\", \"w\") as f:\n",
        "\n",
        "    # The first row must be \"Id, Category\"\n",
        "    f.write(\"Id,Category\\n\")\n",
        "\n",
        "    # For the rest of the rows, each image id corresponds to a predicted class.\n",
        "    for i, pred in  enumerate(predictions):\n",
        "         f.write(f\"{i},{pred}\\n\")"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HmCWl8uU8V14"
      },
      "source": [
        "## **Statistics**\n",
        "\n",
        "|Baseline|Accuracy|Training Time|\n",
        "|-|-|-|\n",
        "|Simple Baseline |0.59856|2 Hours|\n",
        "|Medium Baseline |0.65412|2 Hours|\n",
        "|Strong Baseline |0.72819|4 Hours|\n",
        "|Boss Baseline |0.81003|Unmeasueable|\n",
        "\n",
        "## **Learning Curve**\n",
        "\n",
        "![img](https://lh5.googleusercontent.com/amMLGa7dkqvXGmsJlrVN49VfSjClk5d-n7nCi_Y3ROK4himsBSHhB7SpdWe7Zm06ctRO77VdDkD9u_aKfAh1tMW-KcyYX7vF7LPlKqOo2fVtt3SyfsLv0KTYDB0YbAk6ZhyOIKT8Zfg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zPTYk9w-B_yt"
      },
      "source": [
        "\n",
        "\n",
        "## **Q&A**\n",
        "\n",
        "If you have any question about this colab, please send a email to ntu-ml-2021spring-ta@googlegroups.com"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q3w5w7nMNd3R"
      },
      "source": [
        "## **Backup Links**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J337ak5VNZUT"
      },
      "source": [
        "# resnet_model \n",
        "# !gdown --id '1zH1x39Y8a0XyOORG7TWzAnFf_YPY8e-m' --output resnet_model.ckpt\n",
        "# !gdown --id '1VBIeQKH4xRHfToUxuDxtEPsqz0MHvrgd' --output resnet_model.ckpt\n",
        "# !gdown --id '1Er2azErvXWS5m1jboKN7BLxNXnuAatYw' --output resnet_model.ckpt\n",
        "# !gdown --id '1Qya0vmf3nRl11IyxxF7nudDpZI_Q4Amh' --output resnet_model.ckpt\n",
        "# !gdown --id '1fGOOb5ndljraBIkRkLp3bW9orR4YN97U' --output resnet_model.ckpt\n",
        "# !gdown --id '1apHLvZBZ3GYEMxXxToGKF7qDLn1XbOfJ' --output resnet_model.ckpt\n",
        "# !gdown --id '1vsDylNsLaAqxonop7Mw3dBAig0EO7tlF' --output resnet_model.ckpt\n",
        "# !gdown --id '1V_hXJM_V9-10i6wldRyl0SOiivPp4SNt' --output resnet_model.ckpt\n",
        "# !gdown --id '11HzaJM2M2yg6KYhLaWpWy8WmPIIvJgnk' --output resnet_model.ckpt\n",
        "\n",
        "# food-11\n",
        "# !gdown --id '1qdyNN0Ek4S5yi-pAqHes1yjj5cNkENCc' --output food-11.zip\n",
        "# !gdown --id '1c0Q1EP6yIx0O2rqVMIVInIt8wFjLxmRh' --output food-11.zip\n",
        "# !gdown --id '1hKO054nT1R8egcXY2-tgQbwX4EjowRLz' --output food-11.zip\n",
        "# !gdown --id '1_7_uC1WUvX6H51gQaYmI4q3AezdQJhud' --output food-11.zip\n",
        "# !gdown --id '12bz82Zpx0_7BDGXq4nRt7E_fMFmILoc9' --output food-11.zip\n",
        "# !gdown --id '1oiqRKrDQXVBM5y63MeEaHxFmCIzNXx1Q' --output food-11.zip\n",
        "# !gdown --id '1qaL43sl4qUMeCT1OVpk4aOFycnLL5ZJX' --output food-11.zip"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}